{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PostgreSQL cloud server credentials:\n",
    "# server ip: 34.75.124.150\n",
    "# username: user\n",
    "# password: DeEJNEAhy\n",
    "# Data is in materialized views train_data_random and train_labels_random\n",
    "\n",
    "# Sample Python code to load a full table from the dataframe:\n",
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('postgresql://user:DeEJNEAhy@34.75.124.150/postgres')\n",
    "df = pd.read_sql(\"\"\"\n",
    "                 WITH BASE AS (\n",
    "                    SELECT *\n",
    "                    ,ROW_NUMBER() OVER      (\n",
    "                                            PARTITION BY customer_id \n",
    "                                            ORDER BY s_2\n",
    "                                            )\n",
    "                    ,ROW_NUMBER() OVER      (\n",
    "                                            PARTITION BY customer_id\n",
    "                                            ORDER BY s_2 DESC\n",
    "                                            ) last_statement_flag_drop\n",
    "                    FROM TRAIN_DATA_RANDOM\n",
    "                    )\n",
    "\n",
    "\n",
    "                    SELECT *\n",
    "                    ,CASE WHEN last_statement_flag_drop = 1 then 1 else 0 end as last_statement_flag\n",
    "                    ,CASE WHEN (target = 1 AND last_statement_flag_drop = 1) then 1 else 0 end as last_statement_target\n",
    "                    FROM BASE B\n",
    "                    LEFT JOIN train_labels_random L\n",
    "                    ON B.customer_id = L.customer_id\n",
    "                 \"\"\", engine) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['customer_id', 's_2', 'p_2', 'd_39', 'b_1', 'b_2', 'r_1', 's_3', 'd_41', 'b_3', 'd_42', 'd_43', 'd_44', 'b_4', 'd_45', 'b_5', 'r_2', 'd_46', 'd_47', 'd_48', 'd_49', 'b_6', 'b_7', 'b_8', 'd_50', 'd_51', 'b_9', 'r_3', 'd_52', 'p_3', 'b_10', 'd_53', 's_5', 'b_11', 's_6', 'd_54', 'r_4', 's_7', 'b_12', 's_8', 'd_55', 'd_56', 'b_13', 'r_5', 'd_58', 's_9', 'b_14', 'd_59', 'd_60', 'd_61', 'b_15', 's_11', 'd_62', 'd_63', 'd_64', 'd_65', 'b_16', 'b_17', 'b_18', 'b_19', 'd_66', 'b_20', 'd_68', 's_12', 'r_6', 's_13', 'b_21', 'd_69', 'b_22', 'd_70', 'd_71', 'd_72', 's_15', 'b_23', 'd_73', 'p_4', 'd_74', 'd_75', 'd_76', 'b_24', 'r_7', 'd_77', 'b_25', 'b_26', 'd_78', 'd_79', 'r_8', 'r_9', 's_16', 'd_80', 'r_10', 'r_11', 'b_27', 'd_81', 'd_82', 's_17', 'r_12', 'b_28', 'r_13', 'd_83', 'r_14', 'r_15', 'd_84', 'r_16', 'b_29', 'b_30', 's_18', 'd_86', 'd_87', 'r_17', 'r_18', 'd_88', 'b_31', 's_19', 'r_19', 'b_32', 's_20', 'r_20', 'r_21', 'b_33', 'd_89', 'r_22', 'r_23', 'd_91', 'd_92', 'd_93', 'd_94', 'r_24', 'r_25', 'd_96', 's_22', 's_23', 's_24', 's_25', 's_26', 'd_102', 'd_103', 'd_104', 'd_105', 'd_106', 'd_107', 'b_36', 'b_37', 'r_26', 'r_27', 'b_38', 'd_108', 'd_109', 'd_110', 'd_111', 'b_39', 'd_112', 'b_40', 's_27', 'd_113', 'd_114', 'd_115', 'd_116', 'd_117', 'd_118', 'd_119', 'd_120', 'd_121', 'd_122', 'd_123', 'd_124', 'd_125', 'd_126', 'd_127', 'd_128', 'd_129', 'b_41', 'b_42', 'd_130', 'd_131', 'd_132', 'd_133', 'r_28', 'd_134', 'd_135', 'd_136', 'd_137', 'd_138', 'd_139', 'd_140', 'd_141', 'd_142', 'd_143', 'd_144', 'd_145', 'row_number', 'last_statement_flag_drop', 'customer_id', 'target', 'last_statement_flag', 'last_statement_target']\n"
     ]
    }
   ],
   "source": [
    "col_names = df.columns.tolist()\n",
    "print(col_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last Statement Specific Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import auc, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import datetime\n",
    "\n",
    "rand_state = 1337"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10000 entries, 12 to 120487\n",
      "Columns: 196 entries, customer_id to last_statement_target\n",
      "dtypes: float64(185), int64(6), object(5)\n",
      "memory usage: 15.0+ MB\n",
      "None\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10000 entries, 12 to 120487\n",
      "Columns: 190 entries, s_2 to target\n",
      "dtypes: float64(185), int64(2), object(3)\n",
      "memory usage: 14.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df_last = df[df.last_statement_flag == 1]\n",
    "print(df_last.info())\n",
    "print(\"\\n\")\n",
    "df_last = df_last.drop(columns=[\"customer_id\",\"row_number\",\"last_statement_flag_drop\",\"last_statement_flag\",\"last_statement_target\"]) #customer_id appears twice so ignore the mismatched # of dropped cols\n",
    "print(df_last.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a month only field\n",
    "#df_last['s_2-month'] = pd.DatetimeIndex(df_last['s_2']).month\n",
    "df_last = df_last.drop(columns=[\"s_2\"])\n",
    "\n",
    "#turns out month of last statement is always around a certain date. so actually going to drop the column entirely as we won't detect any cyclical variation between customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#have 2 categorical variables that need dummy coding\n",
    "df_last = pd.get_dummies(df_last, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imputing with mean values\n",
    "df_last = df_last.fillna(df_last.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_df_last = df_last.drop(columns=[\"target\"])\n",
    "y_df_last = df_last['target']\n",
    "\n",
    "x_df_last_train, x_df_last_test, y_df_last_train, y_df_last_test = train_test_split(x_df_last, y_df_last, test_size=0.3, random_state=rand_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=1337)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_last = RandomForestClassifier(random_state=rand_state)\n",
    "rf_last.fit(x_df_last_train, y_df_last_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.887"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_last.score(x_df_last_test, y_df_last_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All Statements (Diluted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 120488 entries, 0 to 120487\n",
      "Columns: 196 entries, customer_id to last_statement_target\n",
      "dtypes: float64(185), int64(6), object(5)\n",
      "memory usage: 180.2+ MB\n",
      "None\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 120488 entries, 0 to 120487\n",
      "Columns: 190 entries, s_2 to target\n",
      "dtypes: float64(185), int64(2), object(3)\n",
      "memory usage: 174.7+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df_all = df\n",
    "print(df_all.info())\n",
    "print(\"\\n\")\n",
    "df_all = df_all.drop(columns=[\"customer_id\",\"row_number\",\"last_statement_flag_drop\",\"last_statement_flag\",\"last_statement_target\"]) #customer_id appears twice so ignore the mismatched # of dropped cols\n",
    "print(df_all.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a month only field\n",
    "#df_last['s_2-month'] = pd.DatetimeIndex(df_last['s_2']).month\n",
    "df_all = df_all.drop(columns=[\"s_2\"])\n",
    "\n",
    "#turns out month of last statement is always around a certain date. so actually going to drop the column entirely as we won't detect any cyclical variation between customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#have 2 categorical variables that need dummy coding\n",
    "df_all = pd.get_dummies(df_all, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imputing with mean values\n",
    "df_all = df_all.fillna(df_all.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_df_all = df_all.drop(columns=[\"target\"])\n",
    "y_df_all = df_all['target']\n",
    "\n",
    "x_df_all_train, x_df_all_test, y_df_all_train, y_df_all_test = train_test_split(x_df_all, y_df_all, test_size=0.3, random_state=rand_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=1337)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_all = RandomForestClassifier(random_state=rand_state)\n",
    "rf_all.fit(x_df_all_train, y_df_all_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9222895399341577\n"
     ]
    }
   ],
   "source": [
    "print(rf_all.score(x_df_all_test, y_df_all_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp_last = pd.Series(rf_last.feature_importances_, index=x_df_last.columns).sort_values(ascending=False)\n",
    "feature_imp_all = pd.Series(rf_all.feature_importances_, index=x_df_all.columns).sort_values(ascending=False)\n",
    "pd.options.display.max_rows=200\n",
    "print(\"Last\")\n",
    "print(feature_imp_last)\n",
    "print(\"All\")\n",
    "print(feature_imp_all)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b38687464f26cc788bd6aab5d6ae24f3673c8f039be5f165e71e31106dd7d5ca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
