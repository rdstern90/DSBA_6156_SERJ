{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/pipelines-custom-transformers-in-scikit-learn-the-step-by-step-guide-with-python-code-4a7d9b068156"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.decomposition import PCA\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report,confusion_matrix,roc_curve,roc_auc_score, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "engine = create_engine('postgresql://user:DeEJNEAhy@34.75.124.150/postgres')\n",
    "\n",
    "rand_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = pd.read_sql(\"\"\" select schemaname as schema_name,\n",
    "#                         matviewname as view_name,\n",
    "#                         matviewowner as owner,\n",
    "#                         ispopulated as is_populated,\n",
    "#                         definition\n",
    "#                         from pg_matviews\n",
    "#                         order by schema_name,\n",
    "#                                 view_name\"\"\",engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_df = pd.read_sql(\"\"\"\n",
    "                 WITH BASE AS (\n",
    "                    SELECT *\n",
    "                    ,ROW_NUMBER() OVER      (\n",
    "                                            PARTITION BY customer_id\n",
    "                                            ORDER BY s_2\n",
    "                                            )\n",
    "                    ,ROW_NUMBER() OVER      (\n",
    "                                            PARTITION BY customer_id\n",
    "                                            ORDER BY s_2 DESC\n",
    "                                            ) last_statement_flag_drop\n",
    "                    FROM TRAIN_DATA_random\n",
    "                    )\n",
    "\n",
    "\n",
    "                    SELECT B.* , L.target\n",
    "                    ,CASE WHEN last_statement_flag_drop = 1 then 1 else 0 end as last_statement_flag\n",
    "                    ,CASE WHEN (target = 1 AND last_statement_flag_drop = 1) then 1 else 0 end as last_statement_target\n",
    "                    FROM BASE B                 \n",
    "                  INNER JOIN train_labels_random AS L\n",
    "                    ON B.customer_ID = L.customer_ID\n",
    "                 \"\"\", engine) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120488, 195)\n"
     ]
    }
   ],
   "source": [
    "# Moving the prepared dataframe to other dataframe to keep the original dataframe intact\n",
    "df = sql_df.copy()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['customer_id', 's_2', 'p_2', 'd_39', 'b_1', 'b_2', 'r_1', 's_3', 'd_41', 'b_3', 'd_42', 'd_43', 'd_44', 'b_4', 'd_45', 'b_5', 'r_2', 'd_46', 'd_47', 'd_48', 'd_49', 'b_6', 'b_7', 'b_8', 'd_50', 'd_51', 'b_9', 'r_3', 'd_52', 'p_3', 'b_10', 'd_53', 's_5', 'b_11', 's_6', 'd_54', 'r_4', 's_7', 'b_12', 's_8', 'd_55', 'd_56', 'b_13', 'r_5', 'd_58', 's_9', 'b_14', 'd_59', 'd_60', 'd_61', 'b_15', 's_11', 'd_62', 'd_63', 'd_64', 'd_65', 'b_16', 'b_17', 'b_18', 'b_19', 'd_66', 'b_20', 'd_68', 's_12', 'r_6', 's_13', 'b_21', 'd_69', 'b_22', 'd_70', 'd_71', 'd_72', 's_15', 'b_23', 'd_73', 'p_4', 'd_74', 'd_75', 'd_76', 'b_24', 'r_7', 'd_77', 'b_25', 'b_26', 'd_78', 'd_79', 'r_8', 'r_9', 's_16', 'd_80', 'r_10', 'r_11', 'b_27', 'd_81', 'd_82', 's_17', 'r_12', 'b_28', 'r_13', 'd_83', 'r_14', 'r_15', 'd_84', 'r_16', 'b_29', 'b_30', 's_18', 'd_86', 'd_87', 'r_17', 'r_18', 'd_88', 'b_31', 's_19', 'r_19', 'b_32', 's_20', 'r_20', 'r_21', 'b_33', 'd_89', 'r_22', 'r_23', 'd_91', 'd_92', 'd_93', 'd_94', 'r_24', 'r_25', 'd_96', 's_22', 's_23', 's_24', 's_25', 's_26', 'd_102', 'd_103', 'd_104', 'd_105', 'd_106', 'd_107', 'b_36', 'b_37', 'r_26', 'r_27', 'b_38', 'd_108', 'd_109', 'd_110', 'd_111', 'b_39', 'd_112', 'b_40', 's_27', 'd_113', 'd_114', 'd_115', 'd_116', 'd_117', 'd_118', 'd_119', 'd_120', 'd_121', 'd_122', 'd_123', 'd_124', 'd_125', 'd_126', 'd_127', 'd_128', 'd_129', 'b_41', 'b_42', 'd_130', 'd_131', 'd_132', 'd_133', 'r_28', 'd_134', 'd_135', 'd_136', 'd_137', 'd_138', 'd_139', 'd_140', 'd_141', 'd_142', 'd_143', 'd_144', 'd_145', 'row_number', 'last_statement_flag_drop', 'target', 'last_statement_flag', 'last_statement_target']\n"
     ]
    }
   ],
   "source": [
    "print(list(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps=[])\n",
    "# Categorical column D_66 was removed as it has missing values greater than 40% and would be taken care\n",
    "categorical_cols = ['b_30', 'b_38', 'd_114', 'd_116', 'd_117', 'd_120', 'd_126', 'd_63', 'd_64', 'd_68', 'b_31']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreProcessing(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cols_to_drop, categorical_cols):\n",
    "        # Creating the pipeline for the categorical variables and continuous variables\n",
    "        # Defining the categorical imputation for categorical variables.\n",
    "        self.categorical_pipeline = Pipeline(\n",
    "            steps=[\n",
    "                (\"impute_na\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                (\"impute_none\", SimpleImputer(missing_values=None, strategy=\"most_frequent\")) \n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # defining the numerical imputation and standard scaler for numerical variables.\n",
    "        self.numeric_pipeline = Pipeline(\n",
    "            steps=[(\"impute\", SimpleImputer(strategy=\"mean\")), \n",
    "                (\"scale\", StandardScaler())]\n",
    "        )\n",
    "\n",
    "        self.cols_to_drop = cols_to_drop + [\"customer_id\", \"s_2\" , \"row_number\",\"last_statement_flag_drop\"]\n",
    "        \n",
    "        \n",
    "        self.categorical_cols = categorical_cols\n",
    "\n",
    "    def fit(self, X, y = None):\n",
    "        # Get the list of columns that have missing values greater than equal to 40%\n",
    "        missing_perc = round((df.isnull().sum() / len(df)) * 100,2)\n",
    "        # Prepare final List of columns to drop\n",
    "        self.cols_to_drop = self.cols_to_drop + missing_perc[missing_perc.ge(40)].index.tolist()\n",
    "        # print(self.cols_to_drop)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Get the clean dataframe with columns to work\n",
    "        df = X.drop(columns=self.cols_to_drop)\n",
    "\n",
    "        numeric_cols = df.drop(columns=self.categorical_cols + ['target']).columns.tolist()\n",
    "        \n",
    "        # Apply the tranformation defined in pipeline\n",
    "        full_transformer = ColumnTransformer(\n",
    "            transformers=[\n",
    "                (\"numeric\", self.numeric_pipeline, numeric_cols),\n",
    "                (\"categorical\", self.categorical_pipeline, self.categorical_cols),\n",
    "            ],\n",
    "            # to keep the target column and just passthrough it, instead of dropping\n",
    "            remainder='passthrough'\n",
    "        )\n",
    "\n",
    "        transformed = full_transformer.fit_transform(df)\n",
    "        # Converted the array to dataframe\n",
    "        df_transformed = pd.DataFrame(data=transformed, columns= numeric_cols + self.categorical_cols + ['target'])\n",
    "        \n",
    "        # Convert the data type except for the columns which have categorical (text) values to float64\n",
    "        list1 = [col for col in df_transformed.columns.tolist() if col != 'd_63' and col != 'd_64']\n",
    "        df_transformed[list1] = df_transformed[list1].astype('float64')\n",
    "\n",
    "        # OneHotEncoding for d_63 and d_64\n",
    "        categories = [['CL', 'CO', 'CR', 'XL', 'XM', 'XZ'], ['-1', 'O', 'R', 'U']]\n",
    "        enc = OneHotEncoder(categories=categories, sparse=False, drop='first')\n",
    "        encoded = enc.fit_transform(df_transformed[['d_63', 'd_64']].values)\n",
    "        df_transformed = pd.concat([\n",
    "            df_transformed.drop(columns=['d_63', 'd_64']),\n",
    "            pd.DataFrame(encoded, columns=enc.get_feature_names_out(['d_63', 'd_64']))\n",
    "        ], axis=1)\n",
    "\n",
    "        return df_transformed\n",
    "\n",
    "\n",
    "preprocessing = PreProcessing([\"last_statement_flag\",\"last_statement_target\"], categorical_cols)\n",
    "df_processed = preprocessing.fit_transform(df)\n",
    "\n",
    "pipeline.steps.append(('preprocessing', preprocessing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_2</th>\n",
       "      <th>d_39</th>\n",
       "      <th>b_1</th>\n",
       "      <th>b_2</th>\n",
       "      <th>r_1</th>\n",
       "      <th>s_3</th>\n",
       "      <th>d_41</th>\n",
       "      <th>b_3</th>\n",
       "      <th>d_43</th>\n",
       "      <th>d_44</th>\n",
       "      <th>...</th>\n",
       "      <th>b_31</th>\n",
       "      <th>target</th>\n",
       "      <th>d_63_CO</th>\n",
       "      <th>d_63_CR</th>\n",
       "      <th>d_63_XL</th>\n",
       "      <th>d_63_XM</th>\n",
       "      <th>d_63_XZ</th>\n",
       "      <th>d_64_O</th>\n",
       "      <th>d_64_R</th>\n",
       "      <th>d_64_U</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.902703</td>\n",
       "      <td>-0.351567</td>\n",
       "      <td>-0.003581</td>\n",
       "      <td>0.942175</td>\n",
       "      <td>-0.307893</td>\n",
       "      <td>-1.733677</td>\n",
       "      <td>-0.264934</td>\n",
       "      <td>-0.523208</td>\n",
       "      <td>-0.628418</td>\n",
       "      <td>-0.539412</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.918297</td>\n",
       "      <td>1.086441</td>\n",
       "      <td>0.084757</td>\n",
       "      <td>0.962055</td>\n",
       "      <td>-0.308245</td>\n",
       "      <td>-1.644936</td>\n",
       "      <td>-0.247591</td>\n",
       "      <td>-0.542647</td>\n",
       "      <td>-0.652007</td>\n",
       "      <td>-0.515992</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.801276</td>\n",
       "      <td>-0.545151</td>\n",
       "      <td>-0.522329</td>\n",
       "      <td>0.943050</td>\n",
       "      <td>-0.341281</td>\n",
       "      <td>-1.687701</td>\n",
       "      <td>-0.268637</td>\n",
       "      <td>-0.559145</td>\n",
       "      <td>-0.665243</td>\n",
       "      <td>-0.538750</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.690403</td>\n",
       "      <td>1.770372</td>\n",
       "      <td>-0.421388</td>\n",
       "      <td>0.941993</td>\n",
       "      <td>-0.340623</td>\n",
       "      <td>-1.670525</td>\n",
       "      <td>-0.282410</td>\n",
       "      <td>-0.520330</td>\n",
       "      <td>-0.659069</td>\n",
       "      <td>-0.558386</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.924602</td>\n",
       "      <td>0.227966</td>\n",
       "      <td>-0.483777</td>\n",
       "      <td>0.852029</td>\n",
       "      <td>-0.321751</td>\n",
       "      <td>-1.720459</td>\n",
       "      <td>-0.247078</td>\n",
       "      <td>-0.561487</td>\n",
       "      <td>-0.675502</td>\n",
       "      <td>-0.544023</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 164 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        p_2      d_39       b_1       b_2       r_1       s_3      d_41  \\\n",
       "0  0.902703 -0.351567 -0.003581  0.942175 -0.307893 -1.733677 -0.264934   \n",
       "1  0.918297  1.086441  0.084757  0.962055 -0.308245 -1.644936 -0.247591   \n",
       "2  0.801276 -0.545151 -0.522329  0.943050 -0.341281 -1.687701 -0.268637   \n",
       "3  0.690403  1.770372 -0.421388  0.941993 -0.340623 -1.670525 -0.282410   \n",
       "4  0.924602  0.227966 -0.483777  0.852029 -0.321751 -1.720459 -0.247078   \n",
       "\n",
       "        b_3      d_43      d_44  ...  b_31  target  d_63_CO  d_63_CR  d_63_XL  \\\n",
       "0 -0.523208 -0.628418 -0.539412  ...   1.0     0.0      1.0      0.0      0.0   \n",
       "1 -0.542647 -0.652007 -0.515992  ...   1.0     0.0      1.0      0.0      0.0   \n",
       "2 -0.559145 -0.665243 -0.538750  ...   1.0     0.0      1.0      0.0      0.0   \n",
       "3 -0.520330 -0.659069 -0.558386  ...   1.0     0.0      1.0      0.0      0.0   \n",
       "4 -0.561487 -0.675502 -0.544023  ...   1.0     0.0      1.0      0.0      0.0   \n",
       "\n",
       "   d_63_XM  d_63_XZ  d_64_O  d_64_R  d_64_U  \n",
       "0      0.0      0.0     1.0     0.0     0.0  \n",
       "1      0.0      0.0     1.0     0.0     0.0  \n",
       "2      0.0      0.0     1.0     0.0     0.0  \n",
       "3      0.0      0.0     1.0     0.0     0.0  \n",
       "4      0.0      0.0     1.0     0.0     0.0  \n",
       "\n",
       "[5 rows x 164 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the correlation and VIF, we will consider the numerical columns only. We have done dummy encoding for d_63 & d_64, so need to consider those column names also\n",
    "cols_to_drop = [col for col in df_processed.columns.tolist() if col.startswith('d_63') or col.startswith('d_64')] + categorical_cols + ['target']\n",
    "cols_to_drop.remove('d_63')\n",
    "cols_to_drop.remove('d_64')\n",
    "#Numerical columns dataframe\n",
    "df_numerical = df_processed.drop(columns=cols_to_drop).copy()\n",
    "\n",
    "# Do the correlation after transposing the array\n",
    "df_corr = df_numerical.corr()\n",
    "df_corr.to_csv(\"./ignore/LR_all_stmt/num_corr_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for the VIF on the numerical columns\n",
    "vif_data1 = pd.DataFrame()\n",
    "vif_data1[\"feature\"] = df_numerical.columns\n",
    "# print(len(vif_data1.feature.unique()))\n",
    "\n",
    "# calculating VIF for each feature\n",
    "vif_data1[\"VIF\"] = [variance_inflation_factor(df_numerical.values, i) for i in range(len(df_numerical.columns))]\n",
    "vif_data1.to_csv(\"./ignore/LR_all_stmt/num_VIF_data_results.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCATransform(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, vif_data):\n",
    "        self.vif_data = vif_data\n",
    "        \n",
    "        # Get the list of the variables with the higher VIF value\n",
    "        self.vif_variable_lst = vif_data1[vif_data1['VIF'] >= 11]['feature'].tolist() \n",
    "\n",
    "        # List of columns that were considered in pca\n",
    "        self.pca_cols_to_drop = set()\n",
    "\n",
    "        self.pca_models = []\n",
    "\n",
    "    def fit(self, X):\n",
    "        # Looping on VIF list\n",
    "        for i in self.vif_variable_lst:   \n",
    "            # Check if the VIF variable is already in the set from the earlier pass\n",
    "            bool1 = i in self.pca_cols_to_drop\n",
    "            # print(bool1)\n",
    "            if bool1 == True:   \n",
    "                continue\n",
    "            else: \n",
    "                # Get the list of correlated columns for the current vif column processed\n",
    "                pca_list = df_corr[(df_corr[i] != 1 ) & ((df_corr[i] >= 0.7) | (df_corr[i] <= -0.7 ))].index.tolist()\n",
    "                # Perform the below logic, only when any correlated column found\n",
    "                if len(pca_list) != 0:\n",
    "\n",
    "                    # Add the processed VIF column also\n",
    "                    pca_list = [i] + pca_list\n",
    "                    # print(pca_list)\n",
    "\n",
    "                    # Append this list to set, as these columns at the later stage needs to be dropped off from the main dataframe, because then the PCA values will be used instead of original column\n",
    "                    self.pca_cols_to_drop.update(pca_list)\n",
    "                    \n",
    "                    # Create the dataframe of only those columns that are correlated with the column processed in the loop\n",
    "                    df_pca = X.loc[:,pca_list]\n",
    "                    # Create instance of PCA model\n",
    "                    pca = PCA(random_state=rand_state)\n",
    "                    pca.fit_transform(df_pca)\n",
    "\n",
    "                    # Create eigen value array\n",
    "                    eigen_arr = pca.explained_variance_\n",
    "                    # Create a filter array where the eigen value should be >= 1\n",
    "                    filter_arr = eigen_arr >=1\n",
    "                    # No. of components with eigen value >= 1\n",
    "                    no_of_components = len(eigen_arr[filter_arr])\n",
    "                    \n",
    "                    # Run the PCA again with the no_of_components found\n",
    "                    pca = PCA(n_components = no_of_components, random_state=rand_state)\n",
    "                    pca.fit(df_pca)\n",
    "                    # append the tuple of the columns went for PCA , no. of components, and the instance of the fitted PCA\n",
    "                    self.pca_models.append((pca_list, no_of_components, pca))\n",
    "\n",
    "                    \n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        for pca_list, no_of_components, pca in self.pca_models:\n",
    "            df_pca = X.loc[:,pca_list]\n",
    "            PCA_values = pca.transform(df_pca)\n",
    "\n",
    "            # The number of columns to create for the final PCA dataframe\n",
    "            pca_columns = []\n",
    "            for val in range(1, no_of_components + 1):\n",
    "                a = pca_list[0] + '_pca_' + str(val)\n",
    "                pca_columns += [a]\n",
    "                    \n",
    "            # Create the final PCA dataframe that will be concatenated to original dataframe\n",
    "            finalpca_df = pd.DataFrame(data = PCA_values, columns=pca_columns)\n",
    "\n",
    "            # Append this dataframe to main one\n",
    "            X = pd.concat([X, finalpca_df], axis=1)   \n",
    "\n",
    "            # Clean-up RAM & memory\n",
    "            del [[df_pca, finalpca_df]]\n",
    "\n",
    "        \n",
    "        # Now remove the columns for which pca was done\n",
    "        X.drop(columns=self.pca_cols_to_drop, inplace=True)\n",
    "\n",
    "        return X\n",
    "\n",
    "pca_transform = PCATransform(vif_data1)\n",
    "df_pca = pca_transform.fit_transform(df_processed)\n",
    "\n",
    "pipeline.steps.append(('pca', pca_transform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.steps = pipeline.steps[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_2</th>\n",
       "      <th>d_39</th>\n",
       "      <th>r_1</th>\n",
       "      <th>s_3</th>\n",
       "      <th>d_41</th>\n",
       "      <th>d_43</th>\n",
       "      <th>d_45</th>\n",
       "      <th>b_5</th>\n",
       "      <th>r_2</th>\n",
       "      <th>d_46</th>\n",
       "      <th>...</th>\n",
       "      <th>b_1_pca_1</th>\n",
       "      <th>b_2_pca_1</th>\n",
       "      <th>b_7_pca_1</th>\n",
       "      <th>r_5_pca_1</th>\n",
       "      <th>d_58_pca_1</th>\n",
       "      <th>b_14_pca_1</th>\n",
       "      <th>s_22_pca_1</th>\n",
       "      <th>d_103_pca_1</th>\n",
       "      <th>d_118_pca_1</th>\n",
       "      <th>d_139_pca_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.902703</td>\n",
       "      <td>-0.351567</td>\n",
       "      <td>-0.307893</td>\n",
       "      <td>-1.733677</td>\n",
       "      <td>-0.264934</td>\n",
       "      <td>-0.628418</td>\n",
       "      <td>0.779124</td>\n",
       "      <td>0.372871</td>\n",
       "      <td>-0.197518</td>\n",
       "      <td>-0.151851</td>\n",
       "      <td>...</td>\n",
       "      <td>0.425069</td>\n",
       "      <td>-1.746947</td>\n",
       "      <td>-0.608979</td>\n",
       "      <td>-0.137862</td>\n",
       "      <td>-1.653912</td>\n",
       "      <td>0.612386</td>\n",
       "      <td>-0.379177</td>\n",
       "      <td>-1.661071</td>\n",
       "      <td>-1.008564</td>\n",
       "      <td>-0.791340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.918297</td>\n",
       "      <td>1.086441</td>\n",
       "      <td>-0.308245</td>\n",
       "      <td>-1.644936</td>\n",
       "      <td>-0.247591</td>\n",
       "      <td>-0.652007</td>\n",
       "      <td>0.783272</td>\n",
       "      <td>0.371638</td>\n",
       "      <td>-0.205938</td>\n",
       "      <td>-0.228841</td>\n",
       "      <td>...</td>\n",
       "      <td>0.290437</td>\n",
       "      <td>-1.840949</td>\n",
       "      <td>-0.551344</td>\n",
       "      <td>-0.137255</td>\n",
       "      <td>-1.616202</td>\n",
       "      <td>0.765313</td>\n",
       "      <td>-0.374092</td>\n",
       "      <td>-1.657163</td>\n",
       "      <td>-0.972036</td>\n",
       "      <td>-0.813867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.801276</td>\n",
       "      <td>-0.545151</td>\n",
       "      <td>-0.341281</td>\n",
       "      <td>-1.687701</td>\n",
       "      <td>-0.268637</td>\n",
       "      <td>-0.665243</td>\n",
       "      <td>0.802244</td>\n",
       "      <td>0.688468</td>\n",
       "      <td>-0.188065</td>\n",
       "      <td>-0.174993</td>\n",
       "      <td>...</td>\n",
       "      <td>1.166267</td>\n",
       "      <td>-1.834468</td>\n",
       "      <td>-0.985151</td>\n",
       "      <td>-0.142654</td>\n",
       "      <td>-1.882491</td>\n",
       "      <td>-0.321875</td>\n",
       "      <td>-0.371926</td>\n",
       "      <td>-1.670606</td>\n",
       "      <td>-0.965347</td>\n",
       "      <td>-0.809064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.690403</td>\n",
       "      <td>1.770372</td>\n",
       "      <td>-0.340623</td>\n",
       "      <td>-1.670525</td>\n",
       "      <td>-0.282410</td>\n",
       "      <td>-0.659069</td>\n",
       "      <td>0.792745</td>\n",
       "      <td>0.660893</td>\n",
       "      <td>-0.230207</td>\n",
       "      <td>-0.073850</td>\n",
       "      <td>...</td>\n",
       "      <td>1.030819</td>\n",
       "      <td>-1.826860</td>\n",
       "      <td>-0.951834</td>\n",
       "      <td>-0.166809</td>\n",
       "      <td>-1.871942</td>\n",
       "      <td>-0.134618</td>\n",
       "      <td>-0.381019</td>\n",
       "      <td>-1.661401</td>\n",
       "      <td>-0.989551</td>\n",
       "      <td>-0.809642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.924602</td>\n",
       "      <td>0.227966</td>\n",
       "      <td>-0.321751</td>\n",
       "      <td>-1.720459</td>\n",
       "      <td>-0.247078</td>\n",
       "      <td>-0.675502</td>\n",
       "      <td>0.834221</td>\n",
       "      <td>0.268389</td>\n",
       "      <td>-0.198559</td>\n",
       "      <td>-0.339467</td>\n",
       "      <td>...</td>\n",
       "      <td>1.081608</td>\n",
       "      <td>-1.330898</td>\n",
       "      <td>-0.940834</td>\n",
       "      <td>-0.151958</td>\n",
       "      <td>-0.960280</td>\n",
       "      <td>-0.193006</td>\n",
       "      <td>-0.346291</td>\n",
       "      <td>-1.665437</td>\n",
       "      <td>-0.966359</td>\n",
       "      <td>-0.797467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        p_2      d_39       r_1       s_3      d_41      d_43      d_45  \\\n",
       "0  0.902703 -0.351567 -0.307893 -1.733677 -0.264934 -0.628418  0.779124   \n",
       "1  0.918297  1.086441 -0.308245 -1.644936 -0.247591 -0.652007  0.783272   \n",
       "2  0.801276 -0.545151 -0.341281 -1.687701 -0.268637 -0.665243  0.802244   \n",
       "3  0.690403  1.770372 -0.340623 -1.670525 -0.282410 -0.659069  0.792745   \n",
       "4  0.924602  0.227966 -0.321751 -1.720459 -0.247078 -0.675502  0.834221   \n",
       "\n",
       "        b_5       r_2      d_46  ...  b_1_pca_1  b_2_pca_1  b_7_pca_1  \\\n",
       "0  0.372871 -0.197518 -0.151851  ...   0.425069  -1.746947  -0.608979   \n",
       "1  0.371638 -0.205938 -0.228841  ...   0.290437  -1.840949  -0.551344   \n",
       "2  0.688468 -0.188065 -0.174993  ...   1.166267  -1.834468  -0.985151   \n",
       "3  0.660893 -0.230207 -0.073850  ...   1.030819  -1.826860  -0.951834   \n",
       "4  0.268389 -0.198559 -0.339467  ...   1.081608  -1.330898  -0.940834   \n",
       "\n",
       "   r_5_pca_1  d_58_pca_1  b_14_pca_1  s_22_pca_1  d_103_pca_1  d_118_pca_1  \\\n",
       "0  -0.137862   -1.653912    0.612386   -0.379177    -1.661071    -1.008564   \n",
       "1  -0.137255   -1.616202    0.765313   -0.374092    -1.657163    -0.972036   \n",
       "2  -0.142654   -1.882491   -0.321875   -0.371926    -1.670606    -0.965347   \n",
       "3  -0.166809   -1.871942   -0.134618   -0.381019    -1.661401    -0.989551   \n",
       "4  -0.151958   -0.960280   -0.193006   -0.346291    -1.665437    -0.966359   \n",
       "\n",
       "   d_139_pca_1  \n",
       "0    -0.791340  \n",
       "1    -0.813867  \n",
       "2    -0.809064  \n",
       "3    -0.809642  \n",
       "4    -0.797467  \n",
       "\n",
       "[5 rows x 140 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.289265\n",
      "         Iterations 9\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                 target   No. Observations:                84341\n",
      "Model:                          Logit   Df Residuals:                    84202\n",
      "Method:                           MLE   Df Model:                          138\n",
      "Date:                Sun, 30 Oct 2022   Pseudo R-squ.:                  0.4909\n",
      "Time:                        21:13:48   Log-Likelihood:                -24397.\n",
      "converged:                       True   LL-Null:                       -47921.\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "===============================================================================\n",
      "                  coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "p_2            -0.8624      0.025    -35.057      0.000      -0.911      -0.814\n",
      "d_39            0.1226      0.013      9.247      0.000       0.097       0.149\n",
      "r_1             0.1689      0.031      5.488      0.000       0.109       0.229\n",
      "s_3             0.1224      0.025      4.981      0.000       0.074       0.171\n",
      "d_41            0.1929      0.019     10.077      0.000       0.155       0.230\n",
      "d_43            0.0913      0.016      5.618      0.000       0.059       0.123\n",
      "d_45           -0.0786      0.026     -3.056      0.002      -0.129      -0.028\n",
      "b_5            -0.1222      0.028     -4.350      0.000      -0.177      -0.067\n",
      "r_2            -0.0138      0.023     -0.589      0.556      -0.060       0.032\n",
      "d_46            0.1579      0.014     11.658      0.000       0.131       0.184\n",
      "d_47           -0.2295      0.021    -11.136      0.000      -0.270      -0.189\n",
      "d_48            0.0214      0.022      0.994      0.320      -0.021       0.064\n",
      "b_6             0.0094      0.010      0.968      0.333      -0.010       0.029\n",
      "b_8             0.2081      0.020     10.411      0.000       0.169       0.247\n",
      "d_51           -0.3340      0.030    -11.209      0.000      -0.392      -0.276\n",
      "b_9             0.0588      0.015      3.812      0.000       0.029       0.089\n",
      "r_3             0.1974      0.016     12.628      0.000       0.167       0.228\n",
      "d_52            0.0031      0.014      0.228      0.820      -0.023       0.030\n",
      "p_3             0.1127      0.014      8.194      0.000       0.086       0.140\n",
      "b_10           -0.0338      0.048     -0.698      0.485      -0.129       0.061\n",
      "s_5             0.0012      0.010      0.124      0.902      -0.018       0.021\n",
      "s_6             0.0305      0.016      1.923      0.055      -0.001       0.062\n",
      "d_54            0.0147      0.012      1.193      0.233      -0.009       0.039\n",
      "r_4            -0.0088      0.026     -0.338      0.736      -0.060       0.042\n",
      "s_7             0.0343      0.025      1.365      0.172      -0.015       0.083\n",
      "b_12            0.0595      0.025      2.342      0.019       0.010       0.109\n",
      "s_8             0.0520      0.028      1.846      0.065      -0.003       0.107\n",
      "b_13           -0.0098      0.034     -0.287      0.774      -0.077       0.057\n",
      "d_59           -0.0063      0.013     -0.493      0.622      -0.031       0.019\n",
      "d_60            0.0733      0.019      3.835      0.000       0.036       0.111\n",
      "d_61            0.1822      0.021      8.573      0.000       0.141       0.224\n",
      "s_11           -0.1212      0.014     -8.878      0.000      -0.148      -0.094\n",
      "d_62           -0.2045      0.025     -8.318      0.000      -0.253      -0.156\n",
      "d_65            0.0056      0.014      0.411      0.681      -0.021       0.032\n",
      "s_12            0.0342      0.010      3.328      0.001       0.014       0.054\n",
      "r_6            -0.0280      0.019     -1.446      0.148      -0.066       0.010\n",
      "s_13            0.0470      0.021      2.206      0.027       0.005       0.089\n",
      "b_21            0.0307      0.021      1.432      0.152      -0.011       0.073\n",
      "d_69            0.0642      0.010      6.187      0.000       0.044       0.084\n",
      "b_22            0.0189      0.018      1.025      0.305      -0.017       0.055\n",
      "d_70            0.0329      0.013      2.561      0.010       0.008       0.058\n",
      "d_71           -0.0543      0.041     -1.332      0.183      -0.134       0.026\n",
      "d_72           -0.0157      0.015     -1.034      0.301      -0.045       0.014\n",
      "s_15            0.0980      0.020      4.902      0.000       0.059       0.137\n",
      "p_4             0.1374      0.013     10.682      0.000       0.112       0.163\n",
      "b_24           -0.0168      0.020     -0.834      0.404      -0.056       0.023\n",
      "r_7             0.0499      0.020      2.525      0.012       0.011       0.089\n",
      "b_25            0.0183      0.015      1.217      0.224      -0.011       0.048\n",
      "b_26            0.0300      0.012      2.526      0.012       0.007       0.053\n",
      "d_78           -0.0097      0.014     -0.714      0.475      -0.036       0.017\n",
      "d_79            0.0372      0.021      1.790      0.074      -0.004       0.078\n",
      "s_16            0.0357      0.015      2.397      0.017       0.007       0.065\n",
      "d_80            0.0255      0.013      2.025      0.043       0.001       0.050\n",
      "r_10           -0.0573      0.018     -3.156      0.002      -0.093      -0.022\n",
      "r_11            0.0524      0.011      4.852      0.000       0.031       0.074\n",
      "b_27           -0.0030      0.012     -0.264      0.792      -0.026       0.020\n",
      "d_81           -0.0436      0.015     -2.870      0.004      -0.073      -0.014\n",
      "s_17           -0.0247      0.010     -2.395      0.017      -0.045      -0.004\n",
      "r_12            0.0181      0.015      1.177      0.239      -0.012       0.048\n",
      "b_28           -0.0825      0.027     -3.029      0.002      -0.136      -0.029\n",
      "r_13           -0.0278      0.018     -1.576      0.115      -0.062       0.007\n",
      "d_83           -0.0027      0.010     -0.284      0.776      -0.022       0.016\n",
      "r_14            0.0395      0.016      2.512      0.012       0.009       0.070\n",
      "r_15           -0.0087      0.014     -0.604      0.546      -0.037       0.020\n",
      "d_84            0.0310      0.025      1.243      0.214      -0.018       0.080\n",
      "r_16           -0.0343      0.014     -2.511      0.012      -0.061      -0.008\n",
      "s_18            0.0144      0.013      1.100      0.271      -0.011       0.040\n",
      "d_86           -0.1614      0.018     -8.981      0.000      -0.197      -0.126\n",
      "r_17           -0.0058      0.013     -0.436      0.663      -0.032       0.020\n",
      "r_18           -0.0262      0.011     -2.379      0.017      -0.048      -0.005\n",
      "s_19           -0.0053      0.011     -0.462      0.644      -0.028       0.017\n",
      "r_19           -0.0129      0.012     -1.096      0.273      -0.036       0.010\n",
      "b_32           -0.0436      0.010     -4.335      0.000      -0.063      -0.024\n",
      "s_20            0.0666      0.016      4.169      0.000       0.035       0.098\n",
      "r_20           -0.0143      0.018     -0.793      0.428      -0.050       0.021\n",
      "r_21           -0.0053      0.019     -0.280      0.780      -0.043       0.032\n",
      "d_89           -0.0209      0.017     -1.203      0.229      -0.055       0.013\n",
      "r_22           -0.0284      0.009     -3.119      0.002      -0.046      -0.011\n",
      "r_23           -0.0051      0.009     -0.579      0.562      -0.023       0.012\n",
      "d_91           -0.0057      0.024     -0.233      0.815      -0.054       0.042\n",
      "d_92            0.0432      0.027      1.584      0.113      -0.010       0.097\n",
      "d_93           -0.0510      0.019     -2.655      0.008      -0.089      -0.013\n",
      "d_94            0.0353      0.029      1.208      0.227      -0.022       0.093\n",
      "r_24           -0.0087      0.020     -0.440      0.660      -0.048       0.030\n",
      "r_25           -0.0367      0.015     -2.391      0.017      -0.067      -0.007\n",
      "d_96           -0.0415      0.016     -2.557      0.011      -0.073      -0.010\n",
      "s_23            0.0326      0.010      3.118      0.002       0.012       0.053\n",
      "s_25            0.0218      0.010      2.176      0.030       0.002       0.042\n",
      "s_26           -0.1501      0.033     -4.482      0.000      -0.216      -0.084\n",
      "b_36            0.0927      0.010      9.329      0.000       0.073       0.112\n",
      "r_27           -0.1413      0.011    -13.389      0.000      -0.162      -0.121\n",
      "d_109           0.0698      0.014      5.096      0.000       0.043       0.097\n",
      "d_112          -0.0934      0.014     -6.526      0.000      -0.121      -0.065\n",
      "b_40            0.0036      0.014      0.261      0.794      -0.023       0.030\n",
      "s_27           -0.0230      0.010     -2.315      0.021      -0.042      -0.004\n",
      "d_113          -0.0193      0.017     -1.143      0.253      -0.052       0.014\n",
      "d_121           0.2546      0.023     11.281      0.000       0.210       0.299\n",
      "d_122          -0.0170      0.016     -1.038      0.299      -0.049       0.015\n",
      "d_123           0.0552      0.012      4.445      0.000       0.031       0.080\n",
      "d_124           0.0384      0.015      2.505      0.012       0.008       0.068\n",
      "d_125           0.0143      0.014      1.039      0.299      -0.013       0.041\n",
      "d_127          -0.1672      0.030     -5.609      0.000      -0.226      -0.109\n",
      "d_128           0.0030      0.021      0.148      0.882      -0.037       0.043\n",
      "d_129          -0.1789      0.020     -8.850      0.000      -0.218      -0.139\n",
      "b_41            0.0440      0.013      3.349      0.001       0.018       0.070\n",
      "d_130           0.0399      0.015      2.732      0.006       0.011       0.069\n",
      "d_131           0.1818      0.025      7.365      0.000       0.133       0.230\n",
      "d_133          -0.1440      0.014    -10.201      0.000      -0.172      -0.116\n",
      "r_28           -0.0187      0.009     -2.153      0.031      -0.036      -0.002\n",
      "d_140           0.0577      0.010      5.539      0.000       0.037       0.078\n",
      "d_144          -0.0011      0.014     -0.078      0.938      -0.029       0.027\n",
      "d_145          -0.0116      0.013     -0.905      0.365      -0.037       0.014\n",
      "b_30            0.0540      0.042      1.285      0.199      -0.028       0.136\n",
      "b_38            0.0394      0.010      3.829      0.000       0.019       0.059\n",
      "d_114          -0.1812      0.032     -5.700      0.000      -0.244      -0.119\n",
      "d_116          -0.0921      0.269     -0.343      0.732      -0.619       0.435\n",
      "d_117          -0.0293      0.006     -5.100      0.000      -0.041      -0.018\n",
      "d_120          -0.1413      0.035     -4.026      0.000      -0.210      -0.072\n",
      "d_126          -0.0229      0.024     -0.964      0.335      -0.070       0.024\n",
      "d_68           -0.0138      0.013     -1.096      0.273      -0.038       0.011\n",
      "b_31           -1.7294      0.139    -12.453      0.000      -2.002      -1.457\n",
      "d_63_CO        -0.0747      0.051     -1.454      0.146      -0.175       0.026\n",
      "d_63_CR         0.2755      0.055      4.978      0.000       0.167       0.384\n",
      "d_63_XL         0.4031      0.350      1.153      0.249      -0.282       1.088\n",
      "d_63_XM         0.5193      0.262      1.984      0.047       0.006       1.032\n",
      "d_63_XZ         0.2939      0.173      1.700      0.089      -0.045       0.633\n",
      "d_64_O         -0.2170      0.132     -1.641      0.101      -0.476       0.042\n",
      "d_64_R         -0.2865      0.132     -2.178      0.029      -0.544      -0.029\n",
      "d_64_U         -0.3000      0.130     -2.304      0.021      -0.555      -0.045\n",
      "b_1_pca_1      -0.1231      0.010    -12.379      0.000      -0.143      -0.104\n",
      "b_2_pca_1       0.0373      0.011      3.250      0.001       0.015       0.060\n",
      "b_7_pca_1       0.1311      0.012     10.518      0.000       0.107       0.156\n",
      "r_5_pca_1       0.0520      0.023      2.252      0.024       0.007       0.097\n",
      "d_58_pca_1      0.1162      0.013      8.651      0.000       0.090       0.143\n",
      "b_14_pca_1      0.0628      0.016      4.045      0.000       0.032       0.093\n",
      "s_22_pca_1     -0.0076      0.008     -0.911      0.362      -0.024       0.009\n",
      "d_103_pca_1     0.0027      0.007      0.395      0.693      -0.011       0.016\n",
      "d_118_pca_1     0.0049      0.012      0.407      0.684      -0.019       0.029\n",
      "d_139_pca_1    -0.0358      0.010     -3.515      0.000      -0.056      -0.016\n",
      "===============================================================================\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression model\n",
    "Xdf_SG = df_pca.drop(columns=['target'])\n",
    "ydf_SG = df_pca['target']\n",
    "# Split the data using stratify method, to avoid only one class data seep in train\n",
    "train_XSG, val_XSG, train_ySG, val_ySG = train_test_split(Xdf_SG,ydf_SG,test_size=0.3,random_state=rand_state,stratify = ydf_SG)\n",
    "\n",
    "# Model\n",
    "regression1_SG = sm.Logit(train_ySG,train_XSG).fit()\n",
    "print(regression1_SG.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[24862,  2054],\n",
       "       [ 2684,  6547]], dtype=int64)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the confusion matrix\n",
    "prediction_probab = regression1_SG.predict(val_XSG)\n",
    "prediction = list(map(round,prediction_probab))\n",
    "confusion_matrix(val_ySG,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic : ROC AUC = 0.931\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate roc metric \n",
    "regression1_SG_auc = roc_auc_score(val_ySG,prediction_probab)\n",
    "print('Logistic : ROC AUC = %.3f' % (regression1_SG_auc))\n",
    "\n",
    "regression1_SG_fpr,regression1_SG_tpr,_ = roc_curve(val_ySG,prediction_probab)\n",
    "plt.plot(regression1_SG_fpr,regression1_SG_tpr,marker = '.')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.92      0.91     26916\n",
      "         1.0       0.76      0.71      0.73      9231\n",
      "\n",
      "    accuracy                           0.87     36147\n",
      "   macro avg       0.83      0.82      0.82     36147\n",
      "weighted avg       0.87      0.87      0.87     36147\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate Recall and Precision\n",
    "print(classification_report(val_ySG, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy is: 0.8690435256873881\n",
      "Validation accuracy is: 0.8689241154176004\n"
     ]
    }
   ],
   "source": [
    "# Accuracy Score to find underfitting & overfitting\n",
    "pred_prob_score = regression1_SG.predict(train_XSG)\n",
    "pred = list(map(float,list(map(round,pred_prob_score))))\n",
    "\n",
    "print(f'Training accuracy is: {accuracy_score(train_ySG, pred )}')\n",
    "print(f'Validation accuracy is: {accuracy_score(val_ySG, prediction)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.289668\n",
      "         Iterations 8\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                 target   No. Observations:                84341\n",
      "Model:                          Logit   Df Residuals:                    84259\n",
      "Method:                           MLE   Df Model:                           81\n",
      "Date:                Sun, 30 Oct 2022   Pseudo R-squ.:                  0.4902\n",
      "Time:                        21:13:49   Log-Likelihood:                -24431.\n",
      "converged:                       True   LL-Null:                       -47921.\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "===============================================================================\n",
      "                  coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "p_2            -0.8531      0.023    -37.355      0.000      -0.898      -0.808\n",
      "d_39            0.1256      0.013      9.670      0.000       0.100       0.151\n",
      "r_1             0.1398      0.018      7.742      0.000       0.104       0.175\n",
      "s_3             0.1530      0.012     12.458      0.000       0.129       0.177\n",
      "d_41            0.1807      0.017     10.347      0.000       0.146       0.215\n",
      "d_43            0.0922      0.016      5.702      0.000       0.061       0.124\n",
      "d_45           -0.0704      0.024     -2.897      0.004      -0.118      -0.023\n",
      "b_5            -0.1177      0.027     -4.384      0.000      -0.170      -0.065\n",
      "d_46            0.1639      0.013     12.376      0.000       0.138       0.190\n",
      "d_47           -0.2285      0.020    -11.246      0.000      -0.268      -0.189\n",
      "b_8             0.2074      0.020     10.475      0.000       0.169       0.246\n",
      "d_51           -0.3185      0.021    -15.149      0.000      -0.360      -0.277\n",
      "b_9             0.0658      0.015      4.410      0.000       0.037       0.095\n",
      "r_3             0.1987      0.016     12.812      0.000       0.168       0.229\n",
      "p_3             0.1108      0.013      8.366      0.000       0.085       0.137\n",
      "s_6             0.0256      0.016      1.646      0.100      -0.005       0.056\n",
      "b_12            0.0597      0.016      3.752      0.000       0.029       0.091\n",
      "s_8             0.0451      0.028      1.615      0.106      -0.010       0.100\n",
      "d_60            0.0824      0.019      4.438      0.000       0.046       0.119\n",
      "d_61            0.1926      0.018     10.589      0.000       0.157       0.228\n",
      "s_11           -0.1228      0.014     -9.045      0.000      -0.149      -0.096\n",
      "d_62           -0.2092      0.024     -8.843      0.000      -0.256      -0.163\n",
      "s_12            0.0320      0.010      3.187      0.001       0.012       0.052\n",
      "s_13            0.0558      0.021      2.698      0.007       0.015       0.096\n",
      "d_69            0.0623      0.010      6.542      0.000       0.044       0.081\n",
      "d_70            0.0295      0.013      2.328      0.020       0.005       0.054\n",
      "s_15            0.0944      0.020      4.752      0.000       0.055       0.133\n",
      "p_4             0.1422      0.012     11.586      0.000       0.118       0.166\n",
      "r_7             0.0319      0.013      2.400      0.016       0.006       0.058\n",
      "b_26            0.0298      0.011      2.683      0.007       0.008       0.052\n",
      "s_16            0.0500      0.016      3.192      0.001       0.019       0.081\n",
      "d_80            0.0254      0.012      2.046      0.041       0.001       0.050\n",
      "r_10           -0.0455      0.014     -3.259      0.001      -0.073      -0.018\n",
      "r_11            0.0528      0.011      4.921      0.000       0.032       0.074\n",
      "d_81           -0.0554      0.012     -4.474      0.000      -0.080      -0.031\n",
      "s_17           -0.0239      0.010     -2.325      0.020      -0.044      -0.004\n",
      "b_28           -0.0814      0.023     -3.521      0.000      -0.127      -0.036\n",
      "r_14            0.0233      0.012      1.952      0.051      -0.000       0.047\n",
      "r_16           -0.0341      0.014     -2.521      0.012      -0.061      -0.008\n",
      "d_86           -0.1607      0.018     -9.006      0.000      -0.196      -0.126\n",
      "r_18           -0.0252      0.011     -2.291      0.022      -0.047      -0.004\n",
      "b_32           -0.0429      0.010     -4.298      0.000      -0.063      -0.023\n",
      "s_20            0.0754      0.012      6.179      0.000       0.051       0.099\n",
      "r_22           -0.0277      0.009     -3.126      0.002      -0.045      -0.010\n",
      "d_93           -0.0518      0.019     -2.747      0.006      -0.089      -0.015\n",
      "r_25           -0.0583      0.012     -4.979      0.000      -0.081      -0.035\n",
      "d_96           -0.0424      0.016     -2.630      0.009      -0.074      -0.011\n",
      "s_23            0.0332      0.010      3.211      0.001       0.013       0.053\n",
      "s_25            0.0212      0.010      2.132      0.033       0.002       0.041\n",
      "s_26           -0.1518      0.033     -4.558      0.000      -0.217      -0.087\n",
      "b_36            0.0967      0.010     10.095      0.000       0.078       0.115\n",
      "r_27           -0.1407      0.010    -13.411      0.000      -0.161      -0.120\n",
      "d_109           0.0699      0.014      5.175      0.000       0.043       0.096\n",
      "d_112          -0.0942      0.014     -6.639      0.000      -0.122      -0.066\n",
      "s_27           -0.0222      0.010     -2.252      0.024      -0.041      -0.003\n",
      "d_121           0.2467      0.019     13.125      0.000       0.210       0.283\n",
      "d_123           0.0640      0.010      6.156      0.000       0.044       0.084\n",
      "d_124           0.0386      0.013      2.873      0.004       0.012       0.065\n",
      "d_127          -0.1677      0.029     -5.743      0.000      -0.225      -0.110\n",
      "d_129          -0.1757      0.015    -11.993      0.000      -0.204      -0.147\n",
      "b_41            0.0340      0.012      2.865      0.004       0.011       0.057\n",
      "d_130           0.0394      0.015      2.716      0.007       0.011       0.068\n",
      "d_131           0.2136      0.017     12.669      0.000       0.181       0.247\n",
      "d_133          -0.1448      0.014    -10.284      0.000      -0.172      -0.117\n",
      "r_28           -0.0188      0.009     -2.185      0.029      -0.036      -0.002\n",
      "d_140           0.0582      0.010      5.855      0.000       0.039       0.078\n",
      "b_38            0.0360      0.010      3.551      0.000       0.016       0.056\n",
      "d_114          -0.1937      0.031     -6.286      0.000      -0.254      -0.133\n",
      "d_117          -0.0323      0.005     -5.950      0.000      -0.043      -0.022\n",
      "d_120          -0.1340      0.035     -3.873      0.000      -0.202      -0.066\n",
      "b_31           -2.0624      0.045    -45.637      0.000      -2.151      -1.974\n",
      "d_63_CR         0.3201      0.040      8.002      0.000       0.242       0.399\n",
      "d_63_XM         0.5586      0.259      2.158      0.031       0.051       1.066\n",
      "d_64_R         -0.0609      0.036     -1.704      0.088      -0.131       0.009\n",
      "d_64_U         -0.0762      0.030     -2.553      0.011      -0.135      -0.018\n",
      "b_1_pca_1      -0.1348      0.009    -15.486      0.000      -0.152      -0.118\n",
      "b_2_pca_1       0.0439      0.011      4.012      0.000       0.022       0.065\n",
      "b_7_pca_1       0.1281      0.012     10.637      0.000       0.104       0.152\n",
      "r_5_pca_1       0.0322      0.015      2.092      0.036       0.002       0.062\n",
      "d_58_pca_1      0.1210      0.013      9.442      0.000       0.096       0.146\n",
      "b_14_pca_1      0.0670      0.014      4.861      0.000       0.040       0.094\n",
      "d_139_pca_1    -0.0421      0.007     -6.366      0.000      -0.055      -0.029\n",
      "===============================================================================\n"
     ]
    }
   ],
   "source": [
    "# Remove the insignificant features and train the model again. I will keep the alpha level as 0.07\n",
    "logit_pvalues = round(regression1_SG.pvalues,3)\n",
    "high_pval_col = logit_pvalues.index[logit_pvalues > 0.07]\n",
    "\n",
    "# Drop these columns\n",
    "Xdf_SG_new = Xdf_SG.drop(columns=high_pval_col).copy()\n",
    "\n",
    "# Split the data using stratify method, to avoid only one class data seep in train\n",
    "train_XSG_new, val_XSG_new, train_ySG_new, val_ySG_new = train_test_split(Xdf_SG_new, ydf_SG, test_size=0.3, random_state=rand_state, stratify = ydf_SG)\n",
    "\n",
    "# Model\n",
    "regression2_SG = sm.Logit(train_ySG_new,train_XSG_new).fit()\n",
    "print(regression2_SG.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82\n"
     ]
    }
   ],
   "source": [
    "print(Xdf_SG_new.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy is: 0.868426148781365\n",
      "Logistic : ROC AUC = 0.930\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# After removing the insignificant variables, the AUC score and validation accuracy is still maintained\n",
    "\n",
    "prediction_probab_new = regression2_SG.predict(val_XSG_new)\n",
    "prediction_new = list(map(round,prediction_probab_new))\n",
    "\n",
    "print(f'Validation accuracy is: {accuracy_score(val_ySG_new, prediction_new)}')\n",
    "\n",
    "# Calculate roc metric \n",
    "regression2_SG_auc = roc_auc_score(val_ySG_new,prediction_probab_new)\n",
    "print('Logistic : ROC AUC = %.3f' % (regression2_SG_auc))\n",
    "\n",
    "regression2_SG_fpr,regression2_SG_tpr,_ = roc_curve(val_ySG_new,prediction_probab_new)\n",
    "plt.plot(regression2_SG_fpr,regression2_SG_tpr,marker = '.')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression using sklearn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=500, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=500, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=500, random_state=42)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sklearn Logistic regression aftr removing insignificant variables\n",
    "log_reg = LogisticRegression(random_state=rand_state,  max_iter=500) #,  max_iter=200\n",
    "log_reg.fit(train_XSG_new,train_ySG_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8682324950894956\n"
     ]
    }
   ],
   "source": [
    "y_pred = log_reg.predict(val_XSG_new)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(val_ySG_new,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_model(df):\n",
    "    # Just add extra columns with 0 value so that pipeline does not fail --> these are the extra columns that we had in the training data\n",
    "    extra_cols = ['row_number', 'last_statement_flag_drop', 'target', 'last_statement_flag', 'last_statement_target']\n",
    "    # Concatenate the dataframe of extra columns with the dataframe of the test data\n",
    "    df = pd.concat([\n",
    "        df,\n",
    "        pd.DataFrame(np.zeros((df.shape[0], len(extra_cols))), columns=extra_cols)\n",
    "    ], axis=1)\n",
    "\n",
    "    # Use the pipeline to transform\n",
    "    X = pipeline.transform(df)\n",
    "\n",
    "    # Drop target & the insignificant variables found during the training using statsmodel p-value\n",
    "    X.drop(columns=['target'] + high_pval_col.tolist(), inplace=True)\n",
    "\n",
    "    # return log_reg.predict(X), log_reg.predict_proba(X)\n",
    "    # In the statsmodel predict will give the probability\n",
    "    return list(map(round,regression2_SG.predict(X))), regression2_SG.predict(X).tolist()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1000001\n",
      "2000001\n",
      "3000001\n",
      "4000001\n",
      "5000001\n",
      "6000001\n",
      "7000001\n",
      "8000001\n",
      "9000001\n",
      "10000001\n",
      "11000001\n",
      "12000001\n"
     ]
    }
   ],
   "source": [
    "path = './ignore/test_data.csv/test_data.csv'\n",
    "\n",
    "current_position = 1 \n",
    "split_num_lines = 1000000\n",
    "columns = pd.read_csv(path, nrows=1).columns # Just read columns\n",
    "    \n",
    "# Define the result mdf\n",
    "mdf = pd.DataFrame(columns=['customer_id', 's_2', 'pred', 'proba'])\n",
    "\n",
    "# Get chunks from the test_data.csv and send them to the model\n",
    "while True:\n",
    "    print(current_position)        \n",
    "    df_chunk = pd.read_csv(path, skiprows=current_position, nrows=split_num_lines, header=None, names=columns)\n",
    "    if df_chunk.shape[0] == 0:\n",
    "        break\n",
    "    \n",
    "    df_chunk.columns= df_chunk.columns.str.lower()\n",
    "    y, y_proba = execute_model(df_chunk)\n",
    "    \n",
    "    mdf = pd.concat([\n",
    "        mdf,\n",
    "        pd.DataFrame({\n",
    "            'customer_id': df_chunk['customer_id'].values,\n",
    "            's_2': df_chunk['s_2'].values,\n",
    "            'pred': y,\n",
    "            'proba': y_proba\n",
    "        })\n",
    "    ])\n",
    "\n",
    "    current_position += split_num_lines\n",
    "    \n",
    "mdf.to_csv('./ignore/LR_all_stmt/logistic_regression_prediction.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve the last statement probability of each customer (test data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>s_2</th>\n",
       "      <th>pred</th>\n",
       "      <th>proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000469ba478561f23a92a868bd366de6f6527a684c9a2e78fb826dcac3b9b7</td>\n",
       "      <td>2019-02-19</td>\n",
       "      <td>0</td>\n",
       "      <td>0.231851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000469ba478561f23a92a868bd366de6f6527a684c9a2e78fb826dcac3b9b7</td>\n",
       "      <td>2019-03-25</td>\n",
       "      <td>0</td>\n",
       "      <td>0.145089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000469ba478561f23a92a868bd366de6f6527a684c9a2e78fb826dcac3b9b7</td>\n",
       "      <td>2019-04-25</td>\n",
       "      <td>0</td>\n",
       "      <td>0.157720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00000469ba478561f23a92a868bd366de6f6527a684c9a2e78fb826dcac3b9b7</td>\n",
       "      <td>2019-05-20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.213591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00000469ba478561f23a92a868bd366de6f6527a684c9a2e78fb826dcac3b9b7</td>\n",
       "      <td>2019-06-15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.151958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        customer_id  \\\n",
       "0  00000469ba478561f23a92a868bd366de6f6527a684c9a2e78fb826dcac3b9b7   \n",
       "1  00000469ba478561f23a92a868bd366de6f6527a684c9a2e78fb826dcac3b9b7   \n",
       "2  00000469ba478561f23a92a868bd366de6f6527a684c9a2e78fb826dcac3b9b7   \n",
       "3  00000469ba478561f23a92a868bd366de6f6527a684c9a2e78fb826dcac3b9b7   \n",
       "4  00000469ba478561f23a92a868bd366de6f6527a684c9a2e78fb826dcac3b9b7   \n",
       "\n",
       "         s_2  pred     proba  \n",
       "0 2019-02-19     0  0.231851  \n",
       "1 2019-03-25     0  0.145089  \n",
       "2 2019-04-25     0  0.157720  \n",
       "3 2019-05-20     0  0.213591  \n",
       "4 2019-06-15     0  0.151958  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the probabilities given by the model on test data\n",
    "df_results_all = pd.read_csv('./ignore/LR_all_stmt/logistic_regression_prediction.csv', parse_dates=['s_2'])\n",
    "df_results_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "924621"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_all['customer_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the last statement probability of each of the customer\n",
    "df_result_last = df_results_all.sort_values(by = 's_2').groupby('customer_id')[['customer_id','proba']].tail(1)\n",
    "df_result_last.rename(columns= {'proba' : 'prediction'},inplace=True)\n",
    "df_result_last.head()\n",
    "df_result_last.to_csv('./ignore/LR_all_stmt/last_stmt_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the mean of all the probabilities of the customer's statements (test data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7788240</th>\n",
       "      <td>af9da794a3ec613f9db1321559ffffcf6d5e0324b6f995b9bc5a83a3aba0d882</td>\n",
       "      <td>0.655435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4312152</th>\n",
       "      <td>615acaa0b35859ab76b13b3d5156acc6a208b8ec7b3b57da8288fbe82107af5b</td>\n",
       "      <td>0.213447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9146615</th>\n",
       "      <td>ce0e53cf2a7a180578e81a5e2446f8aac58e04a70d3f97bafde07a60be60167b</td>\n",
       "      <td>0.053694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11221584</th>\n",
       "      <td>fcc9e53e0d05e55eb177e7ac5c9712c32671749013b65787b2a01ab90b2c76b4</td>\n",
       "      <td>0.037584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3591564</th>\n",
       "      <td>50f5d28c9700f06722794aae605a1d784a1702db845b8d0b7bc90edda9c93539</td>\n",
       "      <td>0.026927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                               customer_id  \\\n",
       "7788240   af9da794a3ec613f9db1321559ffffcf6d5e0324b6f995b9bc5a83a3aba0d882   \n",
       "4312152   615acaa0b35859ab76b13b3d5156acc6a208b8ec7b3b57da8288fbe82107af5b   \n",
       "9146615   ce0e53cf2a7a180578e81a5e2446f8aac58e04a70d3f97bafde07a60be60167b   \n",
       "11221584  fcc9e53e0d05e55eb177e7ac5c9712c32671749013b65787b2a01ab90b2c76b4   \n",
       "3591564   50f5d28c9700f06722794aae605a1d784a1702db845b8d0b7bc90edda9c93539   \n",
       "\n",
       "             proba  \n",
       "7788240   0.655435  \n",
       "4312152   0.213447  \n",
       "9146615   0.053694  \n",
       "11221584  0.037584  \n",
       "3591564   0.026927  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tmp = df_results_all.sort_values(by = 's_2')[['customer_id','proba']]\n",
    "df_tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_allstmt_mean_prob = df_tmp.groupby('customer_id').mean()\n",
    "df_allstmt_mean_prob.reset_index(inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_allstmt_mean_prob.rename(columns= {'proba' : 'prediction'},inplace=True)\n",
    "df_allstmt_mean_prob.to_csv('./ignore/LR_all_stmt/mean_stmt_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted probabilities using Joe's Code (test data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the outcome weighting.\n",
    "\n",
    "def conditions(x):\n",
    "    # Customer has 3 statements:\n",
    "    if   x == 3:   return 0.1\n",
    "    elif x == 6:   return 0.15\n",
    "    elif x == 9:   return 0.75\n",
    "    \n",
    "    # Customer has 2 statements:\n",
    "    elif x == 2:   return 0.2\n",
    "    elif x == 4:   return 0.8\n",
    "    \n",
    "    # Customer has 1 statement:\n",
    "    elif x == 1:   return 1.0 \n",
    "    else:          return \"error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the last 3 statements of each customer\n",
    "mdf = df_results_all.sort_values('s_2').groupby('customer_id').tail(3)\n",
    "# if the customer has last 3 stmts the ranking will be as - 1st to the older stmt and 3rd rank to the latest stmt. \n",
    "mdf[\"statement_num\"] = mdf.groupby(\"customer_id\")[\"s_2\"].rank(method=\"first\", ascending=True)\n",
    "# The statement_count variable will give the count of the statements for each customer (i.e. to know if they have all the 3 or less than that)\n",
    "mdf['statement_count'] = mdf.groupby('customer_id')['statement_num'].transform('max')\n",
    "\n",
    "# Create a number so we can handle the case where a customer had only 1 or 2 statements. \n",
    "# Multiplied to give me a unique value for each case. See conditions() above.\n",
    "mdf['statement_checksum'] = (mdf['statement_count']) * mdf['statement_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the weights to the statements\n",
    "mdf['statement_weight'] = mdf['statement_checksum'].apply(conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the weighted sum\n",
    "mdf ['prediction'] = mdf['proba'] * mdf['statement_weight']\n",
    "\n",
    "mdf = mdf[['customer_id', 'prediction']]\n",
    "\n",
    "# Grouping those weighted sums by customer_id to give granularity of 1 proba per customer\n",
    "mdf = mdf.groupby('customer_id').sum()\n",
    "# Bring the customer_id from index to column\n",
    "mdf.reset_index(inplace=True)\n",
    "# Send the data to the file\n",
    "mdf.to_csv('./ignore/LR_all_stmt/weighted_stmt_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(high_pval_col.tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "89a73c21ecc9236fdbb84984cd9e615404f96fb7d0e8948f841b3ff5dee670ca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
