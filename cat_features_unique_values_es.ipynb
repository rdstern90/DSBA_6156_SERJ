{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## code to generate chunks for train data, repeat for test data csv ##\n",
    "\n",
    "chunksize = 100000\n",
    "\n",
    "part = 1\n",
    "with pd.read_csv('./ignore/test_data.csv', chunksize=chunksize) as reader:\n",
    "    for chunk in reader:\n",
    "        outpath = f'./ignore/small_parts_train/train_data_smallpart{part}.csv'\n",
    "        chunk.to_csv(outpath, index=False)\n",
    "        part += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features_list = ['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_63', 'D_64', 'D_66', 'D_68', 'B_31', 'D_87'] # sakshi\n",
    "#cat_features_list = ['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_63', 'D_64', 'D_66', 'D_68'] # kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['B_30', 3, [0.0, 1.0, 2.0]],\n",
       " ['B_38', 7, [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0]],\n",
       " ['D_114', 2, [0.0, 1.0]],\n",
       " ['D_116', 2, [0.0, 1.0]],\n",
       " ['D_117', 7, [-1.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0]],\n",
       " ['D_120', 2, [0.0, 1.0]],\n",
       " ['D_126', 3, [-1.0, 0.0, 1.0]],\n",
       " ['D_63', 6, ['CL', 'CO', 'CR', 'XL', 'XM', 'XZ']],\n",
       " ['D_64', 4, ['-1', 'O', 'R', 'U']],\n",
       " ['D_66', 2, [0.0, 1.0]],\n",
       " ['D_68', 7, [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0]],\n",
       " ['B_31', 2, [0, 1]],\n",
       " ['D_87', 1, [1.0]]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All of the train data (56 chunks)\n",
    "cat_unq_train = []\n",
    "for i in range(56):\n",
    "    path = f'./ignore/small_parts_train/train_data_smallpart{i+1}.csv'\n",
    "    df_temp = pd.read_csv(path)\n",
    "\n",
    "    j = 0\n",
    "    for col in cat_features_list:\n",
    "        if i == 0:\n",
    "            cat_unq_train.append([col, 0, list(df_temp[col].dropna().unique())])\n",
    "        else:\n",
    "            (cat_unq_train[j][2]).extend(list(df_temp[col].dropna().unique()))\n",
    "            cat_unq_train[j][2] = list(np.unique(np.array(cat_unq_train[j][2])))\n",
    "            cat_unq_train[j][1] = pd.Series(np.unique(np.array(cat_unq_train[j][2]))).nunique()\n",
    "        j+=1\n",
    "\n",
    "cat_unq_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['B_30', 3, [0.0, 1.0, 2.0]],\n",
       " ['B_38', 7, [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0]],\n",
       " ['D_114', 2, [0.0, 1.0]],\n",
       " ['D_116', 2, [0.0, 1.0]],\n",
       " ['D_117', 7, [-1.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0]],\n",
       " ['D_120', 2, [0.0, 1.0]],\n",
       " ['D_126', 3, [-1.0, 0.0, 1.0]],\n",
       " ['D_63', 6, ['CL', 'CO', 'CR', 'XL', 'XM', 'XZ']],\n",
       " ['D_64', 3, ['O', 'R', 'U']],\n",
       " ['D_66', 1, [1.0]],\n",
       " ['D_68', 6, [1.0, 2.0, 3.0, 4.0, 5.0, 6.0]],\n",
       " ['B_31', 2, [0, 1]],\n",
       " ['D_87', 1, [1.0]]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All of the test data (114 chunks)\n",
    "cat_unq_test = []\n",
    "for i in range(114):\n",
    "    path = f'./ignore/small_parts_test/test_data_smallpart{i+1}.csv'\n",
    "    df_temp = pd.read_csv(path)\n",
    "\n",
    "    j = 0\n",
    "    for col in cat_features_list:\n",
    "        if i == 0:\n",
    "            cat_unq_test.append([col, 0, list(df_temp[col].dropna().unique())])\n",
    "        else:\n",
    "            (cat_unq_test[j][2]).extend(list(df_temp[col].dropna().unique()))\n",
    "            cat_unq_test[j][2] = list(np.unique(np.array(cat_unq_test[j][2])))\n",
    "            cat_unq_test[j][1] = pd.Series(np.unique(np.array(cat_unq_test[j][2]))).nunique()\n",
    "        j+=1\n",
    "\n",
    "cat_unq_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfrs = pd.read_csv('./ignore/gcp_random10k_train_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['b_30', 3, [0.0, 2.0, 1.0]],\n",
       " ['b_38', 7, [2.0, 1.0, 3.0, 5.0, 4.0, 7.0, 6.0]],\n",
       " ['d_114', 2, [1.0, 0.0]],\n",
       " ['d_116', 2, [0.0, 1.0]],\n",
       " ['d_117', 7, [6.0, -1.0, 2.0, 1.0, 5.0, 4.0, 3.0]],\n",
       " ['d_120', 2, [0.0, 1.0]],\n",
       " ['d_126', 3, [1.0, 0.0, -1.0]],\n",
       " ['d_63', 6, ['CO', 'CR', 'CL', 'XZ', 'XL', 'XM']],\n",
       " ['d_64', 4, ['O', 'U', '-1', 'R']],\n",
       " ['d_66', 2, [1.0, 0.0]],\n",
       " ['d_68', 7, [5.0, 3.0, 2.0, 6.0, 4.0, 1.0, 0.0]],\n",
       " ['b_31', 2, [1, 0]],\n",
       " ['d_87', 1, [1.0]]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample train data from GCP\n",
    "cat_unq_rsample = []\n",
    "\n",
    "j = 0\n",
    "for col in list(pd.Series(cat_features_list).str.lower()):\n",
    "    cat_unq_rsample.append([col, dfrs[col].nunique(), list(dfrs[col].dropna().unique())])\n",
    "\n",
    "cat_unq_rsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrs = [cat_unq_rsample, cat_unq_train, cat_unq_test]\n",
    "nunqs = ['column: sample: all train: all test:']\n",
    "for  cols in range(len(cat_unq_rsample)):\n",
    "    nunqs.append([cat_unq_rsample[cols][0], cat_unq_rsample[cols][1], cat_unq_train[cols][1], cat_unq_test[cols][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['column: sample: all train: all test:',\n",
       " ['b_30', 3, 3, 3],\n",
       " ['b_38', 7, 7, 7],\n",
       " ['d_114', 2, 2, 2],\n",
       " ['d_116', 2, 2, 2],\n",
       " ['d_117', 7, 7, 7],\n",
       " ['d_120', 2, 2, 2],\n",
       " ['d_126', 3, 3, 3],\n",
       " ['d_63', 6, 6, 6],\n",
       " ['d_64', 4, 4, 3],\n",
       " ['d_66', 2, 2, 1],\n",
       " ['d_68', 7, 7, 6],\n",
       " ['b_31', 2, 2, 2],\n",
       " ['d_87', 1, 1, 1]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique categorical values\n",
    "nunqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d64: value only present in train set: -1\n",
      "d66: value only present in train set: 0.0\n",
      "d68: value only present in train set: 0.0\n"
     ]
    }
   ],
   "source": [
    "# values in train dataset but NOT IN test dataset\n",
    "\n",
    "d64 = list(np.concatenate([cat_unq_train[8][2], cat_unq_test[8][2]]))\n",
    "d66 = list(np.concatenate([cat_unq_train[9][2], cat_unq_test[9][2]]))\n",
    "d68 = list(np.concatenate([cat_unq_train[10][2], cat_unq_test[10][2]]))\n",
    "\n",
    "for i in range(len(d64)):\n",
    "    temp = d64.copy()\n",
    "    temp.remove(d64[i])\n",
    "    if d64[i] not in temp:\n",
    "        print('d64: value only present in train set:', d64[i])\n",
    "        d64[i]\n",
    "\n",
    "for i in range(len(d66)):\n",
    "    temp = d66.copy()\n",
    "    temp.remove(d66[i])\n",
    "    if d66[i] not in temp:\n",
    "        print('d66: value only present in train set:', d66[i])\n",
    "\n",
    "for i in range(len(d68)):\n",
    "    temp = d68.copy()\n",
    "    temp.remove(d68[i])\n",
    "    if d68[i] not in temp:\n",
    "        print('d68: value only present in train set:', d68[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "records to drop: 0.743 %\n"
     ]
    }
   ],
   "source": [
    "#check proportion of records in gcp training sample..\n",
    "# with either d_64 == -1, d_66 == 0 or d_68 == 0\n",
    "\n",
    "#print(100*len(dfrs[dfrs['d_64']=='-1'])/len(dfrs), '%')\n",
    "#print(100*len(dfrs[dfrs['d_66']==0])/len(dfrs), '%')\n",
    "#print(100*len(dfrs[dfrs['d_68']==0])/len(dfrs), '%')\n",
    "\n",
    "dfrs_reduced = dfrs[dfrs['d_64']!='-1']\n",
    "dfrs_reduced = dfrs_reduced[dfrs_reduced['d_66']!=0]\n",
    "dfrs_reduced = dfrs_reduced[dfrs_reduced['d_68']!=0]\n",
    "\n",
    "print('records to drop:', round(100*(1-len(dfrs_reduced)/len(dfrs)),3), '%')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f6b15828e38435dc0130cb820d476724eb9da0616a1f96736a4295695b7d921"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
