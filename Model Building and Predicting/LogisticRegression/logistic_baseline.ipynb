{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If the customer has default assigning all statements the value 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report,confusion_matrix,roc_curve,roc_auc_score, accuracy_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read training data \n",
    "df_train_x = pd.read_parquet('../data/train.parquet')\n",
    "df_train_x.columns = df_train_x.columns.str.lower()\n",
    "# Read training data labels\n",
    "df_train_y = pd.read_csv('../data/train_labels.csv')\n",
    "df_train_y.columns = df_train_y.columns.str.lower()\n",
    "df_train_y = df_train_y.set_index('customer_id')\n",
    "\n",
    "df_train_x = df_train_x.sort_values(['customer_id', 's_2'])\n",
    "df_train = pd.merge(df_train_x, df_train_y, on='customer_id')\n",
    "del(df_train_x, df_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>s_2</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0000f99513770170a1aba690daeeb8a96da4a39f11fc27...</td>\n",
       "      <td>2017-03-15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0000f99513770170a1aba690daeeb8a96da4a39f11fc27...</td>\n",
       "      <td>2017-04-14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0000f99513770170a1aba690daeeb8a96da4a39f11fc27...</td>\n",
       "      <td>2017-05-15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0000f99513770170a1aba690daeeb8a96da4a39f11fc27...</td>\n",
       "      <td>2017-06-14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0000f99513770170a1aba690daeeb8a96da4a39f11fc27...</td>\n",
       "      <td>2017-07-15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0000f99513770170a1aba690daeeb8a96da4a39f11fc27...</td>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0000f99513770170a1aba690daeeb8a96da4a39f11fc27...</td>\n",
       "      <td>2017-09-14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0000f99513770170a1aba690daeeb8a96da4a39f11fc27...</td>\n",
       "      <td>2017-10-14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0000f99513770170a1aba690daeeb8a96da4a39f11fc27...</td>\n",
       "      <td>2017-11-14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0000f99513770170a1aba690daeeb8a96da4a39f11fc27...</td>\n",
       "      <td>2017-12-17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0000f99513770170a1aba690daeeb8a96da4a39f11fc27...</td>\n",
       "      <td>2018-01-17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0000f99513770170a1aba690daeeb8a96da4a39f11fc27...</td>\n",
       "      <td>2018-02-05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0000f99513770170a1aba690daeeb8a96da4a39f11fc27...</td>\n",
       "      <td>2018-03-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           customer_id         s_2  target\n",
       "104  0000f99513770170a1aba690daeeb8a96da4a39f11fc27...  2017-03-15       1\n",
       "105  0000f99513770170a1aba690daeeb8a96da4a39f11fc27...  2017-04-14       1\n",
       "106  0000f99513770170a1aba690daeeb8a96da4a39f11fc27...  2017-05-15       1\n",
       "107  0000f99513770170a1aba690daeeb8a96da4a39f11fc27...  2017-06-14       1\n",
       "108  0000f99513770170a1aba690daeeb8a96da4a39f11fc27...  2017-07-15       1\n",
       "109  0000f99513770170a1aba690daeeb8a96da4a39f11fc27...  2017-08-15       1\n",
       "110  0000f99513770170a1aba690daeeb8a96da4a39f11fc27...  2017-09-14       1\n",
       "111  0000f99513770170a1aba690daeeb8a96da4a39f11fc27...  2017-10-14       1\n",
       "112  0000f99513770170a1aba690daeeb8a96da4a39f11fc27...  2017-11-14       1\n",
       "113  0000f99513770170a1aba690daeeb8a96da4a39f11fc27...  2017-12-17       1\n",
       "114  0000f99513770170a1aba690daeeb8a96da4a39f11fc27...  2018-01-17       1\n",
       "115  0000f99513770170a1aba690daeeb8a96da4a39f11fc27...  2018-02-05       1\n",
       "116  0000f99513770170a1aba690daeeb8a96da4a39f11fc27...  2018-03-01       1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train['customer_id']== '0000f99513770170a1aba690daeeb8a96da4a39f11fc27da5c30a79db61c1e85'][['customer_id','s_2','target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before doing any transformation see the datatypes of the features\n",
    "df_train.dtypes.to_csv('../ignore/final/before_transformations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "d_63     0.0\n",
       "d_64     0.0\n",
       "d_66     0.0\n",
       "d_68     0.0\n",
       "b_30     0.0\n",
       "b_31     0.0\n",
       "b_38     0.0\n",
       "d_114    0.0\n",
       "d_116    0.0\n",
       "d_117    0.0\n",
       "d_120    0.0\n",
       "d_126    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline(steps=[])\n",
    "# 89% of d_66 column values were missing, but it has been filled with -1 while parquet generation.\n",
    "# Also assign the column names in sequence in which it appars in the file  \n",
    "categorical_cols = ['d_63', 'd_64', 'd_66', 'd_68', 'b_30', 'b_31', 'b_38', 'd_114', 'd_116',\n",
    "                     'd_117', 'd_120', 'd_126']\n",
    "df_train[categorical_cols].isnull().sum() / len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the percentage of missing values\n",
    "null_series = df_train.isna().sum() / df_train.shape[0]\n",
    "null_series.to_csv('../ignore/final/column_null_values_prop.csv')\n",
    "del null_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The unique values for column d_63 is [0 3 4 1 2 5]\n",
      "The unique values for column d_64 is [ 0  2 -1  3  1]\n",
      "The unique values for column d_66 is [-1  1  0]\n",
      "The unique values for column d_68 is [ 6  2  3 -1  5  4  0  1]\n",
      "The unique values for column b_30 is [ 0  2  1 -1]\n",
      "The unique values for column b_31 is [1 0]\n",
      "The unique values for column b_38 is [ 2  1  3  5  6  7  4 -1]\n",
      "The unique values for column d_114 is [ 1  0 -1]\n",
      "The unique values for column d_116 is [ 0 -1  1]\n",
      "The unique values for column d_117 is [ 5  0  7  3  2 -1  4  6]\n",
      "The unique values for column d_120 is [ 0  1 -1]\n",
      "The unique values for column d_126 is [ 2 -1  1  0]\n"
     ]
    }
   ],
   "source": [
    "# Check for the unique values for all the categorical features\n",
    "for i in categorical_cols:\n",
    "    print(f'The unique values for column {i} is {df_train[i].unique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the original file is:(5531451, 191)\n"
     ]
    }
   ],
   "source": [
    "print(f'The shape of the original file is:{df_train.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/pipelines-custom-transformers-in-scikit-learn-the-step-by-step-guide-with-python-code-4a7d9b068156"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreProcessing(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, categorical_cols):\n",
    "        self.categorical_cols = categorical_cols\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Get the list of columns that have missing values greater than equal to 40%\n",
    "        missing_perc = round((X.isnull().sum() / len(X)) * 100, 2)\n",
    "        # Prepare final List of columns to drop\n",
    "        self.cols_to_drop = missing_perc[missing_perc.ge(40)].index.tolist()\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        numeric_cols = list(set(X.columns.tolist(\n",
    "        )) - set(self.categorical_cols + self.cols_to_drop + ['target', 'customer_id', 's_2']))\n",
    "\n",
    "        # Impute the mean of the numeric columns\n",
    "        for col in numeric_cols:\n",
    "            # Check if the column has any null value, then only apply the imputation\n",
    "            if X[col].isnull().any():\n",
    "                X[col] = X[col].fillna(X[col].mean())\n",
    "                            \n",
    "            # Scale\n",
    "            mean = X[col].mean()\n",
    "            std = X[col].std()\n",
    "            if std > 0:\n",
    "                X[col] = ((X[col] - mean) / std).astype('float32')\n",
    "\n",
    "        X = X.drop(columns = self.cols_to_drop)\n",
    "\n",
    "        return X\n",
    "\n",
    "# use all the statements of a customer where all stmts are marked with the same target value\n",
    "preprocessing = PreProcessing(categorical_cols)\n",
    "df_processed = preprocessing.fit_transform(df_train)\n",
    "\n",
    "pipeline.steps.append(('preprocessing', preprocessing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After processing the shape is :(5531451, 173)\n"
     ]
    }
   ],
   "source": [
    "del (df_train)\n",
    "print(f'After processing the shape is :{df_processed.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check the correlation for the numeric columns\n",
    "# df_corr = df_processed.drop(columns = categorical_cols + ['target','customer_id','s_2']).corr()\n",
    "# df_corr.to_csv(\"../ignore/final/num_corr_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# def sklearn_vif(data):\n",
    "\n",
    "#     # initialize dictionaries\n",
    "#     result = {}\n",
    "\n",
    "#     # form input data for each exogenous variable\n",
    "#     exogs = data.columns.to_list()\n",
    "#     for exog in exogs:\n",
    "#         # print(exog)\n",
    "#         not_exog = [i for i in exogs if i != exog]\n",
    "#         # exog would be for which the VIF has to be calculated based on the combination of other columns\n",
    "#         X, y = data[not_exog], data[exog]  \n",
    "#         # extract r-squared from the fit\n",
    "#         r_squared = LinearRegression(n_jobs=12).fit(X, y).score(X, y)\n",
    "\n",
    "#         # calculate VIF\n",
    "#         vif = 1/(1 - r_squared)\n",
    "#         result[exog] = vif\n",
    "#     return result\n",
    "\n",
    "# vif_data1 = sklearn_vif(df_processed.drop(columns = categorical_cols + ['target','customer_id','s_2']))\n",
    "# # Convert the results from the dictionary to dataframe\n",
    "# df_vif = pd.DataFrame({\n",
    "#     'feature': vif_data1.keys(),\n",
    "#     'VIF': vif_data1.values()\n",
    "# })\n",
    "# del(vif_data1)\n",
    "# df_vif.to_csv(\"../ignore/final/num_VIF_data_results.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vif = pd.read_csv(\"../ignore/final/num_VIF_data_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The remaining columns of the data after dropping columns with high VIF : 144\n"
     ]
    }
   ],
   "source": [
    "# Plainly drop all the columns with higher VIF values\n",
    "df_processed.drop(columns = df_vif[df_vif['VIF']> 11]['feature'].to_list(), inplace=True)\n",
    "print(f'The remaining columns of the data after dropping columns with high VIF : {df_processed.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df_processed.drop(columns=['target','customer_id','s_2']), df_processed['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.2, random_state=2303, stratify = y)\n",
    "# del(df_processed, X, y)                                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.284925\n",
      "         Iterations 8\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                 target   No. Observations:              4425160\n",
      "Model:                          Logit   Df Residuals:                  4425019\n",
      "Method:                           MLE   Df Model:                          140\n",
      "Date:                Sat, 03 Dec 2022   Pseudo R-squ.:                  0.4924\n",
      "Time:                        21:54:29   Log-Likelihood:            -1.2608e+06\n",
      "converged:                       True   LL-Null:                   -2.4840e+06\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "p_2           -0.8067      0.003   -230.818      0.000      -0.814      -0.800\n",
      "d_39           0.1150      0.002     62.569      0.000       0.111       0.119\n",
      "r_1            0.0952      0.004     22.286      0.000       0.087       0.104\n",
      "s_3            0.1246      0.003     36.484      0.000       0.118       0.131\n",
      "d_41           0.0938      0.002     38.148      0.000       0.089       0.099\n",
      "b_3            0.2453      0.003     93.856      0.000       0.240       0.250\n",
      "d_43           0.1046      0.002     45.886      0.000       0.100       0.109\n",
      "d_44           0.0133      0.002      5.740      0.000       0.009       0.018\n",
      "b_4            0.3030      0.002    133.621      0.000       0.299       0.307\n",
      "d_45          -0.1110      0.004    -31.167      0.000      -0.118      -0.104\n",
      "b_5           -0.0824      0.004    -19.782      0.000      -0.091      -0.074\n",
      "r_2            0.0288      0.003      9.296      0.000       0.023       0.035\n",
      "d_46           0.1400      0.002     74.572      0.000       0.136       0.144\n",
      "d_47          -0.1730      0.003    -61.199      0.000      -0.179      -0.167\n",
      "d_48           0.0920      0.004     25.987      0.000       0.085       0.099\n",
      "d_49           0.0555      0.002     26.073      0.000       0.051       0.060\n",
      "b_6           -0.1266      0.010    -12.568      0.000      -0.146      -0.107\n",
      "b_8            0.1800      0.003     65.176      0.000       0.175       0.185\n",
      "d_51          -0.2502      0.004    -65.763      0.000      -0.258      -0.243\n",
      "b_9            0.0834      0.002     39.899      0.000       0.079       0.088\n",
      "r_3            0.1811      0.002     82.949      0.000       0.177       0.185\n",
      "d_52          -0.0586      0.002    -29.009      0.000      -0.063      -0.055\n",
      "p_3            0.0639      0.002     34.031      0.000       0.060       0.068\n",
      "b_10          -0.0012      0.002     -0.602      0.547      -0.005       0.003\n",
      "s_5            0.0241      0.002     14.187      0.000       0.021       0.027\n",
      "s_6            0.0475      0.002     20.716      0.000       0.043       0.052\n",
      "d_54          -0.0406      0.002    -24.409      0.000      -0.044      -0.037\n",
      "r_4            0.0367      0.003     11.498      0.000       0.030       0.043\n",
      "s_7            0.0517      0.003     14.963      0.000       0.045       0.058\n",
      "b_12          -0.0786      0.008     -9.833      0.000      -0.094      -0.063\n",
      "s_8           -0.0934      0.004    -24.737      0.000      -0.101      -0.086\n",
      "d_55          -0.0258      0.004     -7.338      0.000      -0.033      -0.019\n",
      "b_13           0.0764      0.006     13.689      0.000       0.066       0.087\n",
      "d_59          -0.0461      0.002    -26.119      0.000      -0.050      -0.043\n",
      "d_60           0.1315      0.003     50.831      0.000       0.126       0.137\n",
      "d_61           0.0648      0.005     14.223      0.000       0.056       0.074\n",
      "s_11          -0.1057      0.002    -54.610      0.000      -0.109      -0.102\n",
      "d_62          -0.2394      0.004    -66.619      0.000      -0.246      -0.232\n",
      "d_63          -0.0142      0.002     -7.452      0.000      -0.018      -0.010\n",
      "d_64           0.0180      0.001     12.181      0.000       0.015       0.021\n",
      "d_65           0.0201      0.002      8.905      0.000       0.016       0.025\n",
      "b_16           0.1875      0.004     46.659      0.000       0.180       0.195\n",
      "b_18          -0.3132      0.004    -79.956      0.000      -0.321      -0.306\n",
      "b_19           0.0924      0.003     36.546      0.000       0.087       0.097\n",
      "d_66          -0.1737      0.003    -61.160      0.000      -0.179      -0.168\n",
      "b_20          -0.2296      0.003    -66.152      0.000      -0.236      -0.223\n",
      "d_68          -0.0337      0.001    -22.597      0.000      -0.037      -0.031\n",
      "s_12           0.0432      0.002     24.930      0.000       0.040       0.047\n",
      "r_6            0.0124      0.002      5.964      0.000       0.008       0.016\n",
      "s_13           0.0647      0.003     21.896      0.000       0.059       0.070\n",
      "b_21           0.0251      0.002     10.165      0.000       0.020       0.030\n",
      "d_69           0.0009      0.001      0.901      0.368      -0.001       0.003\n",
      "b_22           0.0353      0.002     14.359      0.000       0.030       0.040\n",
      "d_70           0.0563      0.002     34.440      0.000       0.053       0.059\n",
      "d_71          -0.0430      0.006     -6.855      0.000      -0.055      -0.031\n",
      "d_72          -0.0149      0.002     -7.302      0.000      -0.019      -0.011\n",
      "s_15           0.0262      0.003     10.086      0.000       0.021       0.031\n",
      "p_4            0.1307      0.002     65.063      0.000       0.127       0.135\n",
      "b_24          -0.0069      0.003     -2.532      0.011      -0.012      -0.002\n",
      "r_7            0.0015      0.002      0.852      0.394      -0.002       0.005\n",
      "b_26           0.0093      0.002      4.905      0.000       0.006       0.013\n",
      "d_78          -0.0188      0.002     -9.907      0.000      -0.023      -0.015\n",
      "d_79          -0.0148      0.003     -5.426      0.000      -0.020      -0.009\n",
      "r_9            0.0070      0.001      4.706      0.000       0.004       0.010\n",
      "s_16           0.0032      0.002      1.727      0.084      -0.000       0.007\n",
      "d_80           0.0202      0.002     11.786      0.000       0.017       0.024\n",
      "r_10           0.0033      0.003      1.264      0.206      -0.002       0.008\n",
      "r_11           0.0623      0.001     42.274      0.000       0.059       0.065\n",
      "b_27           0.0017      0.002      1.063      0.288      -0.001       0.005\n",
      "d_81          -0.0002      0.002     -0.102      0.919      -0.005       0.004\n",
      "d_82           0.0998      0.003     39.575      0.000       0.095       0.105\n",
      "s_17           0.0107      0.001      7.583      0.000       0.008       0.014\n",
      "r_12          -0.0219      0.002    -10.826      0.000      -0.026      -0.018\n",
      "d_83           0.0106      0.001      7.115      0.000       0.008       0.014\n",
      "r_14           0.0125      0.002      7.737      0.000       0.009       0.016\n",
      "r_15           0.0053      0.002      2.670      0.008       0.001       0.009\n",
      "d_84           0.0099      0.003      3.239      0.001       0.004       0.016\n",
      "r_16          -0.0310      0.002    -16.604      0.000      -0.035      -0.027\n",
      "b_30           0.0184      0.006      3.180      0.001       0.007       0.030\n",
      "s_18           0.0295      0.002     16.689      0.000       0.026       0.033\n",
      "d_86          -0.0596      0.002    -26.186      0.000      -0.064      -0.055\n",
      "d_87          -0.0039      0.002     -2.408      0.016      -0.007      -0.001\n",
      "r_18          -0.0042      0.001     -3.274      0.001      -0.007      -0.002\n",
      "b_31          -2.0140      0.012   -173.571      0.000      -2.037      -1.991\n",
      "s_19           0.0087      0.002      5.607      0.000       0.006       0.012\n",
      "r_19          -0.0327      0.001    -22.228      0.000      -0.036      -0.030\n",
      "b_32          -0.0274      0.001    -19.837      0.000      -0.030      -0.025\n",
      "s_20           0.0193      0.002      8.830      0.000       0.015       0.024\n",
      "r_20          -0.0100      0.003     -3.779      0.000      -0.015      -0.005\n",
      "r_21           0.0330      0.003     12.812      0.000       0.028       0.038\n",
      "d_89          -0.0410      0.002    -18.966      0.000      -0.045      -0.037\n",
      "r_22          -0.0129      0.001    -10.203      0.000      -0.015      -0.010\n",
      "r_23           0.0138      0.001     10.351      0.000       0.011       0.016\n",
      "d_91          -0.0574      0.003    -19.640      0.000      -0.063      -0.052\n",
      "d_92           0.0185      0.004      4.873      0.000       0.011       0.026\n",
      "d_93           0.0217      0.002      9.538      0.000       0.017       0.026\n",
      "d_94          -0.0181      0.004     -4.078      0.000      -0.027      -0.009\n",
      "r_24          -0.0088      0.003     -3.239      0.001      -0.014      -0.003\n",
      "r_25          -0.0344      0.002    -17.317      0.000      -0.038      -0.030\n",
      "d_96          -0.0313      0.002    -14.123      0.000      -0.036      -0.027\n",
      "s_23           0.0065      0.003      2.304      0.021       0.001       0.012\n",
      "s_25        6.679e-05      0.001      0.049      0.961      -0.003       0.003\n",
      "s_26          -0.0234      0.003     -6.776      0.000      -0.030      -0.017\n",
      "d_102         -0.0264      0.002    -13.034      0.000      -0.030      -0.022\n",
      "d_106          0.0009      0.003      0.343      0.731      -0.004       0.006\n",
      "d_107          0.0279      0.002     13.774      0.000       0.024       0.032\n",
      "b_36           0.0119      0.002      5.031      0.000       0.007       0.017\n",
      "r_26           0.0206      0.002     10.289      0.000       0.017       0.025\n",
      "r_27          -0.1035      0.002    -64.697      0.000      -0.107      -0.100\n",
      "b_38          -0.0077      0.001     -5.203      0.000      -0.011      -0.005\n",
      "d_108          0.0201      0.001     14.126      0.000       0.017       0.023\n",
      "d_109         -0.0110      0.002     -4.616      0.000      -0.016      -0.006\n",
      "d_111          0.0641      0.002     26.983      0.000       0.059       0.069\n",
      "d_112         -0.1268      0.002    -63.710      0.000      -0.131      -0.123\n",
      "b_40           0.0018      0.002      0.968      0.333      -0.002       0.006\n",
      "s_27          -0.0349      0.001    -24.974      0.000      -0.038      -0.032\n",
      "d_113         -0.0145      0.002     -6.496      0.000      -0.019      -0.010\n",
      "d_114         -0.1306      0.004    -29.476      0.000      -0.139      -0.122\n",
      "d_115         -0.0501      0.003    -18.286      0.000      -0.055      -0.045\n",
      "d_116          0.0460      0.018      2.604      0.009       0.011       0.081\n",
      "d_117         -0.0222      0.001    -27.541      0.000      -0.024      -0.021\n",
      "d_120          0.0241      0.005      4.956      0.000       0.015       0.034\n",
      "d_121          0.1626      0.003     55.042      0.000       0.157       0.168\n",
      "d_122         -0.0172      0.002     -6.911      0.000      -0.022      -0.012\n",
      "d_123          0.0153      0.002      6.671      0.000       0.011       0.020\n",
      "d_124          0.0358      0.002     16.406      0.000       0.032       0.040\n",
      "d_125          0.0116      0.002      5.306      0.000       0.007       0.016\n",
      "d_126         -0.0151      0.003     -5.013      0.000      -0.021      -0.009\n",
      "d_127         -0.1006      0.004    -25.052      0.000      -0.108      -0.093\n",
      "d_128         -0.0217      0.003     -8.318      0.000      -0.027      -0.017\n",
      "d_129         -0.1419      0.003    -54.896      0.000      -0.147      -0.137\n",
      "b_41           0.0295      0.002     17.114      0.000       0.026       0.033\n",
      "d_130          0.0252      0.002     12.412      0.000       0.021       0.029\n",
      "d_131          0.1835      0.003     56.055      0.000       0.177       0.190\n",
      "d_133         -0.1101      0.002    -54.788      0.000      -0.114      -0.106\n",
      "r_28           0.0022      0.001      1.865      0.062      -0.000       0.005\n",
      "d_136         -0.0029      0.002     -1.364      0.173      -0.007       0.001\n",
      "d_138          0.0372      0.002     17.844      0.000       0.033       0.041\n",
      "d_140          0.0158      0.001     11.572      0.000       0.013       0.019\n",
      "d_144         -0.0280      0.002    -17.299      0.000      -0.031      -0.025\n",
      "d_145         -0.0087      0.001     -6.121      0.000      -0.011      -0.006\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "sm_logit1 = sm.Logit(y_train,X_train).fit()\n",
    "print(sm_logit1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The columns remaining after removing insignificant ones : (5531451, 129)\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.284926\n",
      "         Iterations 8\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                 target   No. Observations:              4425160\n",
      "Model:                          Logit   Df Residuals:                  4425031\n",
      "Method:                           MLE   Df Model:                          128\n",
      "Date:                Sat, 03 Dec 2022   Pseudo R-squ.:                  0.4924\n",
      "Time:                        21:57:05   Log-Likelihood:            -1.2608e+06\n",
      "converged:                       True   LL-Null:                   -2.4840e+06\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "p_2           -0.8067      0.003   -232.989      0.000      -0.813      -0.800\n",
      "d_39           0.1150      0.002     62.587      0.000       0.111       0.119\n",
      "r_1            0.0997      0.003     36.918      0.000       0.094       0.105\n",
      "s_3            0.1253      0.003     36.807      0.000       0.119       0.132\n",
      "d_41           0.0939      0.002     38.209      0.000       0.089       0.099\n",
      "b_3            0.2452      0.003     93.884      0.000       0.240       0.250\n",
      "d_43           0.1045      0.002     45.894      0.000       0.100       0.109\n",
      "d_44           0.0135      0.002      5.892      0.000       0.009       0.018\n",
      "b_4            0.3030      0.002    133.738      0.000       0.299       0.307\n",
      "d_45          -0.1110      0.004    -31.172      0.000      -0.118      -0.104\n",
      "b_5           -0.0823      0.004    -19.771      0.000      -0.090      -0.074\n",
      "r_2            0.0288      0.003      9.281      0.000       0.023       0.035\n",
      "d_46           0.1400      0.002     74.877      0.000       0.136       0.144\n",
      "d_47          -0.1730      0.003    -61.201      0.000      -0.179      -0.167\n",
      "d_48           0.0920      0.004     25.999      0.000       0.085       0.099\n",
      "d_49           0.0557      0.002     27.012      0.000       0.052       0.060\n",
      "b_6           -0.1270      0.010    -12.624      0.000      -0.147      -0.107\n",
      "b_8            0.1799      0.003     65.163      0.000       0.175       0.185\n",
      "d_51          -0.2501      0.004    -65.772      0.000      -0.258      -0.243\n",
      "b_9            0.0834      0.002     40.063      0.000       0.079       0.087\n",
      "r_3            0.1810      0.002     82.961      0.000       0.177       0.185\n",
      "d_52          -0.0585      0.002    -28.998      0.000      -0.062      -0.055\n",
      "p_3            0.0640      0.002     34.119      0.000       0.060       0.068\n",
      "s_5            0.0241      0.002     14.179      0.000       0.021       0.027\n",
      "s_6            0.0475      0.002     20.755      0.000       0.043       0.052\n",
      "d_54          -0.0406      0.002    -24.422      0.000      -0.044      -0.037\n",
      "r_4            0.0353      0.003     11.879      0.000       0.029       0.041\n",
      "s_7            0.0512      0.003     14.870      0.000       0.044       0.058\n",
      "b_12          -0.0783      0.008     -9.807      0.000      -0.094      -0.063\n",
      "s_8           -0.0935      0.004    -24.765      0.000      -0.101      -0.086\n",
      "d_55          -0.0259      0.004     -7.381      0.000      -0.033      -0.019\n",
      "b_13           0.0763      0.006     13.662      0.000       0.065       0.087\n",
      "d_59          -0.0461      0.002    -26.131      0.000      -0.050      -0.043\n",
      "d_60           0.1315      0.003     50.867      0.000       0.126       0.137\n",
      "d_61           0.0649      0.005     14.235      0.000       0.056       0.074\n",
      "s_11          -0.1057      0.002    -54.597      0.000      -0.109      -0.102\n",
      "d_62          -0.2395      0.004    -66.670      0.000      -0.247      -0.232\n",
      "d_63          -0.0142      0.002     -7.481      0.000      -0.018      -0.010\n",
      "d_64           0.0180      0.001     12.179      0.000       0.015       0.021\n",
      "d_65           0.0201      0.002      8.893      0.000       0.016       0.024\n",
      "b_16           0.1874      0.004     46.643      0.000       0.180       0.195\n",
      "b_18          -0.3132      0.004    -80.032      0.000      -0.321      -0.306\n",
      "b_19           0.0927      0.003     36.748      0.000       0.088       0.098\n",
      "d_66          -0.1737      0.003    -61.179      0.000      -0.179      -0.168\n",
      "b_20          -0.2294      0.003    -66.175      0.000      -0.236      -0.223\n",
      "d_68          -0.0338      0.001    -22.604      0.000      -0.037      -0.031\n",
      "s_12           0.0432      0.002     24.921      0.000       0.040       0.047\n",
      "r_6            0.0133      0.002      7.590      0.000       0.010       0.017\n",
      "s_13           0.0646      0.003     21.882      0.000       0.059       0.070\n",
      "b_21           0.0270      0.002     12.093      0.000       0.023       0.031\n",
      "b_22           0.0352      0.002     14.329      0.000       0.030       0.040\n",
      "d_70           0.0562      0.002     34.428      0.000       0.053       0.059\n",
      "d_71          -0.0430      0.006     -6.850      0.000      -0.055      -0.031\n",
      "d_72          -0.0149      0.002     -7.909      0.000      -0.019      -0.011\n",
      "s_15           0.0261      0.003     10.040      0.000       0.021       0.031\n",
      "p_4            0.1308      0.002     65.149      0.000       0.127       0.135\n",
      "b_24          -0.0068      0.003     -2.513      0.012      -0.012      -0.002\n",
      "b_26           0.0094      0.002      4.950      0.000       0.006       0.013\n",
      "d_78          -0.0185      0.002     -9.871      0.000      -0.022      -0.015\n",
      "d_79          -0.0148      0.003     -5.424      0.000      -0.020      -0.009\n",
      "r_9            0.0070      0.001      4.796      0.000       0.004       0.010\n",
      "d_80           0.0202      0.002     11.799      0.000       0.017       0.024\n",
      "r_11           0.0622      0.001     42.248      0.000       0.059       0.065\n",
      "d_82           0.0997      0.003     39.574      0.000       0.095       0.105\n",
      "s_17           0.0106      0.001      7.493      0.000       0.008       0.013\n",
      "r_12          -0.0219      0.002    -10.823      0.000      -0.026      -0.018\n",
      "d_83           0.0106      0.001      7.155      0.000       0.008       0.014\n",
      "r_14           0.0122      0.002      7.744      0.000       0.009       0.015\n",
      "r_15           0.0040      0.002      2.303      0.021       0.001       0.007\n",
      "d_84           0.0099      0.003      3.235      0.001       0.004       0.016\n",
      "r_16          -0.0312      0.002    -16.729      0.000      -0.035      -0.028\n",
      "b_30           0.0180      0.006      3.115      0.002       0.007       0.029\n",
      "s_18           0.0294      0.002     16.675      0.000       0.026       0.033\n",
      "d_86          -0.0596      0.002    -26.185      0.000      -0.064      -0.055\n",
      "d_87          -0.0040      0.002     -2.421      0.015      -0.007      -0.001\n",
      "r_18          -0.0042      0.001     -3.336      0.001      -0.007      -0.002\n",
      "b_31          -2.0136      0.012   -173.573      0.000      -2.036      -1.991\n",
      "s_19           0.0089      0.002      5.747      0.000       0.006       0.012\n",
      "r_19          -0.0333      0.001    -24.051      0.000      -0.036      -0.031\n",
      "b_32          -0.0275      0.001    -19.889      0.000      -0.030      -0.025\n",
      "s_20           0.0191      0.002      8.758      0.000       0.015       0.023\n",
      "r_20          -0.0101      0.003     -3.812      0.000      -0.015      -0.005\n",
      "r_21           0.0324      0.002     13.628      0.000       0.028       0.037\n",
      "d_89          -0.0411      0.002    -20.418      0.000      -0.045      -0.037\n",
      "r_22          -0.0132      0.001    -10.645      0.000      -0.016      -0.011\n",
      "r_23           0.0138      0.001     10.297      0.000       0.011       0.016\n",
      "d_91          -0.0574      0.003    -19.648      0.000      -0.063      -0.052\n",
      "d_92           0.0185      0.004      4.895      0.000       0.011       0.026\n",
      "d_93           0.0216      0.002      9.530      0.000       0.017       0.026\n",
      "d_94          -0.0182      0.004     -4.081      0.000      -0.027      -0.009\n",
      "r_24          -0.0100      0.003     -3.884      0.000      -0.015      -0.005\n",
      "r_25          -0.0347      0.002    -17.553      0.000      -0.039      -0.031\n",
      "d_96          -0.0313      0.002    -14.109      0.000      -0.036      -0.027\n",
      "s_23           0.0066      0.003      2.312      0.021       0.001       0.012\n",
      "s_26          -0.0234      0.003     -6.767      0.000      -0.030      -0.017\n",
      "d_102         -0.0264      0.002    -13.032      0.000      -0.030      -0.022\n",
      "d_107          0.0279      0.002     13.774      0.000       0.024       0.032\n",
      "b_36           0.0119      0.002      5.041      0.000       0.007       0.017\n",
      "r_26           0.0206      0.002     10.274      0.000       0.017       0.024\n",
      "r_27          -0.1035      0.002    -64.696      0.000      -0.107      -0.100\n",
      "b_38          -0.0077      0.001     -5.236      0.000      -0.011      -0.005\n",
      "d_108          0.0201      0.001     14.097      0.000       0.017       0.023\n",
      "d_109         -0.0110      0.002     -4.610      0.000      -0.016      -0.006\n",
      "d_111          0.0640      0.002     26.950      0.000       0.059       0.069\n",
      "d_112         -0.1268      0.002    -63.795      0.000      -0.131      -0.123\n",
      "s_27          -0.0345      0.001    -25.037      0.000      -0.037      -0.032\n",
      "d_113         -0.0146      0.002     -6.511      0.000      -0.019      -0.010\n",
      "d_114         -0.1306      0.004    -29.480      0.000      -0.139      -0.122\n",
      "d_115         -0.0501      0.003    -18.288      0.000      -0.055      -0.045\n",
      "d_116          0.0459      0.018      2.599      0.009       0.011       0.080\n",
      "d_117         -0.0222      0.001    -27.533      0.000      -0.024      -0.021\n",
      "d_120          0.0241      0.005      4.956      0.000       0.015       0.034\n",
      "d_121          0.1627      0.003     55.085      0.000       0.157       0.168\n",
      "d_122         -0.0171      0.002     -6.907      0.000      -0.022      -0.012\n",
      "d_123          0.0153      0.002      6.666      0.000       0.011       0.020\n",
      "d_124          0.0359      0.002     16.425      0.000       0.032       0.040\n",
      "d_125          0.0116      0.002      5.302      0.000       0.007       0.016\n",
      "d_126         -0.0151      0.003     -5.013      0.000      -0.021      -0.009\n",
      "d_127         -0.1005      0.004    -25.037      0.000      -0.108      -0.093\n",
      "d_128         -0.0217      0.003     -8.312      0.000      -0.027      -0.017\n",
      "d_129         -0.1419      0.003    -54.912      0.000      -0.147      -0.137\n",
      "b_41           0.0295      0.002     17.108      0.000       0.026       0.033\n",
      "d_130          0.0252      0.002     12.410      0.000       0.021       0.029\n",
      "d_131          0.1835      0.003     56.066      0.000       0.177       0.190\n",
      "d_133         -0.1100      0.002    -55.033      0.000      -0.114      -0.106\n",
      "d_138          0.0350      0.001     25.969      0.000       0.032       0.038\n",
      "d_140          0.0158      0.001     11.559      0.000       0.013       0.018\n",
      "d_144         -0.0280      0.002    -17.299      0.000      -0.031      -0.025\n",
      "d_145         -0.0087      0.001     -6.152      0.000      -0.011      -0.006\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "del(df_processed)\n",
    "# Remove the insignificant features and train the model again. I will keep the alpha level as 0.05\n",
    "logit_pvalues = round(sm_logit1.pvalues,3)\n",
    "high_pval_col = logit_pvalues.index[logit_pvalues > 0.05]\n",
    "\n",
    "# Drop these columns\n",
    "X = X.drop(columns = high_pval_col)\n",
    "print(f'The columns remaining after removing insignificant ones : {X.shape}')\n",
    "X_train, X_test,y_train, y_test= train_test_split(X, y, test_size=0.2,\n",
    "                                                     random_state=2303, stratify = y)\n",
    "\n",
    "# Model\n",
    "sm_logit2 = sm.Logit(y_train,X_train).fit()\n",
    "print(sm_logit2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[767614,  63103],\n",
       "       [ 81432, 194142]], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the confusion matrix\n",
    "prediction_probab = sm_logit2.predict(X_test)\n",
    "prediction = list(map(round,prediction_probab))\n",
    "confusion_matrix(y_test,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy is: 0.8693517347605648\n",
      "Logistic : ROC AUC = 0.932\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f'Validation accuracy is: {accuracy_score(y_test, prediction)}')\n",
    "\n",
    "# Calculate roc metric \n",
    "print('Logistic : ROC AUC = %.3f' % (roc_auc_score(y_test,prediction_probab)))\n",
    "\n",
    "fpr,tpr,_ = roc_curve(y_test,prediction_probab)\n",
    "plt.plot(fpr,tpr,marker = '.')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear the memory before loading the test data to predict\n",
    "del(fpr,tpr,X_test,X_train,y_test,y_train,X,y,prediction,prediction_probab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_model(df):\n",
    "    # Just add extra columns with 0 value so that pipeline does not fail --> these are the extra columns that we had in the training data\n",
    "    extra_cols = ['target']\n",
    "    # Concatenate the dataframe of extra columns with the dataframe of the test data\n",
    "    df = pd.concat([\n",
    "        df,\n",
    "        pd.DataFrame(np.zeros((df.shape[0], len(extra_cols))), columns=extra_cols)\n",
    "    ], axis=1)\n",
    "\n",
    "    # Use the pipeline to transform\n",
    "    X = pipeline.transform(df)\n",
    "\n",
    "    # Drop target & the insignificant variables found during the training using statsmodel p-value\n",
    "    X.drop(columns=['target','customer_id','s_2'] + df_vif[df_vif['VIF']> 11]['feature'].to_list()\n",
    "                    + high_pval_col.tolist(), inplace=True)\n",
    "\n",
    "    # return log_reg.predict(X), log_reg.predict_proba(X)\n",
    "    # In the statsmodel predict will give the probability\n",
    "    return list(map(round,sm_logit2.predict(X))), sm_logit2.predict(X).tolist()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(sm_logit1)\n",
    "df_test = pd.read_parquet('../data/test.parquet')\n",
    "df_test.columns= df_test.columns.str.lower()\n",
    "# Define the result mdf\n",
    "mdf = pd.DataFrame(columns=['customer_id', 's_2', 'pred', 'proba'])\n",
    "y, y_proba = execute_model(df_test)\n",
    "\n",
    "mdf = pd.concat([\n",
    "    mdf,\n",
    "    pd.DataFrame({\n",
    "        'customer_id': df_test['customer_id'].values,\n",
    "        's_2': df_test['s_2'].values,\n",
    "        'pred': y,\n",
    "        'proba': y_proba\n",
    "    })\n",
    "]) \n",
    "mdf.to_csv('../ignore/final/logisticregression_baseline_prediction.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<M8[ns]')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdf['s_2'] = pd.to_datetime(mdf['s_2'])\n",
    "mdf['s_2'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just take the last statement probability of each customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the last statement probability of each of the customer\n",
    "df_result_last = mdf.sort_values(by = 's_2').groupby('customer_id')[['customer_id','proba']].tail(1)\n",
    "df_result_last.rename(columns= {'proba' : 'prediction'},inplace=True)\n",
    "df_result_last.head()\n",
    "df_result_last.to_csv('../ignore/final/logistic_baseline_laststmt_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weighted probabilities using Joe's Code (test data) for the last 3 stmts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the outcome weighting.\n",
    "\n",
    "def conditions(x):\n",
    "    # Customer has 3 statements:\n",
    "    if   x == 3:   return 0.1\n",
    "    elif x == 6:   return 0.15\n",
    "    elif x == 9:   return 0.75\n",
    "    \n",
    "    # Customer has 2 statements:\n",
    "    elif x == 2:   return 0.2\n",
    "    elif x == 4:   return 0.8\n",
    "    \n",
    "    # Customer has 1 statement:\n",
    "    elif x == 1:   return 1.0 \n",
    "    else:          return \"error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the last 3 statements of each customer\n",
    "mdf1 = mdf.sort_values('s_2').groupby('customer_id').tail(3)\n",
    "# if the customer has last 3 stmts the ranking will be as - 1st to the older stmt and 3rd rank to the latest stmt. \n",
    "mdf1[\"statement_num\"] = mdf1.groupby(\"customer_id\")[\"s_2\"].rank(method=\"first\", ascending=True)\n",
    "# The statement_count variable will give the count of the statements for each customer (i.e. to know if they have all the 3 or less than that)\n",
    "mdf1['statement_count'] = mdf1.groupby('customer_id')['statement_num'].transform('max')\n",
    "\n",
    "# Create a number so we can handle the case where a customer had only 1 or 2 statements. \n",
    "# Multiplied to give me a unique value for each case. See conditions() above.\n",
    "mdf1['statement_checksum'] = (mdf1['statement_count']) * mdf1['statement_num']\n",
    "\n",
    "# Assign the weights to the statements\n",
    "mdf1['statement_weight'] = mdf1['statement_checksum'].apply(conditions)\n",
    "\n",
    "# Calculating the weighted sum\n",
    "mdf1 ['prediction'] = mdf1['proba'] * mdf1['statement_weight']\n",
    "\n",
    "mdf1 = mdf1[['customer_id', 'prediction']]\n",
    "\n",
    "# Grouping those weighted sums by customer_id to give granularity of 1 proba per customer\n",
    "mdf1 = mdf1.groupby('customer_id').sum()\n",
    "# Bring the customer_id from index to column\n",
    "mdf1.reset_index(inplace=True)\n",
    "# Send the data to the file\n",
    "mdf1.to_csv('../ignore/final/logistic_baseline_weighted_last3_stmt.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "89a73c21ecc9236fdbb84984cd9e615404f96fb7d0e8948f841b3ff5dee670ca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
