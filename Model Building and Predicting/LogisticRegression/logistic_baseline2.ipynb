{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pick last statements of customers for train and test both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report,confusion_matrix,roc_curve,roc_auc_score, accuracy_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read training data \n",
    "df_train_x = pd.read_parquet('D:/Sakshi/DSBA_6156_SERJ/data/train.parquet')\n",
    "df_train_x.columns = df_train_x.columns.str.lower()\n",
    "# Read training data labels\n",
    "df_train_y = pd.read_csv('D:/Sakshi/DSBA_6156_SERJ/data/train_labels.csv')\n",
    "df_train_y.columns = df_train_y.columns.str.lower()\n",
    "df_train_y = df_train_y.set_index('customer_id')\n",
    "\n",
    "df_train_x = df_train_x.sort_values(['customer_id', 's_2'])\n",
    "df_train = pd.merge(df_train_x, df_train_y, on='customer_id')\n",
    "del(df_train_x, df_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Before doing any transformation see the datatypes of the features\n",
    "# df_train.dtypes.to_csv('../ignore/final/before_transformations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['last_statement_flag'] = (df_train.groupby('customer_id')['s_2']\n",
    "                      .rank(method='dense', ascending=False)\n",
    "                      .astype(int)\n",
    "                   )\n",
    "df_train = df_train[df_train['last_statement_flag']== 1]                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>s_2</th>\n",
       "      <th>target</th>\n",
       "      <th>last_statement_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0000f99513770170a1aba690daeeb8a96da4a39f11fc27...</td>\n",
       "      <td>2018-03-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           customer_id         s_2  target  \\\n",
       "116  0000f99513770170a1aba690daeeb8a96da4a39f11fc27...  2018-03-01       1   \n",
       "\n",
       "     last_statement_flag  \n",
       "116                    1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train['customer_id']== '0000f99513770170a1aba690daeeb8a96da4a39f11fc27da5c30a79db61c1e85']\\\n",
    "    [['customer_id','s_2','target','last_statement_flag']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(columns = 'last_statement_flag', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "d_63     0.0\n",
       "d_64     0.0\n",
       "d_66     0.0\n",
       "d_68     0.0\n",
       "b_30     0.0\n",
       "b_31     0.0\n",
       "b_38     0.0\n",
       "d_114    0.0\n",
       "d_116    0.0\n",
       "d_117    0.0\n",
       "d_120    0.0\n",
       "d_126    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline(steps=[])\n",
    "# 89% of d_66 column values were missing, but it has been filled with -1 while parquet generation.\n",
    "# Also assign the column names in sequence in which it appars in the file  \n",
    "categorical_cols = ['d_63', 'd_64', 'd_66', 'd_68', 'b_30', 'b_31', 'b_38', 'd_114', 'd_116',\n",
    "                     'd_117', 'd_120', 'd_126']\n",
    "df_train[categorical_cols].isnull().sum() / len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check the percentage of missing values\n",
    "# null_series = df_train.isna().sum() / df_train.shape[0]\n",
    "# null_series.to_csv('../ignore/final/column_null_values_prop.csv')\n",
    "# del null_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The unique values for column d_63 is [0 3 4 5 1 2]\n",
      "The unique values for column d_64 is [ 0  2  3 -1]\n",
      "The unique values for column d_66 is [-1  1]\n",
      "The unique values for column d_68 is [ 6  3  5  4  2  1 -1]\n",
      "The unique values for column b_30 is [ 0  1  2 -1]\n",
      "The unique values for column b_31 is [1 0]\n",
      "The unique values for column b_38 is [ 2  1  3  7  5  6  4 -1]\n",
      "The unique values for column d_114 is [ 1  0 -1]\n",
      "The unique values for column d_116 is [ 0 -1  1]\n",
      "The unique values for column d_117 is [ 5  0  7  2  3  6  4 -1]\n",
      "The unique values for column d_120 is [ 0  1 -1]\n",
      "The unique values for column d_126 is [2 1]\n"
     ]
    }
   ],
   "source": [
    "# Check for the unique values for all the categorical features\n",
    "for i in categorical_cols:\n",
    "    print(f'The unique values for column {i} is {df_train[i].unique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the original file is:(458913, 191)\n"
     ]
    }
   ],
   "source": [
    "print(f'The shape of the original file is:{df_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreProcessing(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, categorical_cols):\n",
    "        self.categorical_cols = categorical_cols\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Get the list of columns that have missing values greater than equal to 40%\n",
    "        missing_perc = round((X.isnull().sum() / len(X)) * 100, 2)\n",
    "        # Prepare final List of columns to drop\n",
    "        self.cols_to_drop = missing_perc[missing_perc.ge(40)].index.tolist() \n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        numeric_cols = list(set(X.columns.tolist(\n",
    "        )) - set(self.categorical_cols + self.cols_to_drop + ['target', 'customer_id', 's_2']))\n",
    "\n",
    "        # Impute the mean of the numeric columns\n",
    "        for col in numeric_cols:\n",
    "            # Check if the column has any null value, then only apply the imputation\n",
    "            if X[col].isnull().any():\n",
    "                X[col] = X[col].fillna(X[col].mean())\n",
    "                            \n",
    "            # Scale\n",
    "            mean = X[col].mean()\n",
    "            std = X[col].std()\n",
    "            if std > 0:\n",
    "                X[col] = ((X[col] - mean) / std).astype('float32')\n",
    "\n",
    "        X = X.drop(columns = self.cols_to_drop)\n",
    "\n",
    "        return X\n",
    "\n",
    "# use all the statements of a customer where all stmts are marked with the same target value\n",
    "preprocessing = PreProcessing(categorical_cols)\n",
    "df_processed = preprocessing.fit_transform(df_train)\n",
    "\n",
    "pipeline.steps.append(('preprocessing', preprocessing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_processed.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After processing the shape is :(458913, 173)\n"
     ]
    }
   ],
   "source": [
    "del (df_train)\n",
    "print(f'After processing the shape is :{df_processed.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the correlation for the numeric columns\n",
    "df_corr = df_processed.drop(columns = categorical_cols + ['target','customer_id','s_2']).corr()\n",
    "df_corr.to_csv(\"D:/Sakshi/DSBA_6156_SERJ/ignore/final/single_num_corr_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def sklearn_vif(data):\n",
    "\n",
    "    # initialize dictionaries\n",
    "    result = {}\n",
    "\n",
    "    # form input data for each exogenous variable\n",
    "    exogs = data.columns.to_list()\n",
    "    for exog in exogs:\n",
    "        # print(exog)\n",
    "        not_exog = [i for i in exogs if i != exog]\n",
    "        # exog would be for which the VIF has to be calculated based on the combination of other columns\n",
    "        X, y = data[not_exog], data[exog]  \n",
    "        # extract r-squared from the fit\n",
    "        r_squared = LinearRegression(n_jobs=12).fit(X, y).score(X, y)\n",
    "\n",
    "        # calculate VIF\n",
    "        vif = 1/(1 - r_squared)\n",
    "        result[exog] = vif\n",
    "    return result\n",
    "\n",
    "vif_data1 = sklearn_vif(df_processed.drop(columns = categorical_cols + ['target','customer_id','s_2']))\n",
    "# Convert the results from the dictionary to dataframe\n",
    "df_vif = pd.DataFrame({\n",
    "    'feature': vif_data1.keys(),\n",
    "    'VIF': vif_data1.values()\n",
    "})\n",
    "del(vif_data1)\n",
    "df_vif.to_csv(\"D:/Sakshi/DSBA_6156_SERJ/ignore/final/single_num_VIF_data_results.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_vif = pd.read_csv(\"D:/Sakshi/DSBA_6156_SERJ/ignore/final/single_num_VIF_data_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The remaining columns of the data after dropping columns with high VIF : 142\n"
     ]
    }
   ],
   "source": [
    "# Plainly drop all the columns with higher VIF values\n",
    "df_processed.drop(columns = df_vif[df_vif['VIF']> 10]['feature'].to_list(), inplace=True)\n",
    "print(f'The remaining columns of the data after dropping columns with high VIF : {df_processed.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df_processed.drop(columns=['target','customer_id','s_2']), df_processed['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.2, random_state=2303, stratify = y)                                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.237577\n",
      "         Iterations 9\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                 target   No. Observations:               367130\n",
      "Model:                          Logit   Df Residuals:                   366991\n",
      "Method:                           MLE   Df Model:                          138\n",
      "Date:                Tue, 13 Dec 2022   Pseudo R-squ.:                  0.5846\n",
      "Time:                        22:48:04   Log-Likelihood:                -87222.\n",
      "converged:                       True   LL-Null:                   -2.0998e+05\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "p_2           -0.8610      0.015    -58.051      0.000      -0.890      -0.832\n",
      "d_39           0.3579      0.010     37.128      0.000       0.339       0.377\n",
      "s_3            0.1291      0.013      9.738      0.000       0.103       0.155\n",
      "d_41           0.1920      0.013     14.347      0.000       0.166       0.218\n",
      "b_3            0.3228      0.010     31.557      0.000       0.303       0.343\n",
      "d_43           0.1075      0.009     12.213      0.000       0.090       0.125\n",
      "d_44           0.0507      0.009      5.493      0.000       0.033       0.069\n",
      "b_4            0.4211      0.009     47.780      0.000       0.404       0.438\n",
      "d_45          -0.0874      0.014     -6.249      0.000      -0.115      -0.060\n",
      "b_5           -0.2061      0.018    -11.281      0.000      -0.242      -0.170\n",
      "r_2            0.0860      0.015      5.883      0.000       0.057       0.115\n",
      "d_46           0.1428      0.007     19.336      0.000       0.128       0.157\n",
      "d_47          -0.1712      0.011    -15.559      0.000      -0.193      -0.150\n",
      "d_48           0.1815      0.015     12.437      0.000       0.153       0.210\n",
      "d_49           0.0730      0.008      8.711      0.000       0.057       0.089\n",
      "b_6           -0.1100      0.022     -5.009      0.000      -0.153      -0.067\n",
      "b_8            0.1619      0.011     14.830      0.000       0.140       0.183\n",
      "d_51          -0.2380      0.014    -16.539      0.000      -0.266      -0.210\n",
      "b_9            0.1754      0.009     20.413      0.000       0.159       0.192\n",
      "r_3            0.1697      0.008     20.242      0.000       0.153       0.186\n",
      "d_52          -0.0255      0.008     -3.322      0.001      -0.041      -0.010\n",
      "p_3           -0.0083      0.008     -1.053      0.292      -0.024       0.007\n",
      "b_10          -0.0444      0.022     -2.000      0.045      -0.088      -0.001\n",
      "s_5            0.0391      0.007      5.750      0.000       0.026       0.052\n",
      "s_6            0.0540      0.009      6.236      0.000       0.037       0.071\n",
      "d_54          -0.0856      0.009    -10.013      0.000      -0.102      -0.069\n",
      "r_4            0.1686      0.014     12.230      0.000       0.142       0.196\n",
      "s_7            0.0580      0.013      4.300      0.000       0.032       0.084\n",
      "b_12          -0.0895      0.025     -3.607      0.000      -0.138      -0.041\n",
      "s_8           -0.0971      0.014     -6.808      0.000      -0.125      -0.069\n",
      "d_55          -0.0906      0.014     -6.322      0.000      -0.119      -0.063\n",
      "b_13           0.0886      0.014      6.494      0.000       0.062       0.115\n",
      "d_59           0.0199      0.007      2.696      0.007       0.005       0.034\n",
      "d_60           0.1450      0.010     14.753      0.000       0.126       0.164\n",
      "d_61           0.0674      0.012      5.451      0.000       0.043       0.092\n",
      "s_11          -0.0971      0.007    -13.168      0.000      -0.112      -0.083\n",
      "d_62          -0.2168      0.014    -15.351      0.000      -0.245      -0.189\n",
      "d_63          -0.0565      0.007     -7.560      0.000      -0.071      -0.042\n",
      "d_64           0.0116      0.006      2.056      0.040       0.001       0.023\n",
      "d_65           0.1219      0.015      8.226      0.000       0.093       0.151\n",
      "b_16           0.1958      0.016     12.539      0.000       0.165       0.226\n",
      "b_19           0.0976      0.010     10.127      0.000       0.079       0.116\n",
      "d_66          -0.1794      0.011    -16.681      0.000      -0.200      -0.158\n",
      "b_20          -0.1703      0.014    -12.561      0.000      -0.197      -0.144\n",
      "d_68          -0.0530      0.006     -8.689      0.000      -0.065      -0.041\n",
      "s_12           0.0448      0.006      7.886      0.000       0.034       0.056\n",
      "r_6            0.0095      0.010      0.970      0.332      -0.010       0.029\n",
      "s_13           0.0222      0.011      1.954      0.051    -6.4e-05       0.044\n",
      "b_21           0.0412      0.011      3.834      0.000       0.020       0.062\n",
      "d_69           0.0179      0.006      2.829      0.005       0.005       0.030\n",
      "b_22           0.0544      0.009      5.835      0.000       0.036       0.073\n",
      "d_70           0.0611      0.006      9.545      0.000       0.049       0.074\n",
      "d_71          -0.1786      0.032     -5.576      0.000      -0.241      -0.116\n",
      "d_72           0.0075      0.009      0.830      0.407      -0.010       0.025\n",
      "s_15           0.0142      0.010      1.467      0.142      -0.005       0.033\n",
      "p_4            0.0795      0.008     10.306      0.000       0.064       0.095\n",
      "b_24           0.0033      0.012      0.289      0.772      -0.019       0.026\n",
      "r_7            0.0017      0.008      0.200      0.842      -0.015       0.018\n",
      "b_26           0.0136      0.007      1.915      0.056      -0.000       0.027\n",
      "d_78          -0.0083      0.009     -0.972      0.331      -0.025       0.008\n",
      "d_79           0.0081      0.011      0.748      0.455      -0.013       0.029\n",
      "r_9            0.0079      0.006      1.378      0.168      -0.003       0.019\n",
      "s_16           0.0005      0.008      0.065      0.948      -0.015       0.016\n",
      "d_80           0.0347      0.007      5.233      0.000       0.022       0.048\n",
      "r_10           0.1021      0.008     13.192      0.000       0.087       0.117\n",
      "r_11           0.0796      0.005     14.485      0.000       0.069       0.090\n",
      "b_27          -0.0014      0.007     -0.194      0.846      -0.016       0.013\n",
      "d_81           0.0241      0.010      2.330      0.020       0.004       0.044\n",
      "d_82           0.0812      0.010      8.462      0.000       0.062       0.100\n",
      "s_17           0.0141      0.005      2.623      0.009       0.004       0.025\n",
      "r_12          -0.0117      0.008     -1.461      0.144      -0.027       0.004\n",
      "d_83           0.0143      0.006      2.571      0.010       0.003       0.025\n",
      "r_14           0.0296      0.009      3.218      0.001       0.012       0.048\n",
      "r_15           0.0172      0.007      2.391      0.017       0.003       0.031\n",
      "d_84           0.0154      0.017      0.915      0.360      -0.018       0.048\n",
      "r_16          -0.0260      0.007     -3.695      0.000      -0.040      -0.012\n",
      "b_30           0.0700      0.021      3.315      0.001       0.029       0.111\n",
      "s_18          -0.0059      0.007     -0.890      0.373      -0.019       0.007\n",
      "d_86          -0.0526      0.009     -5.964      0.000      -0.070      -0.035\n",
      "d_87          -0.0088      0.009     -1.034      0.301      -0.025       0.008\n",
      "r_18           0.0008      0.008      0.105      0.917      -0.015       0.016\n",
      "b_31          -1.9244      0.049    -39.296      0.000      -2.020      -1.828\n",
      "s_19           0.0095      0.006      1.582      0.114      -0.002       0.021\n",
      "r_19          -0.0268      0.005     -5.114      0.000      -0.037      -0.017\n",
      "b_32          -0.0123      0.005     -2.325      0.020      -0.023      -0.002\n",
      "s_20           0.0074      0.008      0.920      0.358      -0.008       0.023\n",
      "r_20          -0.0257      0.013     -1.948      0.051      -0.052       0.000\n",
      "r_21           0.0766      0.009      8.939      0.000       0.060       0.093\n",
      "d_89          -0.0084      0.013     -0.636      0.525      -0.034       0.017\n",
      "r_22          -0.0019      0.005     -0.400      0.689      -0.011       0.007\n",
      "r_23           0.0037      0.005      0.732      0.464      -0.006       0.014\n",
      "d_91          -0.0718      0.011     -6.716      0.000      -0.093      -0.051\n",
      "d_92          -0.0474      0.016     -2.887      0.004      -0.080      -0.015\n",
      "d_93           0.0148      0.009      1.667      0.095      -0.003       0.032\n",
      "d_94           0.0302      0.019      1.569      0.117      -0.008       0.068\n",
      "r_24           0.0193      0.011      1.699      0.089      -0.003       0.042\n",
      "r_25          -0.0286      0.008     -3.404      0.001      -0.045      -0.012\n",
      "d_96          -0.0273      0.009     -3.124      0.002      -0.044      -0.010\n",
      "s_23           0.0666      0.013      5.201      0.000       0.042       0.092\n",
      "s_25          -0.0221      0.005     -4.070      0.000      -0.033      -0.011\n",
      "s_26           0.0078      0.015      0.528      0.597      -0.021       0.037\n",
      "d_102         -0.0394      0.008     -5.076      0.000      -0.055      -0.024\n",
      "d_106         -0.0286      0.006     -4.689      0.000      -0.040      -0.017\n",
      "d_107          0.0244      0.008      3.202      0.001       0.009       0.039\n",
      "b_36           0.0173      0.009      1.922      0.055      -0.000       0.035\n",
      "r_26           0.0066      0.008      0.867      0.386      -0.008       0.022\n",
      "r_27          -0.0693      0.006    -11.203      0.000      -0.081      -0.057\n",
      "b_38           0.0017      0.005      0.313      0.755      -0.009       0.012\n",
      "d_108          0.0189      0.005      3.706      0.000       0.009       0.029\n",
      "d_109         -0.0131      0.012     -1.087      0.277      -0.037       0.011\n",
      "d_111          0.0557      0.009      6.139      0.000       0.038       0.073\n",
      "d_112         -0.1645      0.008    -20.449      0.000      -0.180      -0.149\n",
      "b_40           0.0194      0.015      1.324      0.186      -0.009       0.048\n",
      "s_27          -0.0090      0.005     -1.718      0.086      -0.019       0.001\n",
      "d_113         -0.0055      0.008     -0.658      0.510      -0.022       0.011\n",
      "d_114         -0.1241      0.017     -7.395      0.000      -0.157      -0.091\n",
      "d_115         -0.0475      0.011     -4.465      0.000      -0.068      -0.027\n",
      "d_116         -0.1807      0.064     -2.838      0.005      -0.306      -0.056\n",
      "d_117         -0.0187      0.003     -6.115      0.000      -0.025      -0.013\n",
      "d_120          0.2010      0.017     11.549      0.000       0.167       0.235\n",
      "d_121          0.1701      0.012     14.784      0.000       0.148       0.193\n",
      "d_122         -0.0213      0.009     -2.290      0.022      -0.039      -0.003\n",
      "d_123          0.0151      0.008      1.890      0.059      -0.001       0.031\n",
      "d_124          0.0285      0.008      3.501      0.000       0.013       0.044\n",
      "d_125         -0.0094      0.008     -1.132      0.258      -0.026       0.007\n",
      "d_126         -0.0179      0.017     -1.066      0.286      -0.051       0.015\n",
      "d_127         -0.1330      0.018     -7.529      0.000      -0.168      -0.098\n",
      "d_128         -0.0246      0.011     -2.302      0.021      -0.046      -0.004\n",
      "d_129         -0.1103      0.011    -10.468      0.000      -0.131      -0.090\n",
      "b_41           0.0438      0.007      5.875      0.000       0.029       0.058\n",
      "d_130          0.0087      0.008      1.087      0.277      -0.007       0.024\n",
      "d_131          0.2016      0.013     16.110      0.000       0.177       0.226\n",
      "d_133         -0.1266      0.007    -16.881      0.000      -0.141      -0.112\n",
      "r_28           0.0046      0.004      1.068      0.286      -0.004       0.013\n",
      "d_136         -0.0254      0.008     -3.333      0.001      -0.040      -0.010\n",
      "d_138          0.0564      0.008      7.293      0.000       0.041       0.071\n",
      "d_140          0.0379      0.005      7.471      0.000       0.028       0.048\n",
      "d_144         -0.0294      0.006     -4.726      0.000      -0.042      -0.017\n",
      "d_145         -0.0188      0.005     -3.492      0.000      -0.029      -0.008\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "sm_logit1 = sm.Logit(y_train,X_train).fit()\n",
    "print(sm_logit1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The columns remaining after removing insignificant ones : (458913, 99)\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.237659\n",
      "         Iterations 9\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                 target   No. Observations:               367130\n",
      "Model:                          Logit   Df Residuals:                   367031\n",
      "Method:                           MLE   Df Model:                           98\n",
      "Date:                Tue, 13 Dec 2022   Pseudo R-squ.:                  0.5845\n",
      "Time:                        22:48:14   Log-Likelihood:                -87252.\n",
      "converged:                       True   LL-Null:                   -2.0998e+05\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "p_2           -0.8763      0.014    -64.875      0.000      -0.903      -0.850\n",
      "d_39           0.3560      0.010     37.223      0.000       0.337       0.375\n",
      "s_3            0.1310      0.013     10.132      0.000       0.106       0.156\n",
      "d_41           0.1905      0.013     14.329      0.000       0.164       0.217\n",
      "b_3            0.3228      0.010     31.733      0.000       0.303       0.343\n",
      "d_43           0.1078      0.009     12.280      0.000       0.091       0.125\n",
      "d_44           0.0467      0.009      5.236      0.000       0.029       0.064\n",
      "b_4            0.4230      0.009     48.627      0.000       0.406       0.440\n",
      "d_45          -0.0887      0.014     -6.358      0.000      -0.116      -0.061\n",
      "b_5           -0.2038      0.018    -11.384      0.000      -0.239      -0.169\n",
      "r_2            0.0994      0.011      9.184      0.000       0.078       0.121\n",
      "d_46           0.1441      0.007     20.273      0.000       0.130       0.158\n",
      "d_47          -0.1694      0.011    -15.453      0.000      -0.191      -0.148\n",
      "d_48           0.1836      0.015     12.658      0.000       0.155       0.212\n",
      "d_49           0.0754      0.008      9.530      0.000       0.060       0.091\n",
      "b_6           -0.1111      0.022     -5.046      0.000      -0.154      -0.068\n",
      "b_8            0.1602      0.011     14.719      0.000       0.139       0.182\n",
      "d_51          -0.2333      0.014    -16.638      0.000      -0.261      -0.206\n",
      "b_9            0.1761      0.009     20.687      0.000       0.159       0.193\n",
      "r_3            0.1700      0.008     20.310      0.000       0.154       0.186\n",
      "d_52          -0.0240      0.008     -3.191      0.001      -0.039      -0.009\n",
      "b_10          -0.0445      0.022     -2.004      0.045      -0.088      -0.001\n",
      "s_5            0.0398      0.006      6.152      0.000       0.027       0.052\n",
      "s_6            0.0514      0.009      5.987      0.000       0.035       0.068\n",
      "d_54          -0.0832      0.009     -9.778      0.000      -0.100      -0.067\n",
      "r_4            0.1651      0.011     14.374      0.000       0.143       0.188\n",
      "s_7            0.0597      0.013      4.466      0.000       0.034       0.086\n",
      "b_12          -0.0766      0.023     -3.332      0.001      -0.122      -0.032\n",
      "s_8           -0.1009      0.009    -11.261      0.000      -0.118      -0.083\n",
      "d_55          -0.0935      0.014     -6.606      0.000      -0.121      -0.066\n",
      "b_13           0.0871      0.014      6.414      0.000       0.060       0.114\n",
      "d_59           0.0193      0.007      2.626      0.009       0.005       0.034\n",
      "d_60           0.1491      0.010     15.683      0.000       0.130       0.168\n",
      "d_61           0.0681      0.012      5.516      0.000       0.044       0.092\n",
      "s_11          -0.0938      0.007    -13.311      0.000      -0.108      -0.080\n",
      "d_62          -0.2169      0.014    -15.418      0.000      -0.244      -0.189\n",
      "d_63          -0.0559      0.007     -7.509      0.000      -0.071      -0.041\n",
      "d_64           0.0114      0.006      2.049      0.040       0.000       0.022\n",
      "d_65           0.1311      0.014      9.285      0.000       0.103       0.159\n",
      "b_16           0.1974      0.015     12.989      0.000       0.168       0.227\n",
      "b_19           0.0964      0.009     10.568      0.000       0.079       0.114\n",
      "d_66          -0.1801      0.011    -16.775      0.000      -0.201      -0.159\n",
      "b_20          -0.1708      0.014    -12.639      0.000      -0.197      -0.144\n",
      "d_68          -0.0514      0.005     -9.588      0.000      -0.062      -0.041\n",
      "s_12           0.0465      0.006      8.238      0.000       0.035       0.058\n",
      "b_21           0.0434      0.010      4.455      0.000       0.024       0.062\n",
      "d_69           0.0185      0.006      2.943      0.003       0.006       0.031\n",
      "b_22           0.0548      0.009      5.909      0.000       0.037       0.073\n",
      "d_70           0.0610      0.006      9.550      0.000       0.048       0.073\n",
      "d_71          -0.1495      0.025     -5.886      0.000      -0.199      -0.100\n",
      "p_4            0.0784      0.008     10.238      0.000       0.063       0.093\n",
      "d_80           0.0348      0.007      5.271      0.000       0.022       0.048\n",
      "r_10           0.1002      0.008     13.307      0.000       0.085       0.115\n",
      "r_11           0.0798      0.005     14.545      0.000       0.069       0.091\n",
      "d_81           0.0283      0.008      3.341      0.001       0.012       0.045\n",
      "d_82           0.0831      0.009      8.817      0.000       0.065       0.102\n",
      "s_17           0.0144      0.005      2.689      0.007       0.004       0.025\n",
      "d_83           0.0150      0.006      2.722      0.006       0.004       0.026\n",
      "r_14           0.0346      0.008      4.183      0.000       0.018       0.051\n",
      "r_15           0.0176      0.007      2.535      0.011       0.004       0.031\n",
      "r_16          -0.0261      0.007     -3.717      0.000      -0.040      -0.012\n",
      "b_30           0.0657      0.021      3.126      0.002       0.025       0.107\n",
      "d_86          -0.0511      0.009     -5.816      0.000      -0.068      -0.034\n",
      "b_31          -1.9581      0.038    -51.779      0.000      -2.032      -1.884\n",
      "r_19          -0.0264      0.005     -5.045      0.000      -0.037      -0.016\n",
      "b_32          -0.0122      0.005     -2.334      0.020      -0.022      -0.002\n",
      "r_21           0.0821      0.007     12.484      0.000       0.069       0.095\n",
      "d_91          -0.0730      0.011     -6.891      0.000      -0.094      -0.052\n",
      "d_92          -0.0475      0.016     -2.913      0.004      -0.079      -0.016\n",
      "r_25          -0.0241      0.007     -3.604      0.000      -0.037      -0.011\n",
      "d_96          -0.0246      0.009     -2.843      0.004      -0.042      -0.008\n",
      "s_23           0.0670      0.013      5.245      0.000       0.042       0.092\n",
      "s_25          -0.0217      0.005     -4.014      0.000      -0.032      -0.011\n",
      "d_102         -0.0386      0.008     -4.987      0.000      -0.054      -0.023\n",
      "d_106         -0.0294      0.006     -4.946      0.000      -0.041      -0.018\n",
      "d_107          0.0246      0.008      3.248      0.001       0.010       0.039\n",
      "r_27          -0.0722      0.006    -12.928      0.000      -0.083      -0.061\n",
      "d_108          0.0191      0.005      3.736      0.000       0.009       0.029\n",
      "d_111          0.0706      0.005     14.708      0.000       0.061       0.080\n",
      "d_112         -0.1641      0.008    -20.451      0.000      -0.180      -0.148\n",
      "d_114         -0.1258      0.017     -7.547      0.000      -0.158      -0.093\n",
      "d_115         -0.0456      0.011     -4.313      0.000      -0.066      -0.025\n",
      "d_116         -0.1696      0.059     -2.866      0.004      -0.286      -0.054\n",
      "d_117         -0.0189      0.003     -6.338      0.000      -0.025      -0.013\n",
      "d_120          0.1990      0.017     11.518      0.000       0.165       0.233\n",
      "d_121          0.1692      0.011     15.554      0.000       0.148       0.191\n",
      "d_122         -0.0226      0.009     -2.456      0.014      -0.041      -0.005\n",
      "d_124          0.0275      0.008      3.517      0.000       0.012       0.043\n",
      "d_127         -0.1324      0.018     -7.498      0.000      -0.167      -0.098\n",
      "d_128         -0.0241      0.011     -2.278      0.023      -0.045      -0.003\n",
      "d_129         -0.1079      0.010    -10.366      0.000      -0.128      -0.088\n",
      "b_41           0.0501      0.007      7.521      0.000       0.037       0.063\n",
      "d_131          0.2120      0.009     23.022      0.000       0.194       0.230\n",
      "d_133         -0.1257      0.007    -16.884      0.000      -0.140      -0.111\n",
      "d_136         -0.0252      0.008     -3.315      0.001      -0.040      -0.010\n",
      "d_138          0.0565      0.008      7.322      0.000       0.041       0.072\n",
      "d_140          0.0377      0.005      7.446      0.000       0.028       0.048\n",
      "d_144         -0.0292      0.006     -4.686      0.000      -0.041      -0.017\n",
      "d_145         -0.0189      0.005     -3.522      0.000      -0.029      -0.008\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "del(df_processed)\n",
    "# Remove the insignificant features and train the model again. I will keep the alpha level as 0.05\n",
    "logit_pvalues = round(sm_logit1.pvalues,3)\n",
    "high_pval_col = logit_pvalues.index[logit_pvalues > 0.05]\n",
    "\n",
    "# Drop these columns\n",
    "X = X.drop(columns = high_pval_col)\n",
    "print(f'The columns remaining after removing insignificant ones : {X.shape}')\n",
    "X_train, X_test,y_train, y_test= train_test_split(X, y, test_size=0.2,\n",
    "                                                     random_state=2303, stratify = y)\n",
    "\n",
    "# Model\n",
    "sm_logit2 = sm.Logit(y_train,X_train).fit()\n",
    "print(sm_logit2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[63811,  4206],\n",
       "       [ 5359, 18407]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the confusion matrix\n",
    "prediction_probab = sm_logit2.predict(X_test)\n",
    "prediction = list(map(round,prediction_probab))\n",
    "confusion_matrix(y_test,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy is: 0.8957868014773978\n",
      "Logistic : ROC AUC = 0.956\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f'Validation accuracy is: {accuracy_score(y_test, prediction)}')\n",
    "\n",
    "# Calculate roc metric \n",
    "print('Logistic : ROC AUC = %.3f' % (roc_auc_score(y_test,prediction_probab)))\n",
    "\n",
    "fpr,tpr,_ = roc_curve(y_test,prediction_probab)\n",
    "plt.plot(fpr,tpr,marker = '.')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear the memory before loading the test data to predict\n",
    "del(fpr,tpr,X_test,X_train,y_test,y_train,X,y,prediction,prediction_probab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_model(df):\n",
    "    # Just add extra columns with 0 value so that pipeline does not\n",
    "    # fail --> these are the extra columns that we had in the training data\n",
    "    extra_cols = ['target']\n",
    "    print(df.shape)\n",
    "    # Concatenate the dataframe of extra columns with the dataframe of the test data\n",
    "    df['target'] = np.zeros((df.shape[0], 1))\n",
    "    print(df.shape)\n",
    "\n",
    "    # Use the pipeline to transform\n",
    "    X = pipeline.transform(df)\n",
    "    print(X.shape)\n",
    "    s = X.isnull().values.any()\n",
    "    print(s)\n",
    "    # Drop target & the insignificant variables found during the training using statsmodel p-value\n",
    "    X.drop(columns=['target','customer_id','s_2'] + df_vif[df_vif['VIF']> 10]['feature'].to_list()\n",
    "                    + high_pval_col.tolist(), inplace=True)\n",
    "\n",
    "    # return log_reg.predict(X), log_reg.predict_proba(X)\n",
    "    # In the statsmodel predict will give the probability\n",
    "    return list(map(round,sm_logit2.predict(X))), sm_logit2.predict(X).tolist()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(sm_logit1)\n",
    "df_test = pd.read_parquet('D:/Sakshi/DSBA_6156_SERJ/data/test.parquet')\n",
    "df_test.columns= df_test.columns.str.lower()\n",
    "df_test['last_statement_flag'] = (df_test.groupby('customer_id')['s_2']\n",
    "                      .rank(method='dense', ascending=False)\n",
    "                      .astype(np.int8)\n",
    "                   )\n",
    "df_test = df_test[df_test['last_statement_flag']== 1].copy()\n",
    "df_test.drop(columns='last_statement_flag', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(924621, 190)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(924621, 190)\n",
      "(924621, 191)\n",
      "(924621, 173)\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Define the result mdf\n",
    "mdf = pd.DataFrame(columns=['customer_id', 's_2', 'pred', 'proba'])\n",
    "y, y_proba = execute_model(df_test)\n",
    "\n",
    "mdf = pd.concat([\n",
    "    mdf,\n",
    "    pd.DataFrame({\n",
    "        'customer_id': df_test['customer_id'].values,\n",
    "        's_2': df_test['s_2'].values,\n",
    "        'pred': y,\n",
    "        'proba': y_proba\n",
    "    })\n",
    "]) \n",
    "# mdf.to_csv('../ignore/final/logisticregression_baseline_prediction.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<M8[ns]')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdf['s_2'] = pd.to_datetime(mdf['s_2'])\n",
    "mdf['s_2'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the last statement probability of each of the customer\n",
    "# df_result_last = mdf.sort_values(by = 's_2').groupby('customer_id')[['customer_id','proba']].tail(1)\n",
    "mdf.rename(columns= {'proba' : 'prediction'},inplace=True)\n",
    "mdf.to_csv('D:/Sakshi/DSBA_6156_SERJ/ignore/ppt_analysis/logistic_baseline2_sub.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "89a73c21ecc9236fdbb84984cd9e615404f96fb7d0e8948f841b3ff5dee670ca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
