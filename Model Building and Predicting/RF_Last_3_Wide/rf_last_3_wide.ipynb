{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import auc, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import datetime\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#constants\n",
    "rand_state = 1337"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_col_types(df, target_col=True):\n",
    "    if target_col:\n",
    "        categorical_cols = ['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_63', 'D_64', 'D_66', 'D_68','target']\n",
    "    else:\n",
    "        categorical_cols = ['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_63', 'D_64', 'D_66', 'D_68']\n",
    "        df['customer_ID'] = df['customer_ID'].astype('object')\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        df[col] = df[col].astype('category')\n",
    "    df[\"S_2\"] = pd.to_datetime(df['S_2'], format=r'%Y-%m-%d').astype('datetime64[ns]')\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_data(df, label_cols=[], drop_cols=[]):\n",
    "\n",
    "  df = df.fillna(np.nan) #because SimpleImputer requires specification of the type of nan value, we use this generic to change all nan types to np.nan types\n",
    "\n",
    "  df = df.drop(columns=drop_cols)\n",
    "  print(df.isna().sum().sum(), \"nulls exist after drop\")\n",
    "\n",
    "  df_labels = df[label_cols] #splits any specified columns off to a label df\n",
    "  df = df.drop(columns=label_cols)\n",
    "\n",
    "  cat_cols = df.select_dtypes(include=\"category\")\n",
    "  num_cols = df.select_dtypes(include=\"number\")\n",
    "  date_cols = df.select_dtypes(include=\"datetime\")\n",
    "  other_cols = df.select_dtypes(exclude={\"category\",\"number\",\"datetime\"})\n",
    "\n",
    "  #impute cat cols\n",
    "  for col in cat_cols:\n",
    "      if cat_cols[col].isna().any():\n",
    "        cat_cols[col] = cat_cols[col].cat.add_categories('⍼')\n",
    "  cat_cols = cat_cols.fillna('⍼')\n",
    "\n",
    "  #impute num cols\n",
    "  # for col in num_cols:\n",
    "  #   if num_cols[col].isna().any():\n",
    "  #     num_cols[col] = num_cols[col].fillna(num_cols[col].mean())\n",
    "  num_cols_imputed = SimpleImputer(strategy=\"mean\").fit_transform(num_cols)\n",
    "  num_cols = pd.DataFrame(num_cols_imputed, columns=num_cols.columns)\n",
    "\n",
    "  #scale num\n",
    "  num_cols_scaled = StandardScaler().fit_transform(num_cols)\n",
    "  num_cols_scaled = pd.DataFrame(num_cols_scaled, columns=num_cols.columns)\n",
    "  num_cols = num_cols_scaled\n",
    "\n",
    "  #get dummies for cat cols\n",
    "  cat_cols = pd.get_dummies(cat_cols)\n",
    "\n",
    "  #change datetime into components\n",
    "  date_cols_expanded = pd.DataFrame()\n",
    "  for col in date_cols:\n",
    "    date_cols_expanded[col + \"Month\"] = date_cols[col].dt.month\n",
    "    date_cols_expanded[col + \"Day\"] = date_cols[col].dt.day\n",
    "    date_cols_expanded[col + \"Year\"] = date_cols[col].dt.year\n",
    "\n",
    "  date_cols = date_cols_expanded.fillna(0)  ### ONLY USE THIS ON 3 WIDE - FILLS IN MISSING DATE COMPONENTS FOR PEOPLE WITH < 3 STATEMENTS\n",
    "\n",
    "  #recombine columns\n",
    "  df = pd.concat([other_cols, date_cols, num_cols, cat_cols], axis=1)\n",
    "\n",
    "  if df.isna().sum().sum() > 0:\n",
    "    print(f\"WARNING: {df.isna().sum().sum()} nulls still exist after imputing.\")\n",
    "  else:\n",
    "    print(\"No nulls exist after imputing.\")\n",
    "  \n",
    "  if len(label_cols)>0:\n",
    "    return df, df_labels\n",
    "  else:\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def sync_cols(train_df, pred_df):\n",
    "    for col in train_df.columns:\n",
    "      if col not in pred_df.columns:\n",
    "        print(col, \"not in pred_df so adding - should always be categorical!\")\n",
    "        pred_df[col] = 0\n",
    "    for col in pred_df.columns:\n",
    "      if col not in train_df.columns:\n",
    "        print(col, \"not in train_df so dropping\")\n",
    "        pred_df = pred_df.drop(col, axis=1)\n",
    "    return pred_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def amex_metric(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "\n",
    "    def top_four_percent_captured(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        df = (pd.concat([y_true, y_pred], axis='columns')\n",
    "              .sort_values('prediction', ascending=False))\n",
    "        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "        four_pct_cutoff = int(0.04 * df['weight'].sum())\n",
    "        df['weight_cumsum'] = df['weight'].cumsum()\n",
    "        df_cutoff = df.loc[df['weight_cumsum'] <= four_pct_cutoff]\n",
    "        return (df_cutoff['target'] == 1).sum() / (df['target'] == 1).sum()\n",
    "        \n",
    "    def weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        df = (pd.concat([y_true, y_pred], axis='columns')\n",
    "              .sort_values('prediction', ascending=False))\n",
    "        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "        df['random'] = (df['weight'] / df['weight'].sum()).cumsum()\n",
    "        total_pos = (df['target'] * df['weight']).sum()\n",
    "        df['cum_pos_found'] = (df['target'] * df['weight']).cumsum()\n",
    "        df['lorentz'] = df['cum_pos_found'] / total_pos\n",
    "        df['gini'] = (df['lorentz'] - df['random']) * df['weight']\n",
    "        return df['gini'].sum()\n",
    "\n",
    "    def normalized_weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        y_true_pred = y_true.rename(columns={'target': 'prediction'})\n",
    "        return weighted_gini(y_true, y_pred) / weighted_gini(y_true, y_true_pred)\n",
    "\n",
    "    g = normalized_weighted_gini(y_true, y_pred)\n",
    "    d = top_four_percent_captured(y_true, y_pred)\n",
    "\n",
    "    return 0.5 * (g + d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(r'../../amex-default-prediction/train_data.parquet')\n",
    "df = set_col_types(df)\n",
    "#reduce df for development !!!!! comment out line below for final model\n",
    "#df = df[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5531451 entries, 0 to 5531450\n",
      "Columns: 191 entries, customer_ID to target\n",
      "dtypes: category(12), datetime64[ns](1), float32(176), int64(1), object(1)\n",
      "memory usage: 3.9+ GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['S_2'] = np.int8(df['S_2'].dt.month) #reduce S_2 date column to month only for seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>S_2_1</th>\n",
       "      <th>P_2_1</th>\n",
       "      <th>D_39_1</th>\n",
       "      <th>B_1_1</th>\n",
       "      <th>B_2_1</th>\n",
       "      <th>R_1_1</th>\n",
       "      <th>S_3_1</th>\n",
       "      <th>D_41_1</th>\n",
       "      <th>B_3_1</th>\n",
       "      <th>...</th>\n",
       "      <th>D_136_3</th>\n",
       "      <th>D_137_3</th>\n",
       "      <th>D_138_3</th>\n",
       "      <th>D_139_3</th>\n",
       "      <th>D_140_3</th>\n",
       "      <th>D_141_3</th>\n",
       "      <th>D_142_3</th>\n",
       "      <th>D_143_3</th>\n",
       "      <th>D_144_3</th>\n",
       "      <th>D_145_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>2018-03-13</td>\n",
       "      <td>0.934745</td>\n",
       "      <td>0.009119</td>\n",
       "      <td>0.009382</td>\n",
       "      <td>1.007647</td>\n",
       "      <td>0.006104</td>\n",
       "      <td>0.135021</td>\n",
       "      <td>0.001604</td>\n",
       "      <td>0.007174</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.004594</td>\n",
       "      <td>0.003613</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007568</td>\n",
       "      <td>0.003004</td>\n",
       "      <td>0.006362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000fd6641609c6ece5454664794f0340ad84dddce9a2...</td>\n",
       "      <td>2018-03-25</td>\n",
       "      <td>0.880519</td>\n",
       "      <td>0.178126</td>\n",
       "      <td>0.034684</td>\n",
       "      <td>1.004028</td>\n",
       "      <td>0.006911</td>\n",
       "      <td>0.165509</td>\n",
       "      <td>0.005552</td>\n",
       "      <td>0.005068</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007274</td>\n",
       "      <td>0.008972</td>\n",
       "      <td>0.002497</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003979</td>\n",
       "      <td>0.006627</td>\n",
       "      <td>0.002178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00001b22f846c82c51f6e3958ccd81970162bae8b007e8...</td>\n",
       "      <td>2018-03-12</td>\n",
       "      <td>0.880875</td>\n",
       "      <td>0.009704</td>\n",
       "      <td>0.004284</td>\n",
       "      <td>0.812649</td>\n",
       "      <td>0.006450</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003796</td>\n",
       "      <td>0.007196</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009116</td>\n",
       "      <td>0.003886</td>\n",
       "      <td>0.000715</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007705</td>\n",
       "      <td>0.009415</td>\n",
       "      <td>0.000563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000041bdba6ecadd89a52d11886e8eaaec9325906c9723...</td>\n",
       "      <td>2018-03-29</td>\n",
       "      <td>0.621776</td>\n",
       "      <td>0.001083</td>\n",
       "      <td>0.012564</td>\n",
       "      <td>1.006183</td>\n",
       "      <td>0.007829</td>\n",
       "      <td>0.287766</td>\n",
       "      <td>0.004532</td>\n",
       "      <td>0.009937</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002382</td>\n",
       "      <td>0.003795</td>\n",
       "      <td>0.000637</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009453</td>\n",
       "      <td>0.004793</td>\n",
       "      <td>0.000834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8a...</td>\n",
       "      <td>2018-03-30</td>\n",
       "      <td>0.871900</td>\n",
       "      <td>0.005573</td>\n",
       "      <td>0.007679</td>\n",
       "      <td>0.815746</td>\n",
       "      <td>0.001247</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.005528</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002578</td>\n",
       "      <td>0.001665</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004662</td>\n",
       "      <td>0.002551</td>\n",
       "      <td>0.009652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458908</th>\n",
       "      <td>ffff41c8a52833b56430603969b9ca48d208e7c192c6a4...</td>\n",
       "      <td>2018-03-31</td>\n",
       "      <td>0.844229</td>\n",
       "      <td>0.447585</td>\n",
       "      <td>0.028515</td>\n",
       "      <td>1.009866</td>\n",
       "      <td>0.001928</td>\n",
       "      <td>0.128707</td>\n",
       "      <td>0.003482</td>\n",
       "      <td>0.005893</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008494</td>\n",
       "      <td>0.001622</td>\n",
       "      <td>0.009657</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005007</td>\n",
       "      <td>0.008420</td>\n",
       "      <td>0.002532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458909</th>\n",
       "      <td>ffff518bb2075e4816ee3fe9f3b152c57fc0e6f01bf7fd...</td>\n",
       "      <td>2018-03-22</td>\n",
       "      <td>0.831279</td>\n",
       "      <td>0.033670</td>\n",
       "      <td>0.292360</td>\n",
       "      <td>0.055656</td>\n",
       "      <td>0.006953</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005791</td>\n",
       "      <td>0.233078</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002530</td>\n",
       "      <td>0.007390</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007441</td>\n",
       "      <td>0.005510</td>\n",
       "      <td>0.002929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458910</th>\n",
       "      <td>ffff9984b999fccb2b6127635ed0736dda94e544e67e02...</td>\n",
       "      <td>2018-03-07</td>\n",
       "      <td>0.800522</td>\n",
       "      <td>0.267018</td>\n",
       "      <td>0.020563</td>\n",
       "      <td>1.007023</td>\n",
       "      <td>0.000957</td>\n",
       "      <td>0.066648</td>\n",
       "      <td>0.007424</td>\n",
       "      <td>0.006314</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004904</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458911</th>\n",
       "      <td>ffffa5c46bc8de74f5a4554e74e239c8dee6b9baf38814...</td>\n",
       "      <td>2018-03-23</td>\n",
       "      <td>0.754129</td>\n",
       "      <td>0.008619</td>\n",
       "      <td>0.015838</td>\n",
       "      <td>0.714486</td>\n",
       "      <td>0.000993</td>\n",
       "      <td>0.408849</td>\n",
       "      <td>0.003392</td>\n",
       "      <td>0.050048</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.009795</td>\n",
       "      <td>0.008908</td>\n",
       "      <td>0.941023</td>\n",
       "      <td>0.433807</td>\n",
       "      <td>1.003074</td>\n",
       "      <td>0.007104</td>\n",
       "      <td>0.182622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458912</th>\n",
       "      <td>fffff1d38b785cef84adeace64f8f83db3a0c31e8d92ea...</td>\n",
       "      <td>2018-03-14</td>\n",
       "      <td>0.982175</td>\n",
       "      <td>0.002474</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.992880</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.119165</td>\n",
       "      <td>0.003287</td>\n",
       "      <td>0.014092</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009955</td>\n",
       "      <td>0.009994</td>\n",
       "      <td>0.001088</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005693</td>\n",
       "      <td>0.006773</td>\n",
       "      <td>0.005566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>458913 rows × 569 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              customer_ID      S_2_1  \\\n",
       "0       0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f... 2018-03-13   \n",
       "1       00000fd6641609c6ece5454664794f0340ad84dddce9a2... 2018-03-25   \n",
       "2       00001b22f846c82c51f6e3958ccd81970162bae8b007e8... 2018-03-12   \n",
       "3       000041bdba6ecadd89a52d11886e8eaaec9325906c9723... 2018-03-29   \n",
       "4       00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8a... 2018-03-30   \n",
       "...                                                   ...        ...   \n",
       "458908  ffff41c8a52833b56430603969b9ca48d208e7c192c6a4... 2018-03-31   \n",
       "458909  ffff518bb2075e4816ee3fe9f3b152c57fc0e6f01bf7fd... 2018-03-22   \n",
       "458910  ffff9984b999fccb2b6127635ed0736dda94e544e67e02... 2018-03-07   \n",
       "458911  ffffa5c46bc8de74f5a4554e74e239c8dee6b9baf38814... 2018-03-23   \n",
       "458912  fffff1d38b785cef84adeace64f8f83db3a0c31e8d92ea... 2018-03-14   \n",
       "\n",
       "           P_2_1    D_39_1     B_1_1     B_2_1     R_1_1     S_3_1    D_41_1  \\\n",
       "0       0.934745  0.009119  0.009382  1.007647  0.006104  0.135021  0.001604   \n",
       "1       0.880519  0.178126  0.034684  1.004028  0.006911  0.165509  0.005552   \n",
       "2       0.880875  0.009704  0.004284  0.812649  0.006450       NaN  0.003796   \n",
       "3       0.621776  0.001083  0.012564  1.006183  0.007829  0.287766  0.004532   \n",
       "4       0.871900  0.005573  0.007679  0.815746  0.001247       NaN  0.000231   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "458908  0.844229  0.447585  0.028515  1.009866  0.001928  0.128707  0.003482   \n",
       "458909  0.831279  0.033670  0.292360  0.055656  0.006953       NaN  0.005791   \n",
       "458910  0.800522  0.267018  0.020563  1.007023  0.000957  0.066648  0.007424   \n",
       "458911  0.754129  0.008619  0.015838  0.714486  0.000993  0.408849  0.003392   \n",
       "458912  0.982175  0.002474  0.000077  0.992880  0.000809  0.119165  0.003287   \n",
       "\n",
       "           B_3_1  ...  D_136_3  D_137_3  D_138_3   D_139_3   D_140_3  \\\n",
       "0       0.007174  ...      NaN      NaN      NaN  0.000427  0.004594   \n",
       "1       0.005068  ...      NaN      NaN      NaN  0.007274  0.008972   \n",
       "2       0.007196  ...      NaN      NaN      NaN  0.009116  0.003886   \n",
       "3       0.009937  ...      NaN      NaN      NaN  0.002382  0.003795   \n",
       "4       0.005528  ...      NaN      NaN      NaN  0.002578  0.001665   \n",
       "...          ...  ...      ...      ...      ...       ...       ...   \n",
       "458908  0.005893  ...      NaN      NaN      NaN  0.008494  0.001622   \n",
       "458909  0.233078  ...      NaN      NaN      NaN  0.002530  0.007390   \n",
       "458910  0.006314  ...      NaN      NaN      NaN       NaN  0.000498   \n",
       "458911  0.050048  ...      NaN      NaN      NaN  1.009795  0.008908   \n",
       "458912  0.014092  ...      NaN      NaN      NaN  0.009955  0.009994   \n",
       "\n",
       "         D_141_3   D_142_3   D_143_3   D_144_3   D_145_3  \n",
       "0       0.003613       NaN  0.007568  0.003004  0.006362  \n",
       "1       0.002497       NaN  0.003979  0.006627  0.002178  \n",
       "2       0.000715       NaN  0.007705  0.009415  0.000563  \n",
       "3       0.000637       NaN  0.009453  0.004793  0.000834  \n",
       "4       0.000579       NaN  0.004662  0.002551  0.009652  \n",
       "...          ...       ...       ...       ...       ...  \n",
       "458908  0.009657       NaN  0.005007  0.008420  0.002532  \n",
       "458909  0.003150       NaN  0.007441  0.005510  0.002929  \n",
       "458910       NaN       NaN       NaN  0.004904       NaN  \n",
       "458911  0.941023  0.433807  1.003074  0.007104  0.182622  \n",
       "458912  0.001088       NaN  0.005693  0.006773  0.005566  \n",
       "\n",
       "[458913 rows x 569 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['statement_num'] = df.groupby(\"customer_ID\")['S_2'].rank(method='first', ascending=False).astype(int)\n",
    "df_1 = df[df['statement_num'] == 1] #last\n",
    "df_2 = df[df['statement_num'] == 2] #2nd last\n",
    "df_3 = df[df['statement_num'] == 3] #3rd last\n",
    "\n",
    "\n",
    "df_comb = df_1.merge(df_2, how='left', on='customer_ID', suffixes=('', '_2'))\n",
    "df_comb = df_comb.merge(df_3, how='left', on='customer_ID', suffixes=('_1', '_3'))\n",
    "df_comb = df_comb.drop(['statement_num_1','target_2', 'statement_num_2','target_3', 'statement_num_3'], axis=1)\n",
    "df_comb.rename(columns={'target_1':'target'}, inplace=True)\n",
    "df_comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_comb #overwriting df so I can reuse code from rf_pipeline\n",
    "del df_1\n",
    "del df_2\n",
    "del df_3\n",
    "del df_comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build list of columns with 50 percent missing values\n",
    "percent_null = df.isnull().sum() / len(df) \n",
    "half_missing_cols = percent_null[percent_null > 0.5].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4870428 nulls exist after drop\n",
      "No nulls exist after imputing.\n"
     ]
    }
   ],
   "source": [
    "#build model\n",
    "y = df['target']\n",
    "x = df.drop(columns=[\"target\"])\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=rand_state)\n",
    "# IMPORTANT! - MUST reset the index because numcols gets it's index reset by either simpleimputer or standardscaler so concat later on will produce mismatched rows\n",
    "x_train.reset_index(inplace=True, drop=True)\n",
    "x_test.reset_index(inplace=True, drop=True) \n",
    "y_train.reset_index(inplace=True, drop=True)\n",
    "y_test.reset_index(inplace=True, drop=True)\n",
    "\n",
    "x_train, x_train_labels = preprocess_data(x_train, label_cols=[\"customer_ID\"], drop_cols=half_missing_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_jobs=-1, random_state=1337)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_jobs=-1, random_state=1337)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_jobs=-1, random_state=1337)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_all = RandomForestClassifier(random_state=rand_state, n_jobs=-1)\n",
    "print(\"Fitting Model\")\n",
    "rf_all.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2085378 nulls exist after drop\n",
      "No nulls exist after imputing.\n"
     ]
    }
   ],
   "source": [
    "x_test, x_test_labels = preprocess_data(x_test, label_cols=[\"customer_ID\"], drop_cols=half_missing_cols)\n",
    "\n",
    "x_test = sync_cols(x_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7222298604754077\n"
     ]
    }
   ],
   "source": [
    "test_expected_df = pd.DataFrame(y_test, columns=['target'])\n",
    "test_expected_df['target'] = test_expected_df['target'].astype(int)\n",
    "\n",
    "test_predict_df = rf_all.predict_proba(x_test)\n",
    "test_predict_df = pd.DataFrame(test_predict_df,columns=[\"proba-inv\",\"prediction\"]).drop(columns=\"proba-inv\")\n",
    "\n",
    "print(amex_metric(test_expected_df, test_predict_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df #free up memory\n",
    "\n",
    "df = pd.read_parquet(r'../../amex-default-prediction/test_data.parquet')\n",
    "#reduce df for development !!!!! comment out line below for final model\n",
    "#df = df[:100000]\n",
    "\n",
    "df = set_col_types(df, target_col=False)\n",
    "\n",
    "df['statement_num'] = df.groupby(\"customer_ID\")['S_2'].rank(method='first', ascending=False).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df[df['statement_num'] == 1] #last\n",
    "df_2 = df[df['statement_num'] == 2] #2nd last\n",
    "df_3 = df[df['statement_num'] == 3] #3rd last\n",
    "\n",
    "\n",
    "df_comb = df_1.merge(df_2, how='left', on='customer_ID', suffixes=('', '_2'))\n",
    "df_comb = df_comb.merge(df_3, how='left', on='customer_ID', suffixes=('_1', '_3'))\n",
    "df_comb = df_comb.drop(['statement_num_1', 'statement_num_2', 'statement_num_3'], axis=1)\n",
    "df_comb.rename(columns={'target_1':'target'}, inplace=True)\n",
    "df_comb\n",
    "\n",
    "df = df_comb #overwriting df so I can reuse code from rf_pipeline\n",
    "\n",
    "del df_1\n",
    "del df_2\n",
    "del df_3\n",
    "del df_comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11012246 nulls exist after drop\n",
      "No nulls exist after imputing.\n",
      "D_64_1_-1 not in pred_df so adding - should always be categorical!\n",
      "D_68_1_0.0 not in pred_df so adding - should always be categorical!\n",
      "D_64_2_-1 not in pred_df so adding - should always be categorical!\n",
      "D_68_2_0.0 not in pred_df so adding - should always be categorical!\n",
      "D_64_3_-1 not in pred_df so adding - should always be categorical!\n",
      "D_68_3_0.0 not in pred_df so adding - should always be categorical!\n"
     ]
    }
   ],
   "source": [
    "df, df_labels = preprocess_data(df, label_cols=[\"customer_ID\"], drop_cols=half_missing_cols)\n",
    "\n",
    "df = sync_cols(x_train, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Neo\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names must be in the same order as they were in fit.\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n",
      "c:\\Users\\Neo\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names must be in the same order as they were in fit.\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "rf_wide_prediction_preds = rf_all.predict(df)\n",
    "rf_wide_prediction_proba = rf_all.predict_proba(df)\n",
    "rf_wide_prediction_output = pd.concat([df_labels,pd.DataFrame(rf_wide_prediction_preds,columns=[\"pred\"]),pd.DataFrame(rf_wide_prediction_proba,columns=[\"proba-inv\",\"proba\"])], axis=1)\n",
    "\n",
    "rf_wide_prediction_output = rf_wide_prediction_output.drop(['pred', 'proba-inv'], axis=1)\n",
    "rf_wide_prediction_output = rf_wide_prediction_output.rename(columns={\"proba\":\"prediction\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_wide_prediction_output.to_csv(r\"..\\..\\amex-default-prediction\\rf_wide_neg_one_output.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e79cebfffb2e3a4b7d2d2fd53b48f0eab2f20a6a535e26e1d02c2764acd76f0c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
