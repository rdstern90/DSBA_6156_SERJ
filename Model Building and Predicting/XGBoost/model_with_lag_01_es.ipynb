{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import xgboost as xgb\n",
    "\n",
    "rand_state = 1337"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use features according to pickled lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original features: 61 , lag-features: 37 , total features: 98\n"
     ]
    }
   ],
   "source": [
    "f = open('./../../Feature selection/initial_featurelists/features_n61.pickle', 'rb')\n",
    "featurelist = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open(\"./../../Feature selection/initial_featurelists/lag_features_n37.pickle\", 'rb')\n",
    "lagfeaturelist = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "print('original features:', len(featurelist), ', lag-features:', len(lagfeaturelist), ', total features:', len(featurelist)+len(lagfeaturelist) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Pipelines & Functions: \n",
    "1. Pipelines\n",
    "2. Train preprocessing \n",
    "3. Train sampling \n",
    "4. Train scoring \n",
    "5. Test preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipelines: Defining the categorical imputation and one-hot encoder for categorical variables.\n",
    "categorical_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"impute\", SimpleImputer(strategy=\"most_frequent\"))\n",
    "        # (\"oh-encode\", OneHotEncoder(handle_unknown=\"ignore\", sparse=False)), #Commented out because the categorical variables won't play nice with dummies between test/train. Retry when we do a full train model. Can impute values on test_data.csv if necessary.\n",
    "    ]\n",
    ")\n",
    "\n",
    "# defining the numerical imputation and standard scaler for numerical variables.\n",
    "numeric_pipeline = Pipeline(\n",
    "    steps=[(\"impute\", SimpleImputer(strategy=\"mean\")), \n",
    "           (\"scale\", StandardScaler())]\n",
    ")\n",
    "\n",
    "\n",
    "# def_prep_df: Preparing the TRAINING data for creating and testing the model.\n",
    "def prep_df(df, target, target_to_drop):\n",
    "\n",
    "    # save indices\n",
    "    df_index = df.index\n",
    "    # save statement_age column\n",
    "    statement_age_s = df['statement_age']\n",
    "\n",
    "    # Drop columns that shouldn't be scaled or imputed\n",
    "    df = df.drop(columns=[\"s_2\", 'statement_age', target_to_drop])\n",
    "\n",
    "    # Missing values handling\n",
    "    missing_props = df.isna().mean(axis=0)\n",
    "    \n",
    "\n",
    "    over_threshold = missing_props[missing_props >= 0.4]\n",
    "    df.drop(over_threshold.index, axis=1, inplace=True)\n",
    "\n",
    "    \n",
    "    \n",
    "    # Split into predictors and target\n",
    "    X = df.drop(columns=[target])\n",
    "    y = df[target]\n",
    "\n",
    "    # Split categorical and numerical columns\n",
    "    cat_cols_all = ['b_30', 'b_38', 'd_114', 'd_116', 'd_117', 'd_120', 'd_126', 'd_63', 'd_64', 'd_66', 'd_68', 'b_31', 'd_87']\n",
    "    cat_cols = [col for col in X.columns.str.lower() if col in cat_cols_all]\n",
    "    num_cols = [col for col in X.columns.str.lower() if col not in cat_cols]\n",
    "    \n",
    "    # get dummies for categorical variables\n",
    "    Xcat = pd.get_dummies(X[cat_cols], columns=cat_cols, drop_first=True)\n",
    "    \n",
    "    X = pd.concat([X[num_cols],Xcat], axis=1)\n",
    "    X.columns = X.columns.str.lower()\n",
    "    cols_list = X.columns.tolist()\n",
    "\n",
    "    cat_cols = [col for col in cols_list if col not in num_cols]\n",
    "   \n",
    "\n",
    "\n",
    "    full_processor = ColumnTransformer(\n",
    "        transformers=[\n",
    "        (\"numeric\", numeric_pipeline, num_cols),\n",
    "        (\"categorical\", categorical_pipeline, cat_cols),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "    \n",
    "    # Apply preprocessing\n",
    "    X_processed = full_processor.fit_transform(X)\n",
    "    X_processed = pd.concat([pd.DataFrame(X_processed, index=df_index), statement_age_s], axis=1)\n",
    "    print(X_processed.shape)\n",
    "\n",
    "    y_processed = SimpleImputer(strategy=\"most_frequent\").fit_transform(\n",
    "            y.values.reshape(-1, 1)\n",
    "            )\n",
    "    y_processed = pd.DataFrame(y_processed, index=df_index)\n",
    "\n",
    "    \n",
    "    return X_processed, y_processed, cols_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_train_test(df_train, df_train_y, X_processed, y_processed, usefraction):\n",
    "    n = 100\n",
    "    ids = np.array(df_train_y.index)\n",
    "    target = np.array(df_train_y['target'])\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=n, shuffle=True, random_state=rand_state)\n",
    "    skf.get_n_splits(ids, target)\n",
    "\n",
    "    i = 0\n",
    "    id_subsets = [None]*n\n",
    "    for _, subset in skf.split(ids, target):\n",
    "        id_subsets[i] =list(ids[subset])\n",
    "        i += 1\n",
    "\n",
    "    \n",
    "    list1 = list(np.arange(0, int(usefraction[0]*100), 1))\n",
    "    list2 = list(np.arange(int(usefraction[0]*100), int(usefraction[0]*100)+int(usefraction[1]*100), 1))\n",
    "\n",
    "\n",
    "    train_ids = []\n",
    "    for i in list1:\n",
    "        train_ids.extend(id_subsets[i])\n",
    "    test_ids = []\n",
    "    for i in list2:\n",
    "        test_ids.extend(id_subsets[i])\n",
    "\n",
    "\n",
    "    X_train = X_processed[df_train.index.isin(train_ids)]\n",
    "    y_train = y_processed[df_train.index.isin(train_ids)]\n",
    "    X_test = X_processed[df_train.index.isin(test_ids)]\n",
    "    y_test = y_processed[df_train.index.isin(test_ids)]\n",
    "\n",
    "\n",
    "    print(f'Train data obs.: {len(X_train)}')\n",
    "    print(f'Test data obs: {len(X_test)}')\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def amex_metric(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "\n",
    "    def top_four_percent_captured(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        df = (pd.concat([y_true, y_pred], axis='columns')\n",
    "              .sort_values('prediction', ascending=False))\n",
    "        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "        four_pct_cutoff = int(0.04 * df['weight'].sum())\n",
    "        df['weight_cumsum'] = df['weight'].cumsum()\n",
    "        df_cutoff = df.loc[df['weight_cumsum'] <= four_pct_cutoff]\n",
    "        return (df_cutoff['target'] == 1).sum() / (df['target'] == 1).sum()\n",
    "        \n",
    "    def weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        df = (pd.concat([y_true, y_pred], axis='columns')\n",
    "              .sort_values('prediction', ascending=False))\n",
    "        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "        df['random'] = (df['weight'] / df['weight'].sum()).cumsum()\n",
    "        total_pos = (df['target'] * df['weight']).sum()\n",
    "        df['cum_pos_found'] = (df['target'] * df['weight']).cumsum()\n",
    "        df['lorentz'] = df['cum_pos_found'] / total_pos\n",
    "        df['gini'] = (df['lorentz'] - df['random']) * df['weight']\n",
    "        return df['gini'].sum()\n",
    "\n",
    "    def normalized_weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        y_true_pred = y_true.rename(columns={'target': 'prediction'})\n",
    "        return weighted_gini(y_true, y_pred) / weighted_gini(y_true, y_true_pred)\n",
    "\n",
    "    g = normalized_weighted_gini(y_true, y_pred)\n",
    "    d = top_four_percent_captured(y_true, y_pred)\n",
    "\n",
    "    return 0.5 * (g + d)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def prep_test_df(df, selected_features):\n",
    "    # save indices\n",
    "    df_index = df.index\n",
    "    # save statement_age column\n",
    "    statement_age_s = df['statement_age']\n",
    "\n",
    "    # Drop columns that shouldn't be scaled or imputed\n",
    "    X = df.drop(columns=[\"s_2\", 'statement_age'])\n",
    "\n",
    "    # Missing values handling\n",
    "    missing_props = df.isna().mean(axis=0)\n",
    "    over_threshold = missing_props[missing_props >= 0.4]\n",
    "    df.drop(over_threshold.index, axis=1, inplace=True)\n",
    "\n",
    "    cols_list = list(df.columns.str.lower())\n",
    "\n",
    "\n",
    "    # Split categorical and numerical columns\n",
    "    cat_cols_all = ['b_30', 'b_38', 'd_114', 'd_116', 'd_117', 'd_120', 'd_126', 'd_63', 'd_64', 'd_66', 'd_68', 'b_31', 'd_87']\n",
    "    cat_cols = [col for col in X.columns if col in cat_cols_all]\n",
    "    num_cols = [col for col in X.columns if col not in cat_cols]\n",
    "\n",
    "    # get dummies for categorical variables\n",
    "    Xcat = pd.get_dummies(X[cat_cols], columns=cat_cols, drop_first=True)\n",
    "    X = pd.concat([X[num_cols],Xcat], axis=1)\n",
    "\n",
    "    X.columns = X.columns.str.lower()\n",
    "    cols_list = X.columns.tolist()\n",
    "\n",
    "    cat_cols = [col for col in cols_list if col not in num_cols]\n",
    "\n",
    "\n",
    "    # Split list of numerical features into sublist for imputing and scaling in chunks\n",
    "    sublist_size = 20\n",
    "    sublists_cols = [num_cols[x:x+sublist_size] for x in range(0, len(num_cols), sublist_size)]\n",
    "\n",
    "\n",
    "    i = 0\n",
    "    for sublist in sublists_cols:\n",
    "        full_processor = ColumnTransformer(transformers=[(\"numeric\", numeric_pipeline, sublist)])\n",
    "        if i == 0:\n",
    "            X_num = pd.DataFrame(full_processor.fit_transform(X[sublist]), index=df_index, columns=sublist)\n",
    "        else:\n",
    "            X_num = pd.concat([X_num, pd.DataFrame(full_processor.fit_transform(X[sublist]), index=df_index, columns=sublist)], axis=1)\n",
    "        i +=1\n",
    "\n",
    "\n",
    "    X_processed = pd.concat([X_num, X[cat_cols], statement_age_s], axis=1)\n",
    "    X_processed = X_processed[selected_features + ['statement_age']]\n",
    "    print(X_processed.shape)\n",
    "\n",
    "\n",
    "    return X_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create initial train df to be further processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_x = pd.read_parquet('./../../ignore/train.parquet', columns=(['customer_ID', 'S_2'] + featurelist))\n",
    "df_train_x.columns = df_train_x.columns.str.lower()\n",
    "df_train_x = df_train_x.sort_values(['customer_id', 's_2'])\n",
    "df_train_x = df_train_x.set_index('customer_id')\n",
    "\n",
    "df_train_y = pd.read_csv('./../../ignore/train_labels.csv')\n",
    "df_train_y.columns = df_train_y.columns.str.lower()\n",
    "df_train_y = df_train_y.set_index('customer_id')\n",
    "\n",
    "\n",
    "\n",
    "df_train = pd.merge(df_train_x, df_train_y, left_index=True, right_on='customer_id', how='left')\n",
    "\n",
    "df_train['statement_age'] = (df_train.groupby(df_train.index)['s_2']\n",
    "                      .rank(method='dense', ascending=False)\n",
    "                      .astype(int)\n",
    "                   )\n",
    "\n",
    "df_train['last_statement_target'] = df_train['target']*df_train['statement_age'].apply(lambda x: 1 if x==1 else 0)\n",
    "\n",
    "# join lag features (dfl = delta first last) (repeated identical values for all statements)\n",
    "df_train = df_train.join(pd.read_parquet('./../../ignore/train_dfl.parquet', columns=lagfeaturelist), how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select which statements to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_statements = [1,2,3]\n",
    "df_train = df_train[df_train['statement_age'].isin(use_statements)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process remaining data after selecting statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1360401, 120)\n"
     ]
    }
   ],
   "source": [
    "# Prep the dataframe\n",
    "# Note that the last column 'statement_age' is left in the dataframes for scoring, not for predicting!\n",
    "X_processed, y_processed, cols_list = prep_df(df_train, target='target', target_to_drop='last_statement_target')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get train samples for training and testing with train sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data obs.: 68032\n",
      "Test data obs: 68024\n"
     ]
    }
   ],
   "source": [
    "# First vale of \"usefraction\" specifies the train size and the second, the test size (fraction of total train data available)\n",
    "X_train, X_test, y_train, y_test = get_train_test(df_train, df_train_y, X_processed, y_processed, usefraction = [0.05, 0.05])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature selection loop with XGB using feature importances prior to model tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1, Duration: 5.881 s, Score: 0.74494, Number of features: 119\n",
      "Iter 2, Duration: 5.842 s, Score: 0.74716, Number of features: 96\n",
      "Iter 3, Duration: 4.731 s, Score: 0.74833, Number of features: 73\n",
      "Iter 4, Duration: 4.034 s, Score: 0.74538, Number of features: 54\n",
      "Iter 5, First fit yielded too low score, trying again (number of features attempted: 40\n",
      "Iter 5, Duration: 7.701 s, Score: 0.74163 - Iteration failed, too large accuracy loss ([-0.0066929])\n",
      "Current feature reduction rate: 0.1\n",
      "Iter 6, Duration: 4.152 s, Score: 0.74538, Number of features: 54\n",
      "Iter 7, First fit yielded too low score, trying again (number of features attempted: 50\n",
      "Iter 7, Duration: 11.096 s, Score: 0.73978 - Iteration failed, too large accuracy loss ([-0.00855058])\n",
      "Current feature reduction rate: 0.05\n",
      "Iter 8, Duration: 5.569 s, Score: 0.74538, Number of features: 54\n",
      "Iter 9, First fit yielded too low score, trying again (number of features attempted: 52\n",
      "Iter 9, Duration: 10.008 s, Score: 0.74397 - Iteration failed, too large accuracy loss ([-0.0043615])\n",
      "Current feature reduction rate: 0.025\n",
      "Iter 10, Duration: 4.595 s, Score: 0.74538, Number of features: 54\n",
      "Iter 11, First fit yielded too low score, trying again (number of features attempted: 53\n",
      "Iter 11, Duration: 10.039 s, Score: 0.7439 - Iteration failed, too large accuracy loss ([-0.00442895])\n",
      "Completed\n"
     ]
    }
   ],
   "source": [
    "feature_reduction_rate = 0.2 # Attempt to remove 10% of remaining features in each loop iteration\n",
    "accuracy_loss = 0.003 # accepted accuracy loss c.f. max accuracy\n",
    "scoring_method = 'last_statement'\n",
    "\n",
    "\n",
    "scores = []\n",
    "feature_ind = [list(range(0,(X_train.shape[1]-1)))]\n",
    "feature_names = [cols_list]\n",
    "remove_n_features = [int(len(feature_ind[0])*feature_reduction_rate)]\n",
    "i = 0\n",
    "\n",
    "\n",
    "def get_reduced_features(xgbc, feature_names, remove_n_features):\n",
    "    xgb_feature_imp = pd.DataFrame({'name':feature_names,\n",
    "                                    'importances':[val[0] for val in xgbc.feature_importances_.reshape(-1,1)]})\n",
    "\n",
    "    xgb_feature_imp = xgb_feature_imp.sort_values(by='importances', ascending=False)\n",
    "    \n",
    "    df_features = xgb_feature_imp.iloc[:-remove_n_features,:]\n",
    "    feature_ind = df_features.index\n",
    "    feature_names = df_features['name']\n",
    "\n",
    "\n",
    "    return feature_ind, feature_names\n",
    "\n",
    "\n",
    "\n",
    "def fit_predict(feature_ind, feature_names, remove_n_features, X_train, y_train, X_test, y_test):\n",
    "    xgbc = xgb.XGBClassifier(use_label_encoder=False).fit(X_train[feature_ind], y_train, verbose=0, eval_metric='logloss')\n",
    "    \n",
    "    y_pred_a_xgb = pd.DataFrame({'customer_id':X_test.index.values,\n",
    "                            'scoring_var':X_test.iloc[:,-1].values,\n",
    "                            'prediction':[val[1] for val in xgbc.predict_proba(X_test[feature_ind])]})\n",
    "    \n",
    "    if scoring_method == 'last_statement':\n",
    "        proba_xgb = y_pred_a_xgb[y_pred_a_xgb['scoring_var']==1].set_index('customer_id')\n",
    "\n",
    "    elif scoring_method == 'delta0':\n",
    "        proba_xgb = y_pred_a_xgb[y_pred_a_xgb['scoring_var']==0].set_index('customer_id')\n",
    "\n",
    "    elif scoring_method == 'delta1':\n",
    "        proba_xgb = y_pred_a_xgb[y_pred_a_xgb['scoring_var']==1].set_index('customer_id')\n",
    "\n",
    "    elif scoring_method == 'average-deltas':\n",
    "        proba_xgb = y_pred_a_xgb.groupby('customer_id')['prediction'].mean()\n",
    "    \n",
    "    score = [amex_metric(y_test.groupby(y_test.index).max().rename(columns={0:'target'}), proba_xgb)]\n",
    "    feature_ind, feature_names = get_reduced_features(xgbc, feature_names, remove_n_features)\n",
    "\n",
    "    return score, feature_ind, feature_names, xgbc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "    start_time = time.time()\n",
    "\n",
    "    cscore, cfeature_ind, cfeature_names, cxgb = fit_predict(feature_ind[i], feature_names[i], remove_n_features[i], X_train, y_train, X_test, y_test) # \"c\" denotes current\n",
    "    scores += cscore # add score to list\n",
    "\n",
    "    if i > 0:\n",
    "        if (max(scores) - scores[i]) >= accuracy_loss: # Maximum residual between max and current score\n",
    "            \n",
    "            print(f'Iter {i+1}, First fit yielded too low score, trying again (number of features attempted: {len(feature_ind[i])}')\n",
    "            cscore, cfeature_ind, cfeature_names, cxgb = fit_predict(feature_ind[i], feature_names[i], remove_n_features[i], X_train, y_train, X_test, y_test) # \"c\" denotes current\n",
    "\n",
    "            if (max(scores) - cscore) >= accuracy_loss: # use same criterion again\n",
    "                \n",
    "                # print(f'Iter {i+1}, Duration: {round((time.time() - start_time),3)} s, Iteration failed, too large accuracy loss ({cscore-max(scores)}), removing fewer features')\n",
    "                print(f'Iter {i+1}, Duration: {round((time.time() - start_time),3)} s, Score: {round(scores[i],5)} - Iteration failed, too large accuracy loss ({cscore-max(scores)})')\n",
    "                feature_ind += [feature_ind[i-1]] # add list of feature indices to list\n",
    "                feature_names += [feature_names[i-1]] # add list of feature names to list\n",
    "\n",
    "                feature_reduction_rate = feature_reduction_rate*0.5 # decrease feature reduction rate if iteration failed\n",
    "\n",
    "                if int(len(feature_ind[i])*feature_reduction_rate) >= 1: # Check that at least 1 feature can be removed\n",
    "                    remove_n_features += [int(len(feature_ind[i])*feature_reduction_rate)]\n",
    "                    print(f'Current feature reduction rate: {feature_reduction_rate}')\n",
    "                    i += 1\n",
    "                    continue\n",
    "                else:\n",
    "                    print('Completed')\n",
    "                    break\n",
    "\n",
    "\n",
    "            else:\n",
    "                scores[i] = cscore # Overwrite first fit score with 2nd fit score\n",
    "                print(f'Iter {i+1},  Retry successful')\n",
    "\n",
    "\n",
    "\n",
    "    feature_ind += [cfeature_ind] # add list of feature indices to list\n",
    "    feature_names += [cfeature_names] # add list of feature names to list\n",
    "    remove_n_features += [int(len(feature_ind[i])*feature_reduction_rate)]\n",
    "    \n",
    "    print(f'Iter {i+1}, Duration: {round((time.time() - start_time),3)} s, Score: {round(scores[i],5)}, Number of features: {len(feature_ind[i])}')\n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features= list(feature_names[len(feature_names)-2])\n",
    "ind_selected_features= feature_ind[len(feature_names)-2]\n",
    "\n",
    "# f = open('features_and_lagfeatures_0.pickle', 'wb')\n",
    "# pickle.dump(list(selected_features), f)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data obs.: 68032\n",
      "Test data obs: 68024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           enable_categorical=False, gamma=None,\n",
       "                                           gpu_id=None, importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=None,\n",
       "                                           max_delta_step=None, max_depth=None,\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_constraints...\n",
       "                                           scale_pos_weight=None,\n",
       "                                           subsample=None, tree_method=None,\n",
       "                                           use_label_encoder=False,\n",
       "                                           validate_parameters=None,\n",
       "                                           verbosity=None),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'colsample_bytree': [0.3, 0.4, 0.5,\n",
       "                                                             0.7],\n",
       "                                        'eval_metric': ['logloss'],\n",
       "                                        'gamma': [0.0, 0.1, 0.2, 0.3, 0.4],\n",
       "                                        'learning_rate': [0.05, 0.1, 0.15, 0.2,\n",
       "                                                          0.25, 0.3],\n",
       "                                        'max_depth': [5, 6, 8, 10, 12, 15],\n",
       "                                        'min_child_weight': [1, 3, 5, 7]},\n",
       "                   scoring='roc_auc')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tune parameters of model with selected features\n",
    "X_train, X_test, y_train, y_test = get_train_test(df_train, df_train_y, X_processed, y_processed, usefraction = [0.05, 0.05])\n",
    "\n",
    "classifier = xgb.XGBClassifier(use_label_encoder=False)\n",
    "\n",
    "params = {\n",
    "    'learning_rate' : [0.05, 0.10, 0.15, 0.20, 0.25, 0.30],\n",
    "    'max_depth' : [5, 6, 8, 10, 12, 15],\n",
    "    'min_child_weight' : [1, 3, 5, 7],\n",
    "    'gamma': [0.0, 0.1, 0.2, 0.3, 0.4],\n",
    "    'colsample_bytree' : [0.3, 0.4, 0.5, 0.7],\n",
    "    'eval_metric': ['logloss']\n",
    "}\n",
    "\n",
    "model_tune=RandomizedSearchCV(classifier, param_distributions=params, n_iter=10, scoring='roc_auc', n_jobs=-1, cv=5,verbose=0)\n",
    "model_tune.fit(X_train[ind_selected_features],y_train, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default xgb-model score: [0.7438977273160245]\n",
      "Tuned xgb-model score: [0.761865571556257]\n"
     ]
    }
   ],
   "source": [
    "tuned_model = model_tune.best_estimator_ \n",
    "scoring_method == 'last_statement'\n",
    "\n",
    "def post_predict(model, feature_ind, scoring_method, X_train, X_test, y_train, y_test):\n",
    "    xgb_base = xgb.XGBClassifier(use_label_encoder=False).fit(X_train[feature_ind], y_train, verbose=0, eval_metric='logloss')\n",
    "    y_pred_pre = pd.DataFrame({'customer_id':X_test.index.values,\n",
    "                            'scoring_var':X_test.iloc[:,-1].values,\n",
    "                            'prediction':[val[1] for val in xgb_base.predict_proba(X_test[feature_ind])]})\n",
    "    \n",
    "    xgb_tuned = model\n",
    "    y_pred_post = pd.DataFrame({'customer_id':X_test.index.values,\n",
    "                            'scoring_var':X_test.iloc[:,-1].values,\n",
    "                            'prediction':[val[1] for val in xgb_tuned.predict_proba(X_test[feature_ind])]})\n",
    "    \n",
    "    if scoring_method == 'last_statement':\n",
    "        proba_xgb_pre = y_pred_pre[y_pred_pre['scoring_var']==1].set_index('customer_id')\n",
    "        proba_xgb_post = y_pred_post[y_pred_post['scoring_var']==1].set_index('customer_id')\n",
    "\n",
    "    elif scoring_method == 'xxxx':\n",
    "        print('scoring method not yet defined')\n",
    "\n",
    "    \n",
    "    score_pre = [amex_metric(y_test.groupby(y_test.index).max().rename(columns={0:'target'}), proba_xgb_pre)]\n",
    "    score_post = [amex_metric(y_test.groupby(y_test.index).max().rename(columns={0:'target'}), proba_xgb_post)]\n",
    "    \n",
    "    print(f'Default xgb-model score: {score_pre}')\n",
    "    print(f'Tuned xgb-model score: {score_post}')\n",
    "\n",
    "    return [score_pre, score_post]\n",
    "\n",
    "\n",
    "val_scores = post_predict(tuned_model, ind_selected_features, scoring_method, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare test data sample and make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_parquet('./../../ignore/test.parquet', columns=(['customer_ID', 'S_2'] + featurelist))\n",
    "df_test.columns = df_test.columns.str.lower()\n",
    "df_test = df_test.sort_values(['customer_id', 's_2'])\n",
    "df_test = df_test.set_index('customer_id')\n",
    "\n",
    "# join lag features (dfl = delta first last) (repeated identical values for all statements)\n",
    "df_test = df_test.join(pd.read_parquet('./../../ignore/test_dfl.parquet', columns=lagfeaturelist), how='left')\n",
    "\n",
    "df_test['statement_age'] = (df_test.groupby(df_test.index)['s_2']\n",
    "                      .rank(method='dense', ascending=False)\n",
    "                      .astype(int)\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selct which statements to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_statements = [1,2,3]\n",
    "df_test = df_test[df_test['statement_age'].isin(use_statements)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2754035, 54)\n"
     ]
    }
   ],
   "source": [
    "X_processed_test = prep_test_df(df_test, selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict with the tuned classifier\n",
    "# tuned_model = model_tune.best_estimator_ \n",
    "scoring_method == 'last_statement'\n",
    "\n",
    "def predict_on_test(model, scoring_method, X):\n",
    "    y_pred = pd.DataFrame({'customer_ID':X.index.values,\n",
    "                            'scoring_var':X.iloc[:,-1].values,\n",
    "                            'prediction':[val[1] for val in model.predict_proba(X.iloc[:,:-1])]})\n",
    "    \n",
    "    if scoring_method == 'last_statement':\n",
    "        y_pred = y_pred[y_pred['scoring_var']==1].set_index('customer_ID').drop(columns='scoring_var')\n",
    "        # y_pred = y_pred[y_pred['scoring_var']==1].drop(columns='scoring_var')\n",
    "\n",
    "    elif scoring_method == 'xxxx':\n",
    "        print('scoring method not yet defined')\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "test_predictions = predict_on_test(tuned_model, 'last_statement', X_processed_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions.to_csv('./../../ignore/_my_submissions/submission1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ca7b95862a80fe182a4f5fb98c5ac1654efde8b126ad722bfd53b4f5adb0e8de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
