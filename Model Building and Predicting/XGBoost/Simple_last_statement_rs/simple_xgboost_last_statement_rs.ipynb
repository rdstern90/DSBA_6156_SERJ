{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amex_metric(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "\n",
    "    def top_four_percent_captured(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        df = (pd.concat([y_true, y_pred], axis='columns')\n",
    "              .sort_values('prediction', ascending=False))\n",
    "        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "        four_pct_cutoff = int(0.04 * df['weight'].sum())\n",
    "        df['weight_cumsum'] = df['weight'].cumsum()\n",
    "        df_cutoff = df.loc[df['weight_cumsum'] <= four_pct_cutoff]\n",
    "        return (df_cutoff['target'] == 1).sum() / (df['target'] == 1).sum()\n",
    "        \n",
    "    def weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        df = (pd.concat([y_true, y_pred], axis='columns')\n",
    "              .sort_values('prediction', ascending=False))\n",
    "        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "        df['random'] = (df['weight'] / df['weight'].sum()).cumsum()\n",
    "        total_pos = (df['target'] * df['weight']).sum()\n",
    "        df['cum_pos_found'] = (df['target'] * df['weight']).cumsum()\n",
    "        df['lorentz'] = df['cum_pos_found'] / total_pos\n",
    "        df['gini'] = (df['lorentz'] - df['random']) * df['weight']\n",
    "        return df['gini'].sum()\n",
    "\n",
    "    def normalized_weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        y_true_pred = y_true.rename(columns={'target': 'prediction'})\n",
    "        return weighted_gini(y_true, y_pred) / weighted_gini(y_true, y_true_pred)\n",
    "\n",
    "    g = normalized_weighted_gini(y_true, y_pred)\n",
    "    d = top_four_percent_captured(y_true, y_pred)\n",
    "\n",
    "    return 0.5 * (g + d)\n",
    "\n",
    "def set_col_types(df):\n",
    "    if \"target\" in df.columns:\n",
    "        categorical_cols = ['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_63', 'D_64', 'D_66', 'D_68', 'target']\n",
    "    else:\n",
    "        categorical_cols = ['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_63', 'D_64', 'D_66', 'D_68']\n",
    "    df['customer_ID'] = df['customer_ID'].astype(\"string\")\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        df[col] = df[col].astype(\"string\")\n",
    "    df[\"S_2\"] = pd.to_datetime(df['S_2'], format=r'%Y-%m-%d').astype('datetime64[ns]')\n",
    "    df[\"B_31\"] = df[\"B_31\"].astype(np.int8)\n",
    "    return df\n",
    "\n",
    "def sync_cols(train_df, pred_df):\n",
    "    for col in train_df.columns:\n",
    "      if col not in pred_df.columns:\n",
    "        print(col, \"not in pred_df so adding - should always be categorical!\")\n",
    "        pred_df[col] = 0\n",
    "    for col in pred_df.columns:\n",
    "      if col not in train_df.columns:\n",
    "        print(col, \"not in train_df so dropping\")\n",
    "        pred_df = pred_df.drop(col, axis=1)\n",
    "    return pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.92961   0.93295   0.93128    102185\n",
      "           1    0.80493   0.79658   0.80074     35489\n",
      "\n",
      "    accuracy                        0.89780    137674\n",
      "   macro avg    0.86727   0.86477   0.86601    137674\n",
      "weighted avg    0.89747   0.89780   0.89763    137674\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read data from parquet file\n",
    "df = pd.read_parquet(r\"../../../amex-default-prediction/train_data.parquet\")\n",
    "#reduce df for development !!!!! comment out line below for final model\n",
    "#df = df[:100000]\n",
    "\n",
    "# Set the data types for the columns\n",
    "df = set_col_types(df)\n",
    "\n",
    "#engineer statement num\n",
    "df['statement_num'] = df.groupby(\"customer_ID\")['S_2'].rank(method='first', ascending=False).astype(np.int8) \n",
    "df = df[df[\"statement_num\"] == 1]\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "#engineer date cols\n",
    "df[\"Month\"] = df[\"S_2\"].dt.month\n",
    "df[\"Day\"] = df[\"S_2\"].dt.day\n",
    "df[\"Year\"] = df[\"S_2\"].dt.year\n",
    "df = df.drop([\"S_2\"], axis=1)\n",
    "\n",
    "# Separate target variable and feature columns\n",
    "target = df[\"target\"].astype(int)\n",
    "labels = df['customer_ID']\n",
    "features = df.drop([\"customer_ID\", \"target\"], axis=1)\n",
    "\n",
    "# Impute missing values using mode for categorical columns and median for numerical columns\n",
    "cat_columns = features.select_dtypes(include=[\"string\"]).columns\n",
    "num_columns = features.select_dtypes(include=\"number\").columns\n",
    "\n",
    "# Replace missing values in the categorical columns with the most frequent value\n",
    "for col in cat_columns:\n",
    "    features[col].fillna(\"NA\", inplace=True)\n",
    "\n",
    "# Replace missing values in the numerical columns with the median value\n",
    "for col in num_columns:\n",
    "    features[col].fillna(features[col].mean(), inplace=True)\n",
    "\n",
    "features = pd.get_dummies(features)\n",
    "\n",
    "features = features.sort_index(axis=1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create XGBoost model\n",
    "model = xgb.XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "print(classification_report(y_test, y_pred, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7742451693185308"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amex_test = y_test.reset_index(drop=True).to_frame()\n",
    "amex_test['target'] = amex_test['target'].astype('int')\n",
    "\n",
    "amex_pred = model.predict_proba(X_test)\n",
    "amex_pred = pd.DataFrame(amex_pred,columns=[\"proba-inv\",\"proba\"])\n",
    "amex_pred = amex_pred.drop(columns=['proba-inv'])\n",
    "amex_pred = amex_pred.rename(columns={\"proba\":\"prediction\"})\n",
    "\n",
    "\n",
    "amex_metric(amex_test, amex_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read test data from parquet file\n",
    "df = pd.read_parquet(r\"../../../amex-default-prediction/test_data.parquet\")\n",
    "#df = df[:100000]\n",
    "\n",
    "# Set the data types for the columns\n",
    "df = set_col_types(df)\n",
    "\n",
    "# Engineer statement num\n",
    "df['statement_num'] = df.groupby(\"customer_ID\")['S_2'].rank(method='first', ascending=False).astype(np.int8)\n",
    "df = df[df[\"statement_num\"] == 1]\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "# Engineer date cols\n",
    "df[\"Month\"] = df[\"S_2\"].dt.month\n",
    "df[\"Day\"] = df[\"S_2\"].dt.day\n",
    "df[\"Year\"] = df[\"S_2\"].dt.year\n",
    "df = df.drop([\"S_2\"], axis=1)\n",
    "\n",
    "# Separate labels and feature columns\n",
    "labels = df['customer_ID']\n",
    "features = df.drop([\"customer_ID\"], axis=1)\n",
    "\n",
    "# Impute missing values using mode for categorical columns and median for numerical columns\n",
    "cat_columns = features.select_dtypes(include=[\"string\"]).columns\n",
    "num_columns = features.select_dtypes(include=\"number\").columns\n",
    "\n",
    "# Replace missing values in the categorical columns with the most frequent value\n",
    "for col in cat_columns:\n",
    "    features[col].fillna(\"NA\", inplace=True)\n",
    "\n",
    "# Replace missing values in the numerical columns with the median value\n",
    "for col in num_columns:\n",
    "    features[col].fillna(features[col].mean(), inplace=True)\n",
    "\n",
    "features = pd.get_dummies(features)\n",
    "\n",
    "features = sync_cols(X_train, features)\n",
    "\n",
    "features = features.sort_index(axis=1)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(features)\n",
    "y_prob = model.predict_proba(features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the labels to the predictions\n",
    "prediction_output = pd.concat([labels,pd.DataFrame(y_pred,columns=[\"pred\"]),pd.DataFrame(y_prob,columns=[\"proba-inv\",\"proba\"])], axis=1)\n",
    "\n",
    "prediction_output = prediction_output.drop(columns=['proba-inv','pred'])\n",
    "prediction_output = prediction_output.rename(columns={\"proba\":\"prediction\"})\n",
    "\n",
    "prediction_output.to_csv(\"xgb_simple.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e79cebfffb2e3a4b7d2d2fd53b48f0eab2f20a6a535e26e1d02c2764acd76f0c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
