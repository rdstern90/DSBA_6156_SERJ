{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import auc, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import datetime\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#constants\n",
    "rand_state = 1337\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_col_types(df, target_col=True):\n",
    "    if target_col:\n",
    "        categorical_cols = ['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_63', 'D_64', 'D_66', 'D_68','target']\n",
    "    else:\n",
    "        categorical_cols = ['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_63', 'D_64', 'D_66', 'D_68']\n",
    "        df['customer_ID'] = df['customer_ID'].astype('object')\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        df[col] = df[col].astype('category')\n",
    "    df[\"S_2\"] = pd.to_datetime(df['S_2'], format=r'%Y-%m-%d').astype('datetime64[ns]')\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_data(df, label_cols=[], drop_cols=[]):\n",
    "\n",
    "  df = df.fillna(np.nan) #because SimpleImputer requires specification of the type of nan value, we use this generic to change all nan types to np.nan types\n",
    "\n",
    "  df = df.drop(columns=drop_cols)\n",
    "  print(df.isna().sum().sum(), \"nulls exist after drop\")\n",
    "\n",
    "  df_labels = df[label_cols] #splits any specified columns off to a label df\n",
    "  df = df.drop(columns=label_cols)\n",
    "\n",
    "  cat_cols = df.select_dtypes(include=\"category\")\n",
    "  num_cols = df.select_dtypes(include=\"number\")\n",
    "  date_cols = df.select_dtypes(include=\"datetime\")\n",
    "  other_cols = df.select_dtypes(exclude={\"category\",\"number\",\"datetime\"})\n",
    "\n",
    "  #impute cat cols\n",
    "  for col in cat_cols:\n",
    "      if cat_cols[col].isna().any():\n",
    "        cat_cols[col] = cat_cols[col].cat.add_categories('⍼')\n",
    "  cat_cols = cat_cols.fillna('⍼')\n",
    "\n",
    "  #impute num cols\n",
    "  # for col in num_cols:\n",
    "  #   if num_cols[col].isna().any():\n",
    "  #     num_cols[col] = num_cols[col].fillna(num_cols[col].mean())\n",
    "  num_cols_imputed = SimpleImputer(strategy=\"mean\").fit_transform(num_cols)\n",
    "  num_cols = pd.DataFrame(num_cols_imputed, columns=num_cols.columns)\n",
    "\n",
    "  #scale num\n",
    "  num_cols_scaled = StandardScaler().fit_transform(num_cols)\n",
    "  num_cols_scaled = pd.DataFrame(num_cols_scaled, columns=num_cols.columns)\n",
    "  num_cols = num_cols_scaled\n",
    "\n",
    "  #get dummies for cat cols\n",
    "  cat_cols = pd.get_dummies(cat_cols)\n",
    "\n",
    "  #change datetime into components\n",
    "  date_cols_expanded = pd.DataFrame()\n",
    "  for col in date_cols:\n",
    "    date_cols_expanded[col + \"Month\"] = date_cols[col].dt.month\n",
    "    date_cols_expanded[col + \"Day\"] = date_cols[col].dt.day\n",
    "    date_cols_expanded[col + \"Year\"] = date_cols[col].dt.year\n",
    "\n",
    "  date_cols = date_cols_expanded\n",
    "\n",
    "  #recombine columns\n",
    "  df = pd.concat([other_cols, date_cols, num_cols, cat_cols], axis=1)\n",
    "\n",
    "  if df.isna().sum().sum() > 0:\n",
    "    print(f\"WARNING: {df.isna().sum().sum()} nulls still exist after imputing.\")\n",
    "  else:\n",
    "    print(\"No nulls exist after imputing.\")\n",
    "  \n",
    "  if len(label_cols)>0:\n",
    "    return df, df_labels\n",
    "  else:\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def sync_cols(train_df, pred_df):\n",
    "    for col in train_df.columns:\n",
    "      if col not in pred_df.columns:\n",
    "        print(col, \"not in pred_df so adding - should always be categorical!\")\n",
    "        pred_df[col] = 0\n",
    "    for col in pred_df.columns:\n",
    "      if col not in train_df.columns:\n",
    "        print(col, \"not in train_df so dropping\")\n",
    "        pred_df = pred_df.drop(col, axis=1)\n",
    "    return pred_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def amex_metric(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "\n",
    "    def top_four_percent_captured(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        df = (pd.concat([y_true, y_pred], axis='columns')\n",
    "              .sort_values('prediction', ascending=False))\n",
    "        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "        four_pct_cutoff = int(0.04 * df['weight'].sum())\n",
    "        df['weight_cumsum'] = df['weight'].cumsum()\n",
    "        df_cutoff = df.loc[df['weight_cumsum'] <= four_pct_cutoff]\n",
    "        return (df_cutoff['target'] == 1).sum() / (df['target'] == 1).sum()\n",
    "        \n",
    "    def weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        df = (pd.concat([y_true, y_pred], axis='columns')\n",
    "              .sort_values('prediction', ascending=False))\n",
    "        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "        df['random'] = (df['weight'] / df['weight'].sum()).cumsum()\n",
    "        total_pos = (df['target'] * df['weight']).sum()\n",
    "        df['cum_pos_found'] = (df['target'] * df['weight']).cumsum()\n",
    "        df['lorentz'] = df['cum_pos_found'] / total_pos\n",
    "        df['gini'] = (df['lorentz'] - df['random']) * df['weight']\n",
    "        return df['gini'].sum()\n",
    "\n",
    "    def normalized_weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        y_true_pred = y_true.rename(columns={'target': 'prediction'})\n",
    "        return weighted_gini(y_true, y_pred) / weighted_gini(y_true, y_true_pred)\n",
    "\n",
    "    g = normalized_weighted_gini(y_true, y_pred)\n",
    "    d = top_four_percent_captured(y_true, y_pred)\n",
    "\n",
    "    return 0.5 * (g + d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(r'../../amex-default-prediction/train_data.parquet')\n",
    "df = set_col_types(df)\n",
    "\n",
    "#reduce df for development !!!!! comment out line below for final model\n",
    "df = df[:100000]\n",
    "\n",
    "df['statement_num'] = df.groupby(\"customer_ID\")['S_2'].rank(method='first', ascending=False).astype(np.int8) #statement_num - 1 is last statement\n",
    "df['statement_num_reverse'] = df.groupby(\"customer_ID\")['S_2'].rank(method='first', ascending=True).astype(np.int8) #reverse  - 1 is first statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 200000 entries, 0 to 199999\n",
      "Data columns (total 193 columns):\n",
      " #    Column                 Dtype         \n",
      "---   ------                 -----         \n",
      " 0    customer_ID            object        \n",
      " 1    S_2                    datetime64[ns]\n",
      " 2    P_2                    float32       \n",
      " 3    D_39                   float32       \n",
      " 4    B_1                    float32       \n",
      " 5    B_2                    float32       \n",
      " 6    R_1                    float32       \n",
      " 7    S_3                    float32       \n",
      " 8    D_41                   float32       \n",
      " 9    B_3                    float32       \n",
      " 10   D_42                   float32       \n",
      " 11   D_43                   float32       \n",
      " 12   D_44                   float32       \n",
      " 13   B_4                    float32       \n",
      " 14   D_45                   float32       \n",
      " 15   B_5                    float32       \n",
      " 16   R_2                    float32       \n",
      " 17   D_46                   float32       \n",
      " 18   D_47                   float32       \n",
      " 19   D_48                   float32       \n",
      " 20   D_49                   float32       \n",
      " 21   B_6                    float32       \n",
      " 22   B_7                    float32       \n",
      " 23   B_8                    float32       \n",
      " 24   D_50                   float32       \n",
      " 25   D_51                   float32       \n",
      " 26   B_9                    float32       \n",
      " 27   R_3                    float32       \n",
      " 28   D_52                   float32       \n",
      " 29   P_3                    float32       \n",
      " 30   B_10                   float32       \n",
      " 31   D_53                   float32       \n",
      " 32   S_5                    float32       \n",
      " 33   B_11                   float32       \n",
      " 34   S_6                    float32       \n",
      " 35   D_54                   float32       \n",
      " 36   R_4                    float32       \n",
      " 37   S_7                    float32       \n",
      " 38   B_12                   float32       \n",
      " 39   S_8                    float32       \n",
      " 40   D_55                   float32       \n",
      " 41   D_56                   float32       \n",
      " 42   B_13                   float32       \n",
      " 43   R_5                    float32       \n",
      " 44   D_58                   float32       \n",
      " 45   S_9                    float32       \n",
      " 46   B_14                   float32       \n",
      " 47   D_59                   float32       \n",
      " 48   D_60                   float32       \n",
      " 49   D_61                   float32       \n",
      " 50   B_15                   float32       \n",
      " 51   S_11                   float32       \n",
      " 52   D_62                   float32       \n",
      " 53   D_63                   category      \n",
      " 54   D_64                   category      \n",
      " 55   D_65                   float32       \n",
      " 56   B_16                   float32       \n",
      " 57   B_17                   float32       \n",
      " 58   B_18                   float32       \n",
      " 59   B_19                   float32       \n",
      " 60   D_66                   category      \n",
      " 61   B_20                   float32       \n",
      " 62   D_68                   category      \n",
      " 63   S_12                   float32       \n",
      " 64   R_6                    float32       \n",
      " 65   S_13                   float32       \n",
      " 66   B_21                   float32       \n",
      " 67   D_69                   float32       \n",
      " 68   B_22                   float32       \n",
      " 69   D_70                   float32       \n",
      " 70   D_71                   float32       \n",
      " 71   D_72                   float32       \n",
      " 72   S_15                   float32       \n",
      " 73   B_23                   float32       \n",
      " 74   D_73                   float32       \n",
      " 75   P_4                    float32       \n",
      " 76   D_74                   float32       \n",
      " 77   D_75                   float32       \n",
      " 78   D_76                   float32       \n",
      " 79   B_24                   float32       \n",
      " 80   R_7                    float32       \n",
      " 81   D_77                   float32       \n",
      " 82   B_25                   float32       \n",
      " 83   B_26                   float32       \n",
      " 84   D_78                   float32       \n",
      " 85   D_79                   float32       \n",
      " 86   R_8                    float32       \n",
      " 87   R_9                    float32       \n",
      " 88   S_16                   float32       \n",
      " 89   D_80                   float32       \n",
      " 90   R_10                   float32       \n",
      " 91   R_11                   float32       \n",
      " 92   B_27                   float32       \n",
      " 93   D_81                   float32       \n",
      " 94   D_82                   float32       \n",
      " 95   S_17                   float32       \n",
      " 96   R_12                   float32       \n",
      " 97   B_28                   float32       \n",
      " 98   R_13                   float32       \n",
      " 99   D_83                   float32       \n",
      " 100  R_14                   float32       \n",
      " 101  R_15                   float32       \n",
      " 102  D_84                   float32       \n",
      " 103  R_16                   float32       \n",
      " 104  B_29                   float32       \n",
      " 105  B_30                   category      \n",
      " 106  S_18                   float32       \n",
      " 107  D_86                   float32       \n",
      " 108  D_87                   float32       \n",
      " 109  R_17                   float32       \n",
      " 110  R_18                   float32       \n",
      " 111  D_88                   float32       \n",
      " 112  B_31                   int64         \n",
      " 113  S_19                   float32       \n",
      " 114  R_19                   float32       \n",
      " 115  B_32                   float32       \n",
      " 116  S_20                   float32       \n",
      " 117  R_20                   float32       \n",
      " 118  R_21                   float32       \n",
      " 119  B_33                   float32       \n",
      " 120  D_89                   float32       \n",
      " 121  R_22                   float32       \n",
      " 122  R_23                   float32       \n",
      " 123  D_91                   float32       \n",
      " 124  D_92                   float32       \n",
      " 125  D_93                   float32       \n",
      " 126  D_94                   float32       \n",
      " 127  R_24                   float32       \n",
      " 128  R_25                   float32       \n",
      " 129  D_96                   float32       \n",
      " 130  S_22                   float32       \n",
      " 131  S_23                   float32       \n",
      " 132  S_24                   float32       \n",
      " 133  S_25                   float32       \n",
      " 134  S_26                   float32       \n",
      " 135  D_102                  float32       \n",
      " 136  D_103                  float32       \n",
      " 137  D_104                  float32       \n",
      " 138  D_105                  float32       \n",
      " 139  D_106                  float32       \n",
      " 140  D_107                  float32       \n",
      " 141  B_36                   float32       \n",
      " 142  B_37                   float32       \n",
      " 143  R_26                   float32       \n",
      " 144  R_27                   float32       \n",
      " 145  B_38                   category      \n",
      " 146  D_108                  float32       \n",
      " 147  D_109                  float32       \n",
      " 148  D_110                  float32       \n",
      " 149  D_111                  float32       \n",
      " 150  B_39                   float32       \n",
      " 151  D_112                  float32       \n",
      " 152  B_40                   float32       \n",
      " 153  S_27                   float32       \n",
      " 154  D_113                  float32       \n",
      " 155  D_114                  category      \n",
      " 156  D_115                  float32       \n",
      " 157  D_116                  category      \n",
      " 158  D_117                  category      \n",
      " 159  D_118                  float32       \n",
      " 160  D_119                  float32       \n",
      " 161  D_120                  category      \n",
      " 162  D_121                  float32       \n",
      " 163  D_122                  float32       \n",
      " 164  D_123                  float32       \n",
      " 165  D_124                  float32       \n",
      " 166  D_125                  float32       \n",
      " 167  D_126                  category      \n",
      " 168  D_127                  float32       \n",
      " 169  D_128                  float32       \n",
      " 170  D_129                  float32       \n",
      " 171  B_41                   float32       \n",
      " 172  B_42                   float32       \n",
      " 173  D_130                  float32       \n",
      " 174  D_131                  float32       \n",
      " 175  D_132                  float32       \n",
      " 176  D_133                  float32       \n",
      " 177  R_28                   float32       \n",
      " 178  D_134                  float32       \n",
      " 179  D_135                  float32       \n",
      " 180  D_136                  float32       \n",
      " 181  D_137                  float32       \n",
      " 182  D_138                  float32       \n",
      " 183  D_139                  float32       \n",
      " 184  D_140                  float32       \n",
      " 185  D_141                  float32       \n",
      " 186  D_142                  float32       \n",
      " 187  D_143                  float32       \n",
      " 188  D_144                  float32       \n",
      " 189  D_145                  float32       \n",
      " 190  target                 category      \n",
      " 191  statement_num          int8          \n",
      " 192  statement_num_reverse  int8          \n",
      "dtypes: category(12), datetime64[ns](1), float32(176), int64(1), int8(2), object(1)\n",
      "memory usage: 143.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13    13925\n",
       "12      399\n",
       "10      265\n",
       "8       241\n",
       "9       232\n",
       "11      210\n",
       "3       208\n",
       "2       199\n",
       "7       195\n",
       "6       185\n",
       "4       175\n",
       "1       174\n",
       "5       168\n",
       "Name: customer_ID, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df['customer_ID'].value_counts()).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ok so 91 customers only have 1 statement. lets isolate them\n",
    "cust_only_one = (df['customer_ID'].value_counts() == 1) #creates series of customers with T/F value if they only have 1 statement\n",
    "cust_only_one = cust_only_one[cust_only_one == True].index #filters series to only the True and leaving behind only the customer_ID index\n",
    "\n",
    "\n",
    "df_cust_one_statement = df[df['customer_ID'].isin(cust_only_one)] #creates df of customers with only 1 statement\n",
    "df = df[~df['customer_ID'].isin(cust_only_one)] #creates df of customers with more than 1 statement\n",
    "\n",
    "del cust_only_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets export customers with one statement so we don't have to worry about them anymore - we will run them though the last statement RF model\n",
    "df_cust_one_statement.to_parquet(r'../../amex-default-prediction/model_output/rf_delta_first_last/cust_one_statement.parquet')\n",
    "del df_cust_one_statement\n",
    "\n",
    "#now all we have in memory is \"df\" with all customers with multiple statements time to reduce them to first + last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_last = df[df['statement_num'] == 1]\n",
    "df_first = df[df['statement_num_reverse'] == 1]\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_last_labels = df_last[['customer_ID', 'S_2']]\n",
    "df_last = df_last.drop(['customer_ID', 'S_2'], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_last = pd.get_dummies(df_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_imputer = cudf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'n_jobs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [81], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m knn_imputer \u001b[39m=\u001b[39m KNNImputer(n_neighbors\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, n_jobs\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m      2\u001b[0m knn_imputer\u001b[39m.\u001b[39mfit_transform(df_last)\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'n_jobs'"
     ]
    }
   ],
   "source": [
    "knn_imputer = KNNImputer(n_neighbors=1)\n",
    "knn_imputer.fit_transform(df_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.93474483, 0.00911864, 0.00938244, ..., 1.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.88051909, 0.17812583, 0.0346842 , ..., 1.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.88087451, 0.00970358, 0.00428367, ..., 1.        , 1.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.68783605, 0.00609202, 0.00782171, ..., 1.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.87805784, 0.21224305, 0.03065685, ..., 1.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.65540254, 0.0020595 , 0.02236446, ..., 1.        , 1.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_imputer = SimpleImputer(strategy='mean')\n",
    "mean_imputer.fit_transform(df_last)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('rapids-22.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7cbb3414c92756923bbc6c41d0262298bd526b337795a913251d875f75c83e8f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
