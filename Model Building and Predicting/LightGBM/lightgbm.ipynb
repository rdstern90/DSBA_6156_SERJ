{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amex_metric(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "\n",
    "    def top_four_percent_captured(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        df = (pd.concat([y_true, y_pred], axis='columns')\n",
    "              .sort_values('prediction', ascending=False))\n",
    "        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "        four_pct_cutoff = int(0.04 * df['weight'].sum())\n",
    "        df['weight_cumsum'] = df['weight'].cumsum()\n",
    "        df_cutoff = df.loc[df['weight_cumsum'] <= four_pct_cutoff]\n",
    "        return (df_cutoff['target'] == 1).sum() / (df['target'] == 1).sum()\n",
    "        \n",
    "    def weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        df = (pd.concat([y_true, y_pred], axis='columns')\n",
    "              .sort_values('prediction', ascending=False))\n",
    "        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "        df['random'] = (df['weight'] / df['weight'].sum()).cumsum()\n",
    "        total_pos = (df['target'] * df['weight']).sum()\n",
    "        df['cum_pos_found'] = (df['target'] * df['weight']).cumsum()\n",
    "        df['lorentz'] = df['cum_pos_found'] / total_pos\n",
    "        df['gini'] = (df['lorentz'] - df['random']) * df['weight']\n",
    "        return df['gini'].sum()\n",
    "\n",
    "    def normalized_weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        y_true_pred = y_true.rename(columns={'target': 'prediction'})\n",
    "        return weighted_gini(y_true, y_pred) / weighted_gini(y_true, y_true_pred)\n",
    "\n",
    "    g = normalized_weighted_gini(y_true, y_pred)\n",
    "    d = top_four_percent_captured(y_true, y_pred)\n",
    "\n",
    "    return 0.5 * (g + d)\n",
    "\n",
    "def set_col_types(df):\n",
    "    if \"target\" in df.columns:\n",
    "        categorical_cols = ['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_63', 'D_64', 'D_66', 'D_68', 'target']\n",
    "    else:\n",
    "        categorical_cols = ['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_63', 'D_64', 'D_66', 'D_68']\n",
    "    df['customer_ID'] = df['customer_ID'].astype(\"string\")\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        df[col] = df[col].astype(\"string\")\n",
    "    df[\"S_2\"] = pd.to_datetime(df['S_2'], format=r'%Y-%m-%d').astype('datetime64[ns]')\n",
    "    df[\"B_31\"] = df[\"B_31\"].astype(np.int8)\n",
    "    return df\n",
    "\n",
    "def sync_cols(train_df, pred_df):\n",
    "    for col in train_df.columns:\n",
    "      if col not in pred_df.columns:\n",
    "        print(col, \"not in pred_df so adding - should always be categorical!\")\n",
    "        pred_df[col] = 0\n",
    "    for col in pred_df.columns:\n",
    "      if col not in train_df.columns:\n",
    "        print(col, \"not in train_df so dropping\")\n",
    "        pred_df = pred_df.drop(col, axis=1)\n",
    "    return pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.5071870813127417, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5071870813127417\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9212862922324698, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9212862922324698\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.93282   0.93183   0.93232    102185\n",
      "           1    0.80431   0.80676   0.80553     35489\n",
      "\n",
      "    accuracy                        0.89959    137674\n",
      "   macro avg    0.86856   0.86929   0.86893    137674\n",
      "weighted avg    0.89969   0.89959   0.89964    137674\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Read data from parquet file\n",
    "df = pd.read_parquet(r\"../../amex-default-prediction/train_data.parquet\")\n",
    "#reduce df for development !!!!! comment out line below for final model\n",
    "#df = df[:100000]\n",
    "\n",
    "# Set the data types for the columns\n",
    "df = set_col_types(df)\n",
    "\n",
    "#engineer statement num\n",
    "df['statement_num'] = df.groupby(\"customer_ID\")['S_2'].rank(method='first', ascending=False).astype(np.int8) \n",
    "df = df[df[\"statement_num\"] == 1]\n",
    "df.reset_index(inplace=True)\n",
    "#engineer date cols\n",
    "df[\"Month\"] = df[\"S_2\"].dt.month\n",
    "df[\"Day\"] = df[\"S_2\"].dt.day\n",
    "df[\"Year\"] = df[\"S_2\"].dt.year\n",
    "df = df.drop([\"S_2\"], axis=1)\n",
    "\n",
    "# Separate target variable and feature columns\n",
    "target = df[\"target\"]\n",
    "labels = df['customer_ID']\n",
    "features = df.drop([\"customer_ID\", \"target\"], axis=1)\n",
    "\n",
    "# Impute missing values using mode for categorical columns and median for numerical columns\n",
    "cat_columns = features.select_dtypes(include=[\"string\"]).columns\n",
    "num_columns = features.select_dtypes(include=\"number\").columns\n",
    "\n",
    "# Replace missing values in the categorical columns with the most frequent value\n",
    "# for col in cat_columns:\n",
    "#     features[col].fillna(\"NA\", inplace=True)\n",
    "\n",
    "# Replace missing values in the numerical columns with the median value\n",
    "for col in num_columns:\n",
    "    features[col].fillna(features[col].mean(), inplace=True)\n",
    "\n",
    "features = pd.get_dummies(features, dummy_na=True)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train a LightGBM model on the training data\n",
    "model = LGBMClassifier()\n",
    "model.set_params(**{'bagging_fraction': 0.9212862922324698, 'bagging_freq': 6, 'feature_fraction': 0.5071870813127417, 'learning_rate': 0.09393773349524241, 'num_leaves': 82, 'reg_alpha': 0.8316783754122955, 'reg_lambda': 0.1695940899747675})\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "print(classification_report(y_test, y_pred, digits=5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7798888718374688"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amex_test = y_test.reset_index(drop=True).to_frame()\n",
    "amex_test['target'] = amex_test['target'].astype('int')\n",
    "\n",
    "amex_pred = model.predict_proba(X_test)\n",
    "amex_pred = pd.DataFrame(amex_pred,columns=[\"proba-inv\",\"proba\"])\n",
    "amex_pred = amex_pred.drop(columns=['proba-inv'])\n",
    "amex_pred = amex_pred.rename(columns={\"proba\":\"prediction\"})\n",
    "\n",
    "\n",
    "amex_metric(amex_test, amex_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.117708 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                     \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430   \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.119113 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                              \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.118314 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                              \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.106225 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                              \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.118669 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                              \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.104016 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                              \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.122991 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                              \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.119545 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                              \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.120018 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                              \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.119833 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                              \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.120775 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.123412 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.120991 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.117642 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.119837 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.117007 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.104929 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.114681 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.116285 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.121030 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.116052 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.118632 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.124472 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.117896 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.120471 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.119609 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.102615 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.117974 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.102154 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.119195 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.099303 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.115261 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.115731 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.119196 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.115892 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.117679 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.121029 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.121395 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.118391 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.112302 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.116336 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.121296 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.119269 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.112932 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.119364 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.120730 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.127950 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.122111 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.118177 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.120983 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.121870 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.122688 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.121493 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.118986 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.107334 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.124064 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.119180 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.117847 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.115578 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.115842 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.118433 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.120718 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.117150 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.119327 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.114892 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.101564 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.099326 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.106519 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.103427 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.105075 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.102817 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.114638 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.120051 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.104318 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                 \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                               \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.104557 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                              \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.117642 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                              \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.103395 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                              \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.103786 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                              \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.116559 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                              \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.104262 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                              \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.105933 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                              \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.118684 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                              \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.120887 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                              \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.116944 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                              \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.102463 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                              \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.133198 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                              \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.119221 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                              \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.118323 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                              \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.103512 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                              \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.105968 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                              \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.118252 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                              \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.102667 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                              \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.118333 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                              \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.101580 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                              \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.104756 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                              \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.099470 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                              \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.122269 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                              \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.116218 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                              \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.106664 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                              \n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.099362 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45010                                                \n",
      "[LightGBM] [Info] Number of data points in the train set: 321239, number of used features: 226\n",
      "[LightGBM] [Info] Start training from score 0.259430                              \n",
      "100%|██████████| 100/100 [07:54<00:00,  4.74s/trial, best loss: -0.778971510608933]\n",
      "{'bagging_fraction': 0.9212862922324698, 'bagging_freq': 6.0, 'feature_fraction': 0.5071870813127417, 'learning_rate': 0.09393773349524241, 'num_leaves': 82.0, 'reg_alpha': 0.8316783754122955, 'reg_lambda': 0.1695940899747675}\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "\n",
    "train_data = lgb.Dataset(X_train, label=y_train.astype(int))\n",
    "\n",
    "# Define the search space for the hyperparameters\n",
    "space = {\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.2),\n",
    "    'num_leaves': hp.quniform('num_leaves', 30, 150, 1),\n",
    "    'feature_fraction': hp.uniform('feature_fraction', 0.5, 1.0),\n",
    "    'bagging_fraction': hp.uniform('bagging_fraction', 0.5, 1.0),\n",
    "    'bagging_freq': hp.quniform('bagging_freq', 5, 25, 1),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 1.0),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 1.0),\n",
    "}\n",
    "\n",
    "# Define the objective function that will be minimized\n",
    "def objective(params):\n",
    "    params = {\n",
    "        'learning_rate': params['learning_rate'],\n",
    "        'num_leaves': int(params['num_leaves']),\n",
    "        'feature_fraction': params['feature_fraction'],\n",
    "        'bagging_fraction': params['bagging_fraction'],\n",
    "        'bagging_freq': int(params['bagging_freq']),\n",
    "        'reg_alpha': params['reg_alpha'],\n",
    "        'reg_lambda': params['reg_lambda'],\n",
    "    }\n",
    "\n",
    "    # Use the LightGBM model to train on the data with the given hyperparameters\n",
    "    model = lgb.train(params, train_data)\n",
    "\n",
    "\n",
    "    \n",
    "    # Calculate the accuracy of the model on the validation data\n",
    "    amex_test = y_test.reset_index(drop=True).to_frame()\n",
    "    amex_test['target'] = amex_test['target'].astype(int)\n",
    "\n",
    "    amex_pred = model.predict(X_test)\n",
    "    amex_pred = pd.DataFrame(amex_pred,columns=[\"prediction\"])\n",
    "    #amex_pred = amex_pred.drop(columns=['proba-inv'])\n",
    "    #amex_pred = amex_pred.rename(columns={\"proba\":\"prediction\"})\n",
    "\n",
    "\n",
    "    accuracy = float(amex_metric(amex_test, amex_pred))\n",
    "\n",
    "\n",
    "    # Return the negative accuracy since we want to minimize the objective\n",
    "    return {'loss': -accuracy, 'status': STATUS_OK}\n",
    "\n",
    "# Use the Tree-structured Parzen Estimator (TPE) to find the best set of hyperparameters\n",
    "best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=100, trials=Trials())\n",
    "\n",
    "# Print the best set of hyperparameters\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read test data from parquet file\n",
    "df = pd.read_parquet(r\"../../amex-default-prediction/test_data.parquet\")\n",
    "#df = df[:100000]\n",
    "\n",
    "# Set the data types for the columns\n",
    "df = set_col_types(df)\n",
    "\n",
    "# Engineer statement num\n",
    "df['statement_num'] = df.groupby(\"customer_ID\")['S_2'].rank(method='first', ascending=False).astype(np.int8)\n",
    "df = df[df[\"statement_num\"] == 1]\n",
    "df.reset_index(inplace=True)\n",
    "# Engineer date cols\n",
    "df[\"Month\"] = df[\"S_2\"].dt.month\n",
    "df[\"Day\"] = df[\"S_2\"].dt.day\n",
    "df[\"Year\"] = df[\"S_2\"].dt.year\n",
    "df = df.drop([\"S_2\"], axis=1)\n",
    "\n",
    "# Separate labels and feature columns\n",
    "labels = df['customer_ID']\n",
    "features = df.drop([\"customer_ID\"], axis=1)\n",
    "\n",
    "# Impute missing values using mode for categorical columns and median for numerical columns\n",
    "cat_columns = features.select_dtypes(include=[\"string\"]).columns\n",
    "num_columns = features.select_dtypes(include=\"number\").columns\n",
    "\n",
    "# Replace missing values in the categorical columns with the most frequent value\n",
    "# for col in cat_columns:\n",
    "#     features[col].fillna(\"NA\", inplace=True)\n",
    "\n",
    "# Replace missing values in the numerical columns with the median value\n",
    "for col in num_columns:\n",
    "    features[col].fillna(features[col].mean(), inplace=True)\n",
    "\n",
    "features = pd.get_dummies(features, dummy_na=True)\n",
    "\n",
    "features = sync_cols(X_train, features)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(features)\n",
    "y_prob = model.predict_proba(features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the labels to the predictions\n",
    "prediction_output = pd.concat([labels,pd.DataFrame(y_pred,columns=[\"pred\"]),pd.DataFrame(y_prob,columns=[\"proba-inv\",\"proba\"])], axis=1)\n",
    "\n",
    "prediction_output = prediction_output.drop(columns=['proba-inv','pred'])\n",
    "prediction_output = prediction_output.rename(columns={\"proba\":\"prediction\"})\n",
    "\n",
    "prediction_output.to_csv(\"train_last_pred_last_mean_tuned_but_int.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e79cebfffb2e3a4b7d2d2fd53b48f0eab2f20a6a535e26e1d02c2764acd76f0c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
