{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring how to flag the target for the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies:\n",
    "# Data Wrangling:\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Modeling Packages:\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import auc, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "import xgboost as xgb\n",
    "import datetime\n",
    "\n",
    "import os\n",
    "import glob\n",
    "rand_state = 1337"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PostgreSQL cloud server credentials:\n",
    "# server ip: 34.75.124.150\n",
    "# username: user\n",
    "# password: DeEJNEAhy\n",
    "# Data is in materialized views train_data and train_labels\n",
    "engine = create_engine('postgresql://user:DeEJNEAhy@34.75.124.150/postgres')\n",
    "sql_df = pd.read_sql(\"\"\"\n",
    "                 WITH BASE AS (\n",
    "                    SELECT *\n",
    "                    ,ROW_NUMBER() OVER      (\n",
    "                                            PARTITION BY customer_id \n",
    "                                            ORDER BY s_2\n",
    "                                            )\n",
    "                    ,ROW_NUMBER() OVER      (\n",
    "                                            PARTITION BY customer_id\n",
    "                                            ORDER BY s_2 DESC\n",
    "                                            ) last_statement_flag_drop\n",
    "                    FROM TRAIN_DATA_random\n",
    "                    )\n",
    "\n",
    "\n",
    "                    SELECT *\n",
    "                    ,CASE WHEN last_statement_flag_drop = 1 then 1 else 0 end as last_statement_flag\n",
    "                    ,CASE WHEN (target = 1 AND last_statement_flag_drop = 1) then 1 else 0 end as last_statement_target\n",
    "                    FROM BASE B\n",
    "                    LEFT JOIN train_labels_random L\n",
    "                    ON B.customer_id = L.customer_id\n",
    "                 \"\"\", engine) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing positive flag on all statements, or only last statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>s_2</th>\n",
       "      <th>p_2</th>\n",
       "      <th>d_39</th>\n",
       "      <th>b_1</th>\n",
       "      <th>b_2</th>\n",
       "      <th>r_1</th>\n",
       "      <th>s_3</th>\n",
       "      <th>d_41</th>\n",
       "      <th>b_3</th>\n",
       "      <th>...</th>\n",
       "      <th>d_142</th>\n",
       "      <th>d_143</th>\n",
       "      <th>d_144</th>\n",
       "      <th>d_145</th>\n",
       "      <th>row_number</th>\n",
       "      <th>last_statement_flag_drop</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>target</th>\n",
       "      <th>last_statement_flag</th>\n",
       "      <th>last_statement_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000548e99fa24cef8377e68e602e4bd70d30500a007999...</td>\n",
       "      <td>2017-03-22</td>\n",
       "      <td>0.871053</td>\n",
       "      <td>0.059789</td>\n",
       "      <td>0.123999</td>\n",
       "      <td>1.000394</td>\n",
       "      <td>0.009311</td>\n",
       "      <td>-0.080754</td>\n",
       "      <td>0.004721</td>\n",
       "      <td>0.009264</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008065</td>\n",
       "      <td>0.003143</td>\n",
       "      <td>0.009226</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>000548e99fa24cef8377e68e602e4bd70d30500a007999...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000548e99fa24cef8377e68e602e4bd70d30500a007999...</td>\n",
       "      <td>2017-04-04</td>\n",
       "      <td>0.874837</td>\n",
       "      <td>0.442610</td>\n",
       "      <td>0.142999</td>\n",
       "      <td>1.008372</td>\n",
       "      <td>0.009232</td>\n",
       "      <td>-0.065012</td>\n",
       "      <td>0.008361</td>\n",
       "      <td>0.004687</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002657</td>\n",
       "      <td>0.008400</td>\n",
       "      <td>0.006783</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>000548e99fa24cef8377e68e602e4bd70d30500a007999...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000548e99fa24cef8377e68e602e4bd70d30500a007999...</td>\n",
       "      <td>2017-05-15</td>\n",
       "      <td>0.846435</td>\n",
       "      <td>0.008253</td>\n",
       "      <td>0.012431</td>\n",
       "      <td>1.000745</td>\n",
       "      <td>0.001761</td>\n",
       "      <td>-0.072598</td>\n",
       "      <td>0.003944</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009037</td>\n",
       "      <td>0.002422</td>\n",
       "      <td>0.005595</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>000548e99fa24cef8377e68e602e4bd70d30500a007999...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000548e99fa24cef8377e68e602e4bd70d30500a007999...</td>\n",
       "      <td>2017-06-09</td>\n",
       "      <td>0.819525</td>\n",
       "      <td>0.624685</td>\n",
       "      <td>0.034141</td>\n",
       "      <td>1.000321</td>\n",
       "      <td>0.001910</td>\n",
       "      <td>-0.069551</td>\n",
       "      <td>0.001054</td>\n",
       "      <td>0.009942</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001113</td>\n",
       "      <td>0.002910</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>000548e99fa24cef8377e68e602e4bd70d30500a007999...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000548e99fa24cef8377e68e602e4bd70d30500a007999...</td>\n",
       "      <td>2017-07-27</td>\n",
       "      <td>0.876368</td>\n",
       "      <td>0.214070</td>\n",
       "      <td>0.020723</td>\n",
       "      <td>0.964219</td>\n",
       "      <td>0.006177</td>\n",
       "      <td>-0.078409</td>\n",
       "      <td>0.008469</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006028</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>000548e99fa24cef8377e68e602e4bd70d30500a007999...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 194 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_id         s_2       p_2  \\\n",
       "0  000548e99fa24cef8377e68e602e4bd70d30500a007999...  2017-03-22  0.871053   \n",
       "1  000548e99fa24cef8377e68e602e4bd70d30500a007999...  2017-04-04  0.874837   \n",
       "2  000548e99fa24cef8377e68e602e4bd70d30500a007999...  2017-05-15  0.846435   \n",
       "3  000548e99fa24cef8377e68e602e4bd70d30500a007999...  2017-06-09  0.819525   \n",
       "4  000548e99fa24cef8377e68e602e4bd70d30500a007999...  2017-07-27  0.876368   \n",
       "\n",
       "       d_39       b_1       b_2       r_1       s_3      d_41       b_3  ...  \\\n",
       "0  0.059789  0.123999  1.000394  0.009311 -0.080754  0.004721  0.009264  ...   \n",
       "1  0.442610  0.142999  1.008372  0.009232 -0.065012  0.008361  0.004687  ...   \n",
       "2  0.008253  0.012431  1.000745  0.001761 -0.072598  0.003944  0.000801  ...   \n",
       "3  0.624685  0.034141  1.000321  0.001910 -0.069551  0.001054  0.009942  ...   \n",
       "4  0.214070  0.020723  0.964219  0.006177 -0.078409  0.008469  0.000250  ...   \n",
       "\n",
       "   d_142     d_143     d_144     d_145  row_number  last_statement_flag_drop  \\\n",
       "0    NaN  0.008065  0.003143  0.009226           1                        13   \n",
       "1    NaN  0.002657  0.008400  0.006783           2                        12   \n",
       "2    NaN  0.009037  0.002422  0.005595           3                        11   \n",
       "3    NaN  0.001113  0.002910  0.002041           4                        10   \n",
       "4    NaN  0.006028  0.000716  0.000856           5                         9   \n",
       "\n",
       "                                         customer_id  target  \\\n",
       "0  000548e99fa24cef8377e68e602e4bd70d30500a007999...       0   \n",
       "1  000548e99fa24cef8377e68e602e4bd70d30500a007999...       0   \n",
       "2  000548e99fa24cef8377e68e602e4bd70d30500a007999...       0   \n",
       "3  000548e99fa24cef8377e68e602e4bd70d30500a007999...       0   \n",
       "4  000548e99fa24cef8377e68e602e4bd70d30500a007999...       0   \n",
       "\n",
       "   last_statement_flag  last_statement_target  \n",
       "0                    0                      0  \n",
       "1                    0                      0  \n",
       "2                    0                      0  \n",
       "3                    0                      0  \n",
       "4                    0                      0  \n",
       "\n",
       "[5 rows x 194 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = sql_df\n",
    "df.head(5)\n",
    "# Dropping columns because the dummy variables \n",
    "df = df.drop(labels=['d_63', 'd_64'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do all imputation and categorical/numerical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the categorical imputation and one-hot encoder for categorical variables.\n",
    "categorical_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"impute\", SimpleImputer(strategy=\"most_frequent\"))\n",
    "        # (\"oh-encode\", OneHotEncoder(handle_unknown=\"ignore\", sparse=False)), #Commented out because the categorical variables won't play nice with dummies between test/train. Retry when we do a full train model. Can impute values on test_data.csv if necessary.\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the numerical imputation and standard scaler for numerical variables.\n",
    "numeric_pipeline = Pipeline(\n",
    "    steps=[(\"impute\", SimpleImputer(strategy=\"mean\")), \n",
    "           (\"scale\", StandardScaler())]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executing the full_processor in one-step for numerical and categorical pipelines.\n",
    "\n",
    "full_processor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"numeric\", numeric_pipeline, num_cols),\n",
    "        (\"categorical\", categorical_pipeline, cat_cols),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions for data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the TRAINING data for creating the model.\n",
    "def prep_df(df, target, target_to_drop):\n",
    "    # Set index\n",
    "    df = df.loc[:,~df.T.duplicated(keep='first')]\n",
    "    \n",
    "    # Drop unecessary columns\n",
    "    df = df.drop(columns=[\"customer_id\", \"row_number\",\"last_statement_flag_drop\",\"last_statement_flag\", \"s_2\", target_to_drop])\n",
    "\n",
    "    # Missing values handling\n",
    "    missing_props = df.isna().mean(axis=0)\n",
    "    \n",
    "\n",
    "    over_threshold = missing_props[missing_props >= 0.4]\n",
    "    over_threshold\n",
    "\n",
    "\n",
    "    df.drop(over_threshold.index, \n",
    "            axis=1, \n",
    "            inplace=True)\n",
    "\n",
    "    \n",
    "    \n",
    "    # Split into predictors and target\n",
    "    X = df.drop(columns=[target])\n",
    "    y = df[target]\n",
    "    \n",
    "    X = pd.get_dummies(X, drop_first=True)\n",
    "    X.columns = X.columns.str.lower()\n",
    "    cols_list = X.columns.tolist()\n",
    "    \n",
    "    # Split categorical and numerical columns\n",
    "    cat_cols = X.select_dtypes(exclude=\"number\").columns\n",
    "    num_cols = X.select_dtypes(include=\"number\").columns\n",
    "    \n",
    "    full_processor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"numeric\", numeric_pipeline, num_cols),\n",
    "        (\"categorical\", categorical_pipeline, cat_cols),\n",
    "    ]\n",
    "    )   \n",
    "    \n",
    "    # Apply preprocessing\n",
    "    X_processed = full_processor.fit_transform(X)\n",
    "    print(X_processed.shape)\n",
    "    y_processed = SimpleImputer(strategy=\"most_frequent\").fit_transform(\n",
    "            y.values.reshape(-1, 1)\n",
    "            )\n",
    "    return X_processed, y_processed, cols_list\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the test_data.csv so it's values can be fed into the built model.\n",
    "def prep_test_df(df, keep_cols):\n",
    "    \n",
    "    # Handling case-sensitivity\n",
    "    keep_cols = keep_cols\n",
    "    # # Drop columns not used in model training\n",
    "    df = df[keep_cols]\n",
    "    df = pd.get_dummies(df, drop_first=True)\n",
    "    \n",
    "    X = df\n",
    "    \n",
    "    # Split categorical and numerical columns\n",
    "    cat_cols = X.select_dtypes(exclude=\"number\").columns\n",
    "    num_cols = X.select_dtypes(include=\"number\").columns\n",
    "    \n",
    "    full_processor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"numeric\", numeric_pipeline, num_cols),\n",
    "        (\"categorical\", categorical_pipeline, cat_cols),\n",
    "    ]\n",
    "    )\n",
    "    \n",
    "    # Apply preprocessing\n",
    "    X_processed_test = full_processor.fit_transform(X)\n",
    "    return X_processed_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%script` not found.\n"
     ]
    }
   ],
   "source": [
    "# Deprecated due to iterating over pre-split files.\n",
    "# Now we just read in chunks from the entire test_data.csv file.\n",
    "\n",
    "%%script false\n",
    "def score_split_files(directory, model, keep_cols, test_data_col_names):\n",
    "    mdf = pd.DataFrame(columns=['customer_id', 's_2', 'pred', 'proba'])\n",
    "    for filename in os.listdir(directory):\n",
    "        f = os.path.join(directory, filename)\n",
    "        # checking if it is a file\n",
    "        if os.path.isfile(f):\n",
    "            print(\"Working on \" + f)\n",
    "            df_pred = pd.read_csv(f)\n",
    "            df_pred.columns = test_data_col_names\n",
    "            X_processed_test = prep_test_df(df_pred, keep_cols=keep_cols)\n",
    "            preds = model.predict(X_processed_test)\n",
    "            proba = model.predict_proba(X_processed_test)\n",
    "            df_c = df_pred[['customer_id', 's_2']]\n",
    "            df_c = pd.concat([df_c, pd.DataFrame(preds, columns=['pred']), pd.DataFrame(proba, columns=['proba_inv', 'proba'])], axis=1)\n",
    "            mdf = pd.concat([mdf, df_c])\n",
    "            del [[df_c,df_pred]]\n",
    "    return mdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feeding the test_data into the model, tabulating results, and building a df. Then saving the df to a .csv file.\n",
    "def score_split_files(path, model, keep_cols, split_num_lines=500000):\n",
    "    current_position = 0 #defines starting position and keeps track of where in file to read\n",
    "    df_columns = None #object to hold the col names collected from the first df chunk\n",
    "    \n",
    "    # Define the result mdf\n",
    "    mdf = pd.DataFrame(columns=['customer_id', 's_2', 'pred', 'proba'])\n",
    "    \n",
    "    # Get chunks from the test_data.csv and send them to the model\n",
    "    while True:\n",
    "        try:\n",
    "            df_chunk = pd.read_csv(path, skiprows=current_position, nrows=split_num_lines)\n",
    "            df_chunk.columns = df_chunk.columns.str.lower()\n",
    "            if current_position == 0:\n",
    "                df_columns = df_chunk.columns\n",
    "            else:\n",
    "                df_chunk.columns = df_columns\n",
    "\n",
    "            # Function to prep the test_data\n",
    "            X_processed_test = prep_test_df(df_chunk, keep_cols=keep_cols)\n",
    "            # Predicting outcomes from test_data\n",
    "            preds = model.predict(X_processed_test)\n",
    "            #Predicting probabilities from test_data\n",
    "            proba = model.predict_proba(X_processed_test)\n",
    "            # Creating df to concat later. Getting date and customer_id from original df read in from .csv\n",
    "            df_c = df_chunk[['customer_id', 's_2']]\n",
    "            # Concating the np arrays to df_c\n",
    "            df_c = pd.concat([df_c, pd.DataFrame(preds, columns=['pred']), pd.DataFrame(proba, columns=['proba_inv', 'proba'])], axis=1)\n",
    "            mdf = pd.concat([mdf, df_c])\n",
    "            # Deleting the temp dfs to free up memory.\n",
    "            del [[df_c,df_chunk]]\n",
    "\n",
    "            current_position += split_num_lines #increments position by chunk size for the next loop\n",
    "        except pd.errors.EmptyDataError:\n",
    "            break\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    return mdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model with training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120488, 155)\n"
     ]
    }
   ],
   "source": [
    "# Prep the dataframe\n",
    "X_processed, y_processed, cols_list = prep_df(df, target='target', target_to_drop='last_statement_target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the test/train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_processed, y_processed, stratify=y_processed, random_state=rand_state\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9218511387026094"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Run the model\n",
    "\n",
    "# Init classifier\n",
    "xgb_cl = xgb.XGBClassifier()\n",
    "\n",
    "# Fit\n",
    "xgb_cl.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "preds = xgb_cl.predict(X_test)\n",
    "proba = xgb_cl.predict_proba(X_test)\n",
    "\n",
    "# Score\n",
    "accuracy_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict test data, every statement flagged as target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120488, 155)\n"
     ]
    }
   ],
   "source": [
    "# Prep the dataframe\n",
    "X_processed, y_processed, cols_list = prep_df(df, target='target', target_to_drop='last_statement_target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Init classifier\n",
    "xgb_cla = xgb.XGBClassifier()\n",
    "\n",
    "# Fit\n",
    "xgb_cla.fit(X_processed, y_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\joebu\\programming_directory\\DSBA_6156_SERJ\\ignore\\test_data.csv'\n",
    "# test_data_col_names = pd.read_csv(r'C:\\Users\\joebu\\programming_directory\\large_data_files\\amex-default-prediction\\test_data.csv', nrows=0, index_col=False).columns.str.lower()\n",
    "\n",
    "\n",
    "results_df = score_split_files(path=path, model=xgb_cla, keep_cols=cols_list)\n",
    "results_df.to_csv('./ignore/XGB_target.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict test data, last_staement_target as outcome:\n",
    "Here will will only flag the last statement as default for each customer that did default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120488, 155)\n"
     ]
    }
   ],
   "source": [
    "# Prep the data with last_statement_target as outcome\n",
    "X_processed, y_processed, cols_list = prep_df(df, target='last_statement_target', target_to_drop='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model with new outcome\n",
    "# Init classifier\n",
    "xgb_cla = xgb.XGBClassifier()\n",
    "\n",
    "# Fit\n",
    "xgb_cla.fit(X_processed, y_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = score_split_files(path=path, model=xgb_cla, keep_cols=cols_list)\n",
    "results_df.to_csv('./ignore/XGB_last_statement_target.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Only training on last statements:\n",
    "Here we will only consider the last statements when training the model, and drop all the other statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>s_2</th>\n",
       "      <th>p_2</th>\n",
       "      <th>d_39</th>\n",
       "      <th>b_1</th>\n",
       "      <th>b_2</th>\n",
       "      <th>r_1</th>\n",
       "      <th>s_3</th>\n",
       "      <th>d_41</th>\n",
       "      <th>b_3</th>\n",
       "      <th>...</th>\n",
       "      <th>d_142</th>\n",
       "      <th>d_143</th>\n",
       "      <th>d_144</th>\n",
       "      <th>d_145</th>\n",
       "      <th>row_number</th>\n",
       "      <th>last_statement_flag_drop</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>target</th>\n",
       "      <th>last_statement_flag</th>\n",
       "      <th>last_statement_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>000548e99fa24cef8377e68e602e4bd70d30500a007999...</td>\n",
       "      <td>2018-03-23</td>\n",
       "      <td>0.850288</td>\n",
       "      <td>0.092471</td>\n",
       "      <td>0.024854</td>\n",
       "      <td>1.008376</td>\n",
       "      <td>0.003778</td>\n",
       "      <td>0.083939</td>\n",
       "      <td>0.008216</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004796</td>\n",
       "      <td>0.004277</td>\n",
       "      <td>0.003490</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>000548e99fa24cef8377e68e602e4bd70d30500a007999...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>00062483fb33d6129dd4ee7e5a12f751d2e7010ac0df01...</td>\n",
       "      <td>2018-03-11</td>\n",
       "      <td>0.573481</td>\n",
       "      <td>0.000626</td>\n",
       "      <td>0.021270</td>\n",
       "      <td>0.818519</td>\n",
       "      <td>0.009274</td>\n",
       "      <td>0.177161</td>\n",
       "      <td>0.001771</td>\n",
       "      <td>0.003341</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004462</td>\n",
       "      <td>0.008460</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>00062483fb33d6129dd4ee7e5a12f751d2e7010ac0df01...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>000b48231b7fad0e00ce78790df80ff94bd890eaaa8c68...</td>\n",
       "      <td>2018-03-28</td>\n",
       "      <td>0.965894</td>\n",
       "      <td>0.089054</td>\n",
       "      <td>0.020007</td>\n",
       "      <td>1.004288</td>\n",
       "      <td>0.003816</td>\n",
       "      <td>0.083451</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.004880</td>\n",
       "      <td>...</td>\n",
       "      <td>0.737618</td>\n",
       "      <td>1.000694</td>\n",
       "      <td>0.228738</td>\n",
       "      <td>1.007654</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>000b48231b7fad0e00ce78790df80ff94bd890eaaa8c68...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>000bbcea7cf6a9d74b2ff2f6fd4fa89a4ff4c419a8b569...</td>\n",
       "      <td>2018-03-06</td>\n",
       "      <td>0.245102</td>\n",
       "      <td>0.009622</td>\n",
       "      <td>0.058433</td>\n",
       "      <td>0.003199</td>\n",
       "      <td>0.257760</td>\n",
       "      <td>0.810220</td>\n",
       "      <td>0.367337</td>\n",
       "      <td>0.138842</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005684</td>\n",
       "      <td>0.001924</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>000bbcea7cf6a9d74b2ff2f6fd4fa89a4ff4c419a8b569...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>000ee46c042bfab551c28d92c93969f8a3539fe1e9fc9c...</td>\n",
       "      <td>2018-03-29</td>\n",
       "      <td>0.836212</td>\n",
       "      <td>0.273643</td>\n",
       "      <td>0.037596</td>\n",
       "      <td>1.004145</td>\n",
       "      <td>0.001018</td>\n",
       "      <td>0.130767</td>\n",
       "      <td>0.008174</td>\n",
       "      <td>0.008470</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000479</td>\n",
       "      <td>0.005803</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>000ee46c042bfab551c28d92c93969f8a3539fe1e9fc9c...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 196 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          customer_id         s_2       p_2  \\\n",
       "12  000548e99fa24cef8377e68e602e4bd70d30500a007999...  2018-03-23  0.850288   \n",
       "20  00062483fb33d6129dd4ee7e5a12f751d2e7010ac0df01...  2018-03-11  0.573481   \n",
       "33  000b48231b7fad0e00ce78790df80ff94bd890eaaa8c68...  2018-03-28  0.965894   \n",
       "46  000bbcea7cf6a9d74b2ff2f6fd4fa89a4ff4c419a8b569...  2018-03-06  0.245102   \n",
       "59  000ee46c042bfab551c28d92c93969f8a3539fe1e9fc9c...  2018-03-29  0.836212   \n",
       "\n",
       "        d_39       b_1       b_2       r_1       s_3      d_41       b_3  ...  \\\n",
       "12  0.092471  0.024854  1.008376  0.003778  0.083939  0.008216  0.000120  ...   \n",
       "20  0.000626  0.021270  0.818519  0.009274  0.177161  0.001771  0.003341  ...   \n",
       "33  0.089054  0.020007  1.004288  0.003816  0.083451  0.000586  0.004880  ...   \n",
       "46  0.009622  0.058433  0.003199  0.257760  0.810220  0.367337  0.138842  ...   \n",
       "59  0.273643  0.037596  1.004145  0.001018  0.130767  0.008174  0.008470  ...   \n",
       "\n",
       "       d_142     d_143     d_144     d_145  row_number  \\\n",
       "12       NaN  0.004796  0.004277  0.003490          13   \n",
       "20       NaN  0.004462  0.008460  0.000035           8   \n",
       "33  0.737618  1.000694  0.228738  1.007654          13   \n",
       "46       NaN  0.005684  0.001924  0.000352          13   \n",
       "59       NaN  0.000479  0.005803  0.000343          13   \n",
       "\n",
       "    last_statement_flag_drop  \\\n",
       "12                         1   \n",
       "20                         1   \n",
       "33                         1   \n",
       "46                         1   \n",
       "59                         1   \n",
       "\n",
       "                                          customer_id  target  \\\n",
       "12  000548e99fa24cef8377e68e602e4bd70d30500a007999...       0   \n",
       "20  00062483fb33d6129dd4ee7e5a12f751d2e7010ac0df01...       0   \n",
       "33  000b48231b7fad0e00ce78790df80ff94bd890eaaa8c68...       0   \n",
       "46  000bbcea7cf6a9d74b2ff2f6fd4fa89a4ff4c419a8b569...       1   \n",
       "59  000ee46c042bfab551c28d92c93969f8a3539fe1e9fc9c...       0   \n",
       "\n",
       "    last_statement_flag  last_statement_target  \n",
       "12                    1                      0  \n",
       "20                    1                      0  \n",
       "33                    1                      0  \n",
       "46                    1                      1  \n",
       "59                    1                      0  \n",
       "\n",
       "[5 rows x 196 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "\"['last_statement_flag'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [61], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m display(ls_df\u001b[39m.\u001b[39mhead())\n\u001b[0;32m      4\u001b[0m \u001b[39m# Prep the data with last_statement_target as outcome\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m X_processed, y_processed, cols_list \u001b[39m=\u001b[39m prep_df(ls_df, target\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mlast_statement_target\u001b[39;49m\u001b[39m'\u001b[39;49m, target_to_drop\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtarget\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn [29], line 7\u001b[0m, in \u001b[0;36mprep_df\u001b[1;34m(df, target, target_to_drop)\u001b[0m\n\u001b[0;32m      4\u001b[0m df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mloc[:,\u001b[39m~\u001b[39mdf\u001b[39m.\u001b[39mT\u001b[39m.\u001b[39mduplicated(keep\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfirst\u001b[39m\u001b[39m'\u001b[39m)]\n\u001b[0;32m      6\u001b[0m \u001b[39m# Drop unecessary columns\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49mdrop(columns\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mcustomer_id\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mrow_number\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mlast_statement_flag_drop\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mlast_statement_flag\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39ms_2\u001b[39;49m\u001b[39m\"\u001b[39;49m, target_to_drop])\n\u001b[0;32m      9\u001b[0m \u001b[39m# Missing values handling\u001b[39;00m\n\u001b[0;32m     10\u001b[0m missing_props \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39misna()\u001b[39m.\u001b[39mmean(axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\joebu\\programming_directory\\DSBA_6156_SERJ\\venv\\venv\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\joebu\\programming_directory\\DSBA_6156_SERJ\\venv\\venv\\lib\\site-packages\\pandas\\core\\frame.py:5388\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5240\u001b[0m \u001b[39m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, allowed_args\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m   5241\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdrop\u001b[39m(  \u001b[39m# type: ignore[override]\u001b[39;00m\n\u001b[0;32m   5242\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5249\u001b[0m     errors: IgnoreRaise \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   5250\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   5251\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   5252\u001b[0m \u001b[39m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5253\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5386\u001b[0m \u001b[39m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5387\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5388\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mdrop(\n\u001b[0;32m   5389\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m   5390\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m   5391\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[0;32m   5392\u001b[0m         columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[0;32m   5393\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m   5394\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[0;32m   5395\u001b[0m         errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m   5396\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\joebu\\programming_directory\\DSBA_6156_SERJ\\venv\\venv\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\joebu\\programming_directory\\DSBA_6156_SERJ\\venv\\venv\\lib\\site-packages\\pandas\\core\\generic.py:4505\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4503\u001b[0m \u001b[39mfor\u001b[39;00m axis, labels \u001b[39min\u001b[39;00m axes\u001b[39m.\u001b[39mitems():\n\u001b[0;32m   4504\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 4505\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_drop_axis(labels, axis, level\u001b[39m=\u001b[39;49mlevel, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   4507\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[0;32m   4508\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mc:\\Users\\joebu\\programming_directory\\DSBA_6156_SERJ\\venv\\venv\\lib\\site-packages\\pandas\\core\\generic.py:4546\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4544\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mdrop(labels, level\u001b[39m=\u001b[39mlevel, errors\u001b[39m=\u001b[39merrors)\n\u001b[0;32m   4545\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 4546\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39;49mdrop(labels, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   4547\u001b[0m     indexer \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4549\u001b[0m \u001b[39m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4550\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\joebu\\programming_directory\\DSBA_6156_SERJ\\venv\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6975\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6973\u001b[0m \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[0;32m   6974\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m-> 6975\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(labels[mask])\u001b[39m}\u001b[39;00m\u001b[39m not found in axis\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6976\u001b[0m     indexer \u001b[39m=\u001b[39m indexer[\u001b[39m~\u001b[39mmask]\n\u001b[0;32m   6977\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['last_statement_flag'] not found in axis\""
     ]
    }
   ],
   "source": [
    "ls_df = sql_df[sql_df['last_statement_flag'] == 1]\n",
    "display(ls_df.head())\n",
    "\n",
    "# Prep the data with last_statement_target as outcome\n",
    "X_processed, y_processed, cols_list = prep_df(ls_df, target='last_statement_target', target_to_drop='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init classifier\n",
    "xgb_cla = xgb.XGBClassifier()\n",
    "\n",
    "# Fit the model\n",
    "xgb_cla.fit(X_processed, y_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = score_split_files(path=path, model=xgb_cla, keep_cols=cols_list)\n",
    "results_df.to_csv('./ignore/XGB_only_last_statements.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5dcb6b7e2f26f70306738e96e7445a78b658183e0554cf15e38890769044d88c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
