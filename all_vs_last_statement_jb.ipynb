{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring how to flag the target for the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies:\n",
    "# Data Wrangling:\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Modeling Packages:\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import auc, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "import xgboost as xgb\n",
    "import datetime\n",
    "\n",
    "import os\n",
    "import glob\n",
    "rand_state = 1337"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PostgreSQL cloud server credentials:\n",
    "# server ip: 34.75.124.150\n",
    "# username: user\n",
    "# password: DeEJNEAhy\n",
    "# Data is in materialized views train_data and train_labels\n",
    "engine = create_engine('postgresql://user:DeEJNEAhy@34.75.124.150/postgres')\n",
    "sql_df = pd.read_sql(\"\"\"\n",
    "                 WITH BASE AS (\n",
    "                    SELECT *\n",
    "                    ,ROW_NUMBER() OVER      (\n",
    "                                            PARTITION BY customer_id \n",
    "                                            ORDER BY s_2\n",
    "                                            )\n",
    "                    ,ROW_NUMBER() OVER      (\n",
    "                                            PARTITION BY customer_id\n",
    "                                            ORDER BY s_2 DESC\n",
    "                                            ) last_statement_flag_drop\n",
    "                    FROM TRAIN_DATA_random\n",
    "                    )\n",
    "\n",
    "\n",
    "                    SELECT *\n",
    "                    ,CASE WHEN last_statement_flag_drop = 1 then 1 else 0 end as last_statement_flag\n",
    "                    ,CASE WHEN (target = 1 AND last_statement_flag_drop = 1) then 1 else 0 end as last_statement_target\n",
    "                    FROM BASE B\n",
    "                    LEFT JOIN train_labels_random L\n",
    "                    ON B.customer_id = L.customer_id\n",
    "                 \"\"\", engine) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing positive flag on all statements, or only last statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sql_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[39m=\u001b[39m sql_df\n\u001b[0;32m      2\u001b[0m df\u001b[39m.\u001b[39mhead(\u001b[39m5\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[39m# Dropping columns because the dummy variables \u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39m# df = df.drop(labels=['d_63', 'd_64'], axis=1)\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sql_df' is not defined"
     ]
    }
   ],
   "source": [
    "df = sql_df\n",
    "df.head(5)\n",
    "# Dropping columns because the dummy variables \n",
    "df = df.drop(labels=['d_63', 'd_64'], axis=1)\n",
    "df.head()\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>S_2</th>\n",
       "      <th>P_2</th>\n",
       "      <th>D_39</th>\n",
       "      <th>B_1</th>\n",
       "      <th>B_2</th>\n",
       "      <th>R_1</th>\n",
       "      <th>S_3</th>\n",
       "      <th>D_41</th>\n",
       "      <th>B_3</th>\n",
       "      <th>...</th>\n",
       "      <th>D_137</th>\n",
       "      <th>D_138</th>\n",
       "      <th>D_139</th>\n",
       "      <th>D_140</th>\n",
       "      <th>D_141</th>\n",
       "      <th>D_142</th>\n",
       "      <th>D_143</th>\n",
       "      <th>D_144</th>\n",
       "      <th>D_145</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>2017-03-09</td>\n",
       "      <td>0.938477</td>\n",
       "      <td>0.001734</td>\n",
       "      <td>0.008728</td>\n",
       "      <td>1.006836</td>\n",
       "      <td>0.009224</td>\n",
       "      <td>0.124023</td>\n",
       "      <td>0.008774</td>\n",
       "      <td>0.004707</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002426</td>\n",
       "      <td>0.003706</td>\n",
       "      <td>0.003819</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>0.002674</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>2017-04-07</td>\n",
       "      <td>0.936523</td>\n",
       "      <td>0.005775</td>\n",
       "      <td>0.004925</td>\n",
       "      <td>1.000977</td>\n",
       "      <td>0.006153</td>\n",
       "      <td>0.126709</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.002714</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003956</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>0.005032</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009575</td>\n",
       "      <td>0.005493</td>\n",
       "      <td>0.009216</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>2017-05-28</td>\n",
       "      <td>0.954102</td>\n",
       "      <td>0.091492</td>\n",
       "      <td>0.021652</td>\n",
       "      <td>1.009766</td>\n",
       "      <td>0.006817</td>\n",
       "      <td>0.123962</td>\n",
       "      <td>0.007599</td>\n",
       "      <td>0.009422</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003269</td>\n",
       "      <td>0.007328</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003429</td>\n",
       "      <td>0.006985</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>2017-06-13</td>\n",
       "      <td>0.960449</td>\n",
       "      <td>0.002455</td>\n",
       "      <td>0.013687</td>\n",
       "      <td>1.002930</td>\n",
       "      <td>0.001372</td>\n",
       "      <td>0.117188</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>0.005531</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006119</td>\n",
       "      <td>0.004517</td>\n",
       "      <td>0.003201</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008423</td>\n",
       "      <td>0.006527</td>\n",
       "      <td>0.009598</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>2017-07-16</td>\n",
       "      <td>0.947266</td>\n",
       "      <td>0.002483</td>\n",
       "      <td>0.015190</td>\n",
       "      <td>1.000977</td>\n",
       "      <td>0.007607</td>\n",
       "      <td>0.117310</td>\n",
       "      <td>0.004654</td>\n",
       "      <td>0.009308</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003672</td>\n",
       "      <td>0.004944</td>\n",
       "      <td>0.008888</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001670</td>\n",
       "      <td>0.008125</td>\n",
       "      <td>0.009827</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 191 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_ID        S_2       P_2  \\\n",
       "0  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f... 2017-03-09  0.938477   \n",
       "1  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f... 2017-04-07  0.936523   \n",
       "2  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f... 2017-05-28  0.954102   \n",
       "3  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f... 2017-06-13  0.960449   \n",
       "4  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f... 2017-07-16  0.947266   \n",
       "\n",
       "       D_39       B_1       B_2       R_1       S_3      D_41       B_3  ...  \\\n",
       "0  0.001734  0.008728  1.006836  0.009224  0.124023  0.008774  0.004707  ...   \n",
       "1  0.005775  0.004925  1.000977  0.006153  0.126709  0.000798  0.002714  ...   \n",
       "2  0.091492  0.021652  1.009766  0.006817  0.123962  0.007599  0.009422  ...   \n",
       "3  0.002455  0.013687  1.002930  0.001372  0.117188  0.000685  0.005531  ...   \n",
       "4  0.002483  0.015190  1.000977  0.007607  0.117310  0.004654  0.009308  ...   \n",
       "\n",
       "   D_137  D_138     D_139     D_140     D_141  D_142     D_143     D_144  \\\n",
       "0    NaN    NaN  0.002426  0.003706  0.003819    NaN  0.000569  0.000610   \n",
       "1    NaN    NaN  0.003956  0.003166  0.005032    NaN  0.009575  0.005493   \n",
       "2    NaN    NaN  0.003269  0.007328  0.000427    NaN  0.003429  0.006985   \n",
       "3    NaN    NaN  0.006119  0.004517  0.003201    NaN  0.008423  0.006527   \n",
       "4    NaN    NaN  0.003672  0.004944  0.008888    NaN  0.001670  0.008125   \n",
       "\n",
       "      D_145  target  \n",
       "0  0.002674       0  \n",
       "1  0.009216       0  \n",
       "2  0.002604       0  \n",
       "3  0.009598       0  \n",
       "4  0.009827       0  \n",
       "\n",
       "[5 rows x 191 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_feather(r'C:\\Users\\joebu\\programming_directory\\DSBA_6156_SERJ\\ignore\\train_data.feather')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['statement_num'] = df.groupby(\"customer_ID\")['S_2'].rank(method='first', ascending=False).astype(int)\n",
    "df['last_statement_target'] = np.where((df['statement_num'] == 1) & (df['target'] == 1), 1, 0)\n",
    "df.columns= df.columns.str.lower()\n",
    "df = df.drop(labels=['d_63', 'd_64', 'd_68', 'b_30', 'd_117', 'd_120', 'd_126', 'b_38', 'd_114', 'd_116', 'd_42'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do all imputation and categorical/numerical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the categorical imputation and one-hot encoder for categorical variables.\n",
    "categorical_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"impute\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        #  (\"oh-encode\", OneHotEncoder(handle_unknown=\"ignore\", sparse=False)), #Commented out because the categorical variables won't play nice with dummies between test/train. Retry when we do a full train model. Can impute values on test_data.csv if necessary.\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the numerical imputation and standard scaler for numerical variables.\n",
    "numeric_pipeline = Pipeline(\n",
    "    steps=[(\"impute\", SimpleImputer(strategy=\"mean\")), \n",
    "           (\"scale\", StandardScaler())]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executing the full_processor in one-step for numerical and categorical pipelines.\n",
    "\n",
    "full_processor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"numeric\", numeric_pipeline, num_cols),\n",
    "        (\"categorical\", categorical_pipeline, cat_cols),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions for data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the TRAINING data for creating the model.\n",
    "def prep_df(df, target, target_to_drop):\n",
    "    # Set index\n",
    "    df = df.loc[:,~df.columns.duplicated()]\n",
    "\n",
    "    # Drop unecessary columns\n",
    "    df = df.drop(columns=[\"customer_id\", \"statement_num\", \"s_2\", target_to_drop])\n",
    "\n",
    "    # Missing values handling\n",
    "    missing_props = df.isna().mean(axis=0)\n",
    "    \n",
    "\n",
    "    over_threshold = missing_props[missing_props >= 0.4]\n",
    "    over_threshold\n",
    "\n",
    "\n",
    "    df.drop(over_threshold.index, \n",
    "            axis=1, \n",
    "            inplace=True)\n",
    "\n",
    "    \n",
    "    \n",
    "    # Split into predictors and target\n",
    "    X = df.drop(columns=[target])\n",
    "    y = df[target]\n",
    "    \n",
    "    X = pd.get_dummies(X, drop_first=True)\n",
    "    X.columns = X.columns.str.lower()\n",
    "    cols_list = X.columns.tolist()\n",
    "    \n",
    "    # Split categorical and numerical columns\n",
    "    cat_cols = X.select_dtypes(exclude=\"number\").columns\n",
    "    num_cols = X.select_dtypes(include=\"number\").columns\n",
    "    \n",
    "    full_processor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"numeric\", numeric_pipeline, num_cols),\n",
    "        (\"categorical\", categorical_pipeline, cat_cols),\n",
    "    ]\n",
    "    )   \n",
    "    \n",
    "    # Apply preprocessing\n",
    "    X_processed = full_processor.fit_transform(X)\n",
    "    print(X_processed.shape)\n",
    "    y_processed = SimpleImputer(strategy=\"most_frequent\").fit_transform(\n",
    "            y.values.reshape(-1, 1)\n",
    "            )\n",
    "    return X_processed, y_processed, cols_list\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the test_data.csv so it's values can be fed into the built model.\n",
    "def prep_test_df(df, keep_cols):\n",
    "    \n",
    "    # Handling case-sensitivity\n",
    "    keep_cols = keep_cols\n",
    "    # # Drop columns not used in model training\n",
    "    \n",
    "    # df = df[keep_cols]\n",
    "    \n",
    "    \n",
    "    X = df\n",
    "    \n",
    "    # Split categorical and numerical columns\n",
    "    cat_cols = X.select_dtypes(exclude=\"number\").columns\n",
    "    num_cols = X.select_dtypes(include=\"number\").columns\n",
    "    \n",
    "    full_processor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"numeric\", numeric_pipeline, num_cols),\n",
    "        (\"categorical\", categorical_pipeline, cat_cols),\n",
    "    ]\n",
    "    )\n",
    "    X = X[keep_cols]\n",
    "    # Apply preprocessing\n",
    "    X_processed_test = full_processor.fit_transform(X)\n",
    "    return X_processed_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%script` not found.\n"
     ]
    }
   ],
   "source": [
    "# Deprecated due to iterating over pre-split files.\n",
    "# Now we just read in chunks from the entire test_data.csv file.\n",
    "\n",
    "%%script false\n",
    "def score_split_files(directory, model, keep_cols, test_data_col_names):\n",
    "    mdf = pd.DataFrame(columns=['customer_id', 's_2', 'pred', 'proba'])\n",
    "    for filename in os.listdir(directory):\n",
    "        f = os.path.join(directory, filename)\n",
    "        # checking if it is a file\n",
    "        if os.path.isfile(f):\n",
    "            print(\"Working on \" + f)\n",
    "            df_pred = pd.read_csv(f)\n",
    "            df_pred.columns = test_data_col_names\n",
    "            X_processed_test = prep_test_df(df_pred, keep_cols=keep_cols)\n",
    "            preds = model.predict(X_processed_test)\n",
    "            proba = model.predict_proba(X_processed_test)\n",
    "            df_c = df_pred[['customer_id', 's_2']]\n",
    "            df_c = pd.concat([df_c, pd.DataFrame(preds, columns=['pred']), pd.DataFrame(proba, columns=['proba_inv', 'proba'])], axis=1)\n",
    "            mdf = pd.concat([mdf, df_c])\n",
    "            del [[df_c,df_pred]]\n",
    "    return mdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feeding the test_data into the model, tabulating results, and building a df. Then saving the df to a .csv file.\n",
    "def score_split_files(path, model, keep_cols, split_num_lines=3500000):\n",
    "    current_position = 0 #defines starting position and keeps track of where in file to read\n",
    "    df_columns = None #object to hold the col names collected from the first df chunk\n",
    "    \n",
    "    # Define the result mdf\n",
    "    mdf = pd.DataFrame(columns=['customer_id', 's_2', 'pred', 'proba'])\n",
    "    \n",
    "    # Get chunks from the test_data.csv and send them to the model\n",
    "    while True:\n",
    "        try:\n",
    "            df_chunk = pd.read_csv(path, skiprows=current_position, nrows=split_num_lines)\n",
    "            df_chunk.columns = df_chunk.columns.str.lower()\n",
    "            if current_position == 0:\n",
    "                df_columns = df_chunk.columns\n",
    "            else:\n",
    "                df_chunk.columns = df_columns\n",
    "\n",
    "            # Function to prep the test_data\n",
    "            X_processed_test = prep_test_df(df_chunk, keep_cols=keep_cols)\n",
    "            # Predicting outcomes from test_data\n",
    "            preds = model.predict(X_processed_test)\n",
    "            #Predicting probabilities from test_data\n",
    "            proba = model.predict_proba(X_processed_test)\n",
    "            # Creating df to concat later. Getting date and customer_id from original df read in from .csv\n",
    "            df_c = df_chunk[['customer_id', 's_2']]\n",
    "            # Concating the np arrays to df_c\n",
    "            df_c = pd.concat([df_c, pd.DataFrame(preds, columns=['pred']), pd.DataFrame(proba, columns=['proba_inv', 'proba'])], axis=1)\n",
    "            mdf = pd.concat([mdf, df_c])\n",
    "            # Deleting the temp dfs to free up memory.\n",
    "            del [[df_c,df_chunk]]\n",
    "\n",
    "            current_position += split_num_lines #increments position by chunk size for the next loop\n",
    "        except pd.errors.EmptyDataError:\n",
    "            break\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    return mdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feeding the test_data into the model, tabulating results, and building a df. Then saving the df to a .csv file.\n",
    "def score_feather_file(file, model, keep_cols, split_num_lines=3500000):\n",
    "    df_columns = None #object to hold the col names collected from the first df chunk\n",
    "    \n",
    "    # Define the result mdf\n",
    "    mdf = pd.DataFrame(columns=['customer_id', 's_2', 'pred', 'proba'])\n",
    "    \n",
    "    df_s = pd.read_feather(file)\n",
    "    df_s.columns = df_s.columns.str.lower()\n",
    "    # Function to prep the test_data\n",
    "    X_processed_test = prep_test_df(df_s, keep_cols=keep_cols)\n",
    "    # Predicting outcomes from test_data\n",
    "    preds = model.predict(X_processed_test)\n",
    "    #Predicting probabilities from test_data\n",
    "    proba = model.predict_proba(X_processed_test)\n",
    "    mdf = pd.concat([mdf, pd.DataFrame(preds, columns=['pred']), pd.DataFrame(proba, columns=['proba_inv', 'proba'])], axis=1)     \n",
    "    \n",
    "    return mdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model with training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120488, 155)\n"
     ]
    }
   ],
   "source": [
    "# Prep the dataframe\n",
    "X_processed, y_processed, cols_list = prep_df(df, target='target', target_to_drop='last_statement_target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the test/train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_processed, y_processed, stratify=y_processed, random_state=rand_state\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9218511387026094"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Run the model\n",
    "\n",
    "# Init classifier\n",
    "xgb_cl = xgb.XGBClassifier()\n",
    "\n",
    "# Fit\n",
    "xgb_cl.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "preds = xgb_cl.predict(X_test)\n",
    "proba = xgb_cl.predict_proba(X_test)\n",
    "\n",
    "# Score\n",
    "accuracy_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict test data, every statement flagged as target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joebu\\programming_directory\\DSBA_6156_SERJ\\venv\\venv\\lib\\site-packages\\numpy\\core\\_methods.py:48: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5531451, 13)\n"
     ]
    }
   ],
   "source": [
    "# Prep the dataframe\n",
    "X_processed, y_processed, cols_list = prep_df(df, target='target', target_to_drop='last_statement_target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Init classifier\n",
    "xgb_cla = xgb.XGBClassifier()\n",
    "\n",
    "# Fit\n",
    "xgb_cla.fit(X_processed, y_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "score_feather_file() got an unexpected keyword argument 'path'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m path \u001b[39m=\u001b[39m \u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mUsers\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mjoebu\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mprogramming_directory\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mDSBA_6156_SERJ\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mtest_data.csv\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[39m# test_data_col_names = pd.read_csv(r'C:\\Users\\joebu\\programming_directory\\large_data_files\\amex-default-prediction\\test_data.csv', nrows=0, index_col=False).columns.str.lower()\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m results_df \u001b[39m=\u001b[39m score_feather_file(path\u001b[39m=\u001b[39;49mpath, model\u001b[39m=\u001b[39;49mxgb_cla, keep_cols\u001b[39m=\u001b[39;49mcols_list)\n\u001b[0;32m      6\u001b[0m results_df\u001b[39m.\u001b[39mto_csv(\u001b[39m'\u001b[39m\u001b[39m./ignore/XGB_target.csv\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: score_feather_file() got an unexpected keyword argument 'path'"
     ]
    }
   ],
   "source": [
    "path = r'C:\\Users\\joebu\\programming_directory\\DSBA_6156_SERJ\\ignore\\test_data.csv'\n",
    "# test_data_col_names = pd.read_csv(r'C:\\Users\\joebu\\programming_directory\\large_data_files\\amex-default-prediction\\test_data.csv', nrows=0, index_col=False).columns.str.lower()\n",
    "\n",
    "\n",
    "results_df = score_feather_file(path=path, model=xgb_cla, keep_cols=cols_list)\n",
    "results_df.to_csv('./ignore/XGB_target.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11363762 entries, 0 to 11363761\n",
      "Data columns (total 190 columns):\n",
      " #    Column       Dtype         \n",
      "---   ------       -----         \n",
      " 0    customer_ID  object        \n",
      " 1    S_2          datetime64[ns]\n",
      " 2    P_2          float16       \n",
      " 3    D_39         float16       \n",
      " 4    B_1          float16       \n",
      " 5    B_2          float16       \n",
      " 6    R_1          float16       \n",
      " 7    S_3          float16       \n",
      " 8    D_41         float16       \n",
      " 9    B_3          float16       \n",
      " 10   D_42         float16       \n",
      " 11   D_43         float16       \n",
      " 12   D_44         float16       \n",
      " 13   B_4          float16       \n",
      " 14   D_45         float16       \n",
      " 15   B_5          float16       \n",
      " 16   R_2          float16       \n",
      " 17   D_46         float16       \n",
      " 18   D_47         float16       \n",
      " 19   D_48         float16       \n",
      " 20   D_49         float16       \n",
      " 21   B_6          float16       \n",
      " 22   B_7          float16       \n",
      " 23   B_8          float16       \n",
      " 24   D_50         float16       \n",
      " 25   D_51         float16       \n",
      " 26   B_9          float16       \n",
      " 27   R_3          float16       \n",
      " 28   D_52         float16       \n",
      " 29   P_3          float16       \n",
      " 30   B_10         float16       \n",
      " 31   D_53         float16       \n",
      " 32   S_5          float16       \n",
      " 33   B_11         float16       \n",
      " 34   S_6          float16       \n",
      " 35   D_54         float16       \n",
      " 36   R_4          float16       \n",
      " 37   S_7          float16       \n",
      " 38   B_12         float16       \n",
      " 39   S_8          float16       \n",
      " 40   D_55         float16       \n",
      " 41   D_56         float16       \n",
      " 42   B_13         float16       \n",
      " 43   R_5          float16       \n",
      " 44   D_58         float16       \n",
      " 45   S_9          float16       \n",
      " 46   B_14         float16       \n",
      " 47   D_59         float16       \n",
      " 48   D_60         float16       \n",
      " 49   D_61         float16       \n",
      " 50   B_15         float16       \n",
      " 51   S_11         float16       \n",
      " 52   D_62         float16       \n",
      " 53   D_63         category      \n",
      " 54   D_64         category      \n",
      " 55   D_65         float16       \n",
      " 56   B_16         float16       \n",
      " 57   B_17         float16       \n",
      " 58   B_18         float16       \n",
      " 59   B_19         float16       \n",
      " 60   D_66         category      \n",
      " 61   B_20         float16       \n",
      " 62   D_68         category      \n",
      " 63   S_12         float16       \n",
      " 64   R_6          float16       \n",
      " 65   S_13         float16       \n",
      " 66   B_21         float16       \n",
      " 67   D_69         float16       \n",
      " 68   B_22         float16       \n",
      " 69   D_70         float16       \n",
      " 70   D_71         float16       \n",
      " 71   D_72         float16       \n",
      " 72   S_15         float16       \n",
      " 73   B_23         float16       \n",
      " 74   D_73         float16       \n",
      " 75   P_4          float16       \n",
      " 76   D_74         float16       \n",
      " 77   D_75         float16       \n",
      " 78   D_76         float16       \n",
      " 79   B_24         float16       \n",
      " 80   R_7          float16       \n",
      " 81   D_77         float16       \n",
      " 82   B_25         float16       \n",
      " 83   B_26         float16       \n",
      " 84   D_78         float16       \n",
      " 85   D_79         float16       \n",
      " 86   R_8          float16       \n",
      " 87   R_9          float16       \n",
      " 88   S_16         float16       \n",
      " 89   D_80         float16       \n",
      " 90   R_10         float16       \n",
      " 91   R_11         float16       \n",
      " 92   B_27         float16       \n",
      " 93   D_81         float16       \n",
      " 94   D_82         float16       \n",
      " 95   S_17         float16       \n",
      " 96   R_12         float16       \n",
      " 97   B_28         float16       \n",
      " 98   R_13         float16       \n",
      " 99   D_83         float16       \n",
      " 100  R_14         float16       \n",
      " 101  R_15         float16       \n",
      " 102  D_84         float16       \n",
      " 103  R_16         float16       \n",
      " 104  B_29         float16       \n",
      " 105  B_30         category      \n",
      " 106  S_18         float16       \n",
      " 107  D_86         float16       \n",
      " 108  D_87         float16       \n",
      " 109  R_17         float16       \n",
      " 110  R_18         float16       \n",
      " 111  D_88         float16       \n",
      " 112  B_31         int8          \n",
      " 113  S_19         float16       \n",
      " 114  R_19         float16       \n",
      " 115  B_32         float16       \n",
      " 116  S_20         float16       \n",
      " 117  R_20         float16       \n",
      " 118  R_21         float16       \n",
      " 119  B_33         float16       \n",
      " 120  D_89         float16       \n",
      " 121  R_22         float16       \n",
      " 122  R_23         float16       \n",
      " 123  D_91         float16       \n",
      " 124  D_92         float16       \n",
      " 125  D_93         float16       \n",
      " 126  D_94         float16       \n",
      " 127  R_24         float16       \n",
      " 128  R_25         float16       \n",
      " 129  D_96         float16       \n",
      " 130  S_22         float16       \n",
      " 131  S_23         float16       \n",
      " 132  S_24         float16       \n",
      " 133  S_25         float16       \n",
      " 134  S_26         float16       \n",
      " 135  D_102        float16       \n",
      " 136  D_103        float16       \n",
      " 137  D_104        float16       \n",
      " 138  D_105        float16       \n",
      " 139  D_106        float16       \n",
      " 140  D_107        float16       \n",
      " 141  B_36         float16       \n",
      " 142  B_37         float16       \n",
      " 143  R_26         float16       \n",
      " 144  R_27         float16       \n",
      " 145  B_38         category      \n",
      " 146  D_108        float16       \n",
      " 147  D_109        float16       \n",
      " 148  D_110        float16       \n",
      " 149  D_111        float16       \n",
      " 150  B_39         float16       \n",
      " 151  D_112        float16       \n",
      " 152  B_40         float16       \n",
      " 153  S_27         float16       \n",
      " 154  D_113        float16       \n",
      " 155  D_114        category      \n",
      " 156  D_115        float16       \n",
      " 157  D_116        category      \n",
      " 158  D_117        category      \n",
      " 159  D_118        float16       \n",
      " 160  D_119        float16       \n",
      " 161  D_120        category      \n",
      " 162  D_121        float16       \n",
      " 163  D_122        float16       \n",
      " 164  D_123        float16       \n",
      " 165  D_124        float16       \n",
      " 166  D_125        float16       \n",
      " 167  D_126        category      \n",
      " 168  D_127        float16       \n",
      " 169  D_128        float16       \n",
      " 170  D_129        float16       \n",
      " 171  B_41         float16       \n",
      " 172  B_42         float16       \n",
      " 173  D_130        float16       \n",
      " 174  D_131        float16       \n",
      " 175  D_132        float16       \n",
      " 176  D_133        float16       \n",
      " 177  R_28         float16       \n",
      " 178  D_134        float16       \n",
      " 179  D_135        float16       \n",
      " 180  D_136        float16       \n",
      " 181  D_137        float16       \n",
      " 182  D_138        float16       \n",
      " 183  D_139        float16       \n",
      " 184  D_140        float16       \n",
      " 185  D_141        float16       \n",
      " 186  D_142        float16       \n",
      " 187  D_143        float16       \n",
      " 188  D_144        float16       \n",
      " 189  D_145        float16       \n",
      "dtypes: category(11), datetime64[ns](1), float16(176), int8(1), object(1)\n",
      "memory usage: 4.0+ GB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5531451 entries, 0 to 5531450\n",
      "Data columns (total 191 columns):\n",
      " #    Column       Dtype         \n",
      "---   ------       -----         \n",
      " 0    customer_ID  object        \n",
      " 1    S_2          datetime64[ns]\n",
      " 2    P_2          float16       \n",
      " 3    D_39         float16       \n",
      " 4    B_1          float16       \n",
      " 5    B_2          float16       \n",
      " 6    R_1          float16       \n",
      " 7    S_3          float16       \n",
      " 8    D_41         float16       \n",
      " 9    B_3          float16       \n",
      " 10   D_42         float16       \n",
      " 11   D_43         float16       \n",
      " 12   D_44         float16       \n",
      " 13   B_4          float16       \n",
      " 14   D_45         float16       \n",
      " 15   B_5          float16       \n",
      " 16   R_2          float16       \n",
      " 17   D_46         float16       \n",
      " 18   D_47         float16       \n",
      " 19   D_48         float16       \n",
      " 20   D_49         float16       \n",
      " 21   B_6          float16       \n",
      " 22   B_7          float16       \n",
      " 23   B_8          float16       \n",
      " 24   D_50         float16       \n",
      " 25   D_51         float16       \n",
      " 26   B_9          float16       \n",
      " 27   R_3          float16       \n",
      " 28   D_52         float16       \n",
      " 29   P_3          float16       \n",
      " 30   B_10         float16       \n",
      " 31   D_53         float16       \n",
      " 32   S_5          float16       \n",
      " 33   B_11         float16       \n",
      " 34   S_6          float16       \n",
      " 35   D_54         float16       \n",
      " 36   R_4          float16       \n",
      " 37   S_7          float16       \n",
      " 38   B_12         float16       \n",
      " 39   S_8          float16       \n",
      " 40   D_55         float16       \n",
      " 41   D_56         float16       \n",
      " 42   B_13         float16       \n",
      " 43   R_5          float16       \n",
      " 44   D_58         float16       \n",
      " 45   S_9          float16       \n",
      " 46   B_14         float16       \n",
      " 47   D_59         float16       \n",
      " 48   D_60         float16       \n",
      " 49   D_61         float16       \n",
      " 50   B_15         float16       \n",
      " 51   S_11         float16       \n",
      " 52   D_62         float16       \n",
      " 53   D_63         category      \n",
      " 54   D_64         category      \n",
      " 55   D_65         float16       \n",
      " 56   B_16         float16       \n",
      " 57   B_17         float16       \n",
      " 58   B_18         float16       \n",
      " 59   B_19         float16       \n",
      " 60   D_66         category      \n",
      " 61   B_20         float16       \n",
      " 62   D_68         category      \n",
      " 63   S_12         float16       \n",
      " 64   R_6          float16       \n",
      " 65   S_13         float16       \n",
      " 66   B_21         float16       \n",
      " 67   D_69         float16       \n",
      " 68   B_22         float16       \n",
      " 69   D_70         float16       \n",
      " 70   D_71         float16       \n",
      " 71   D_72         float16       \n",
      " 72   S_15         float16       \n",
      " 73   B_23         float16       \n",
      " 74   D_73         float16       \n",
      " 75   P_4          float16       \n",
      " 76   D_74         float16       \n",
      " 77   D_75         float16       \n",
      " 78   D_76         float16       \n",
      " 79   B_24         float16       \n",
      " 80   R_7          float16       \n",
      " 81   D_77         float16       \n",
      " 82   B_25         float16       \n",
      " 83   B_26         float16       \n",
      " 84   D_78         float16       \n",
      " 85   D_79         float16       \n",
      " 86   R_8          float16       \n",
      " 87   R_9          float16       \n",
      " 88   S_16         float16       \n",
      " 89   D_80         float16       \n",
      " 90   R_10         float16       \n",
      " 91   R_11         float16       \n",
      " 92   B_27         float16       \n",
      " 93   D_81         float16       \n",
      " 94   D_82         float16       \n",
      " 95   S_17         float16       \n",
      " 96   R_12         float16       \n",
      " 97   B_28         float16       \n",
      " 98   R_13         float16       \n",
      " 99   D_83         float16       \n",
      " 100  R_14         float16       \n",
      " 101  R_15         float16       \n",
      " 102  D_84         float16       \n",
      " 103  R_16         float16       \n",
      " 104  B_29         float16       \n",
      " 105  B_30         category      \n",
      " 106  S_18         float16       \n",
      " 107  D_86         float16       \n",
      " 108  D_87         float16       \n",
      " 109  R_17         float16       \n",
      " 110  R_18         float16       \n",
      " 111  D_88         float16       \n",
      " 112  B_31         int8          \n",
      " 113  S_19         float16       \n",
      " 114  R_19         float16       \n",
      " 115  B_32         float16       \n",
      " 116  S_20         float16       \n",
      " 117  R_20         float16       \n",
      " 118  R_21         float16       \n",
      " 119  B_33         float16       \n",
      " 120  D_89         float16       \n",
      " 121  R_22         float16       \n",
      " 122  R_23         float16       \n",
      " 123  D_91         float16       \n",
      " 124  D_92         float16       \n",
      " 125  D_93         float16       \n",
      " 126  D_94         float16       \n",
      " 127  R_24         float16       \n",
      " 128  R_25         float16       \n",
      " 129  D_96         float16       \n",
      " 130  S_22         float16       \n",
      " 131  S_23         float16       \n",
      " 132  S_24         float16       \n",
      " 133  S_25         float16       \n",
      " 134  S_26         float16       \n",
      " 135  D_102        float16       \n",
      " 136  D_103        float16       \n",
      " 137  D_104        float16       \n",
      " 138  D_105        float16       \n",
      " 139  D_106        float16       \n",
      " 140  D_107        float16       \n",
      " 141  B_36         float16       \n",
      " 142  B_37         float16       \n",
      " 143  R_26         float16       \n",
      " 144  R_27         float16       \n",
      " 145  B_38         category      \n",
      " 146  D_108        float16       \n",
      " 147  D_109        float16       \n",
      " 148  D_110        float16       \n",
      " 149  D_111        float16       \n",
      " 150  B_39         float16       \n",
      " 151  D_112        float16       \n",
      " 152  B_40         float16       \n",
      " 153  S_27         float16       \n",
      " 154  D_113        float16       \n",
      " 155  D_114        category      \n",
      " 156  D_115        float16       \n",
      " 157  D_116        category      \n",
      " 158  D_117        category      \n",
      " 159  D_118        float16       \n",
      " 160  D_119        float16       \n",
      " 161  D_120        category      \n",
      " 162  D_121        float16       \n",
      " 163  D_122        float16       \n",
      " 164  D_123        float16       \n",
      " 165  D_124        float16       \n",
      " 166  D_125        float16       \n",
      " 167  D_126        category      \n",
      " 168  D_127        float16       \n",
      " 169  D_128        float16       \n",
      " 170  D_129        float16       \n",
      " 171  B_41         float16       \n",
      " 172  B_42         float16       \n",
      " 173  D_130        float16       \n",
      " 174  D_131        float16       \n",
      " 175  D_132        float16       \n",
      " 176  D_133        float16       \n",
      " 177  R_28         float16       \n",
      " 178  D_134        float16       \n",
      " 179  D_135        float16       \n",
      " 180  D_136        float16       \n",
      " 181  D_137        float16       \n",
      " 182  D_138        float16       \n",
      " 183  D_139        float16       \n",
      " 184  D_140        float16       \n",
      " 185  D_141        float16       \n",
      " 186  D_142        float16       \n",
      " 187  D_143        float16       \n",
      " 188  D_144        float16       \n",
      " 189  D_145        float16       \n",
      " 190  target       category      \n",
      "dtypes: category(12), datetime64[ns](1), float16(176), int8(1), object(1)\n",
      "memory usage: 2.0+ GB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_feather(r'C:\\Users\\joebu\\programming_directory\\DSBA_6156_SERJ\\ignore\\test_data.feather')\n",
    "display(test_data.info(verbose=True))\n",
    "train_data = pd.read_feather(r'C:\\Users\\joebu\\programming_directory\\DSBA_6156_SERJ\\ignore\\train_data.feather')\n",
    "print(train_data.info(verbose=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11363762 entries, 0 to 11363761\n",
      "Data columns (total 190 columns):\n",
      " #    Column       Dtype         \n",
      "---   ------       -----         \n",
      " 0    customer_ID  object        \n",
      " 1    S_2          datetime64[ns]\n",
      " 2    P_2          float16       \n",
      " 3    D_39         float16       \n",
      " 4    B_1          float16       \n",
      " 5    B_2          float16       \n",
      " 6    R_1          float16       \n",
      " 7    S_3          float16       \n",
      " 8    D_41         float16       \n",
      " 9    B_3          float16       \n",
      " 10   D_42         float16       \n",
      " 11   D_43         float16       \n",
      " 12   D_44         float16       \n",
      " 13   B_4          float16       \n",
      " 14   D_45         float16       \n",
      " 15   B_5          float16       \n",
      " 16   R_2          float16       \n",
      " 17   D_46         float16       \n",
      " 18   D_47         float16       \n",
      " 19   D_48         float16       \n",
      " 20   D_49         float16       \n",
      " 21   B_6          float16       \n",
      " 22   B_7          float16       \n",
      " 23   B_8          float16       \n",
      " 24   D_50         float16       \n",
      " 25   D_51         float16       \n",
      " 26   B_9          float16       \n",
      " 27   R_3          float16       \n",
      " 28   D_52         float16       \n",
      " 29   P_3          float16       \n",
      " 30   B_10         float16       \n",
      " 31   D_53         float16       \n",
      " 32   S_5          float16       \n",
      " 33   B_11         float16       \n",
      " 34   S_6          float16       \n",
      " 35   D_54         float16       \n",
      " 36   R_4          float16       \n",
      " 37   S_7          float16       \n",
      " 38   B_12         float16       \n",
      " 39   S_8          float16       \n",
      " 40   D_55         float16       \n",
      " 41   D_56         float16       \n",
      " 42   B_13         float16       \n",
      " 43   R_5          float16       \n",
      " 44   D_58         float16       \n",
      " 45   S_9          float16       \n",
      " 46   B_14         float16       \n",
      " 47   D_59         float16       \n",
      " 48   D_60         float16       \n",
      " 49   D_61         float16       \n",
      " 50   B_15         float16       \n",
      " 51   S_11         float16       \n",
      " 52   D_62         float16       \n",
      " 53   D_63         category      \n",
      " 54   D_64         category      \n",
      " 55   D_65         float16       \n",
      " 56   B_16         float16       \n",
      " 57   B_17         float16       \n",
      " 58   B_18         float16       \n",
      " 59   B_19         float16       \n",
      " 60   D_66         category      \n",
      " 61   B_20         float16       \n",
      " 62   D_68         category      \n",
      " 63   S_12         float16       \n",
      " 64   R_6          float16       \n",
      " 65   S_13         float16       \n",
      " 66   B_21         float16       \n",
      " 67   D_69         float16       \n",
      " 68   B_22         float16       \n",
      " 69   D_70         float16       \n",
      " 70   D_71         float16       \n",
      " 71   D_72         float16       \n",
      " 72   S_15         float16       \n",
      " 73   B_23         float16       \n",
      " 74   D_73         float16       \n",
      " 75   P_4          float16       \n",
      " 76   D_74         float16       \n",
      " 77   D_75         float16       \n",
      " 78   D_76         float16       \n",
      " 79   B_24         float16       \n",
      " 80   R_7          float16       \n",
      " 81   D_77         float16       \n",
      " 82   B_25         float16       \n",
      " 83   B_26         float16       \n",
      " 84   D_78         float16       \n",
      " 85   D_79         float16       \n",
      " 86   R_8          float16       \n",
      " 87   R_9          float16       \n",
      " 88   S_16         float16       \n",
      " 89   D_80         float16       \n",
      " 90   R_10         float16       \n",
      " 91   R_11         float16       \n",
      " 92   B_27         float16       \n",
      " 93   D_81         float16       \n",
      " 94   D_82         float16       \n",
      " 95   S_17         float16       \n",
      " 96   R_12         float16       \n",
      " 97   B_28         float16       \n",
      " 98   R_13         float16       \n",
      " 99   D_83         float16       \n",
      " 100  R_14         float16       \n",
      " 101  R_15         float16       \n",
      " 102  D_84         float16       \n",
      " 103  R_16         float16       \n",
      " 104  B_29         float16       \n",
      " 105  B_30         category      \n",
      " 106  S_18         float16       \n",
      " 107  D_86         float16       \n",
      " 108  D_87         float16       \n",
      " 109  R_17         float16       \n",
      " 110  R_18         float16       \n",
      " 111  D_88         float16       \n",
      " 112  B_31         int8          \n",
      " 113  S_19         float16       \n",
      " 114  R_19         float16       \n",
      " 115  B_32         float16       \n",
      " 116  S_20         float16       \n",
      " 117  R_20         float16       \n",
      " 118  R_21         float16       \n",
      " 119  B_33         float16       \n",
      " 120  D_89         float16       \n",
      " 121  R_22         float16       \n",
      " 122  R_23         float16       \n",
      " 123  D_91         float16       \n",
      " 124  D_92         float16       \n",
      " 125  D_93         float16       \n",
      " 126  D_94         float16       \n",
      " 127  R_24         float16       \n",
      " 128  R_25         float16       \n",
      " 129  D_96         float16       \n",
      " 130  S_22         float16       \n",
      " 131  S_23         float16       \n",
      " 132  S_24         float16       \n",
      " 133  S_25         float16       \n",
      " 134  S_26         float16       \n",
      " 135  D_102        float16       \n",
      " 136  D_103        float16       \n",
      " 137  D_104        float16       \n",
      " 138  D_105        float16       \n",
      " 139  D_106        float16       \n",
      " 140  D_107        float16       \n",
      " 141  B_36         float16       \n",
      " 142  B_37         float16       \n",
      " 143  R_26         float16       \n",
      " 144  R_27         float16       \n",
      " 145  B_38         category      \n",
      " 146  D_108        float16       \n",
      " 147  D_109        float16       \n",
      " 148  D_110        float16       \n",
      " 149  D_111        float16       \n",
      " 150  B_39         float16       \n",
      " 151  D_112        float16       \n",
      " 152  B_40         float16       \n",
      " 153  S_27         float16       \n",
      " 154  D_113        float16       \n",
      " 155  D_114        category      \n",
      " 156  D_115        float16       \n",
      " 157  D_116        category      \n",
      " 158  D_117        category      \n",
      " 159  D_118        float16       \n",
      " 160  D_119        float16       \n",
      " 161  D_120        category      \n",
      " 162  D_121        float16       \n",
      " 163  D_122        float16       \n",
      " 164  D_123        float16       \n",
      " 165  D_124        float16       \n",
      " 166  D_125        float16       \n",
      " 167  D_126        category      \n",
      " 168  D_127        float16       \n",
      " 169  D_128        float16       \n",
      " 170  D_129        float16       \n",
      " 171  B_41         float16       \n",
      " 172  B_42         float16       \n",
      " 173  D_130        float16       \n",
      " 174  D_131        float16       \n",
      " 175  D_132        float16       \n",
      " 176  D_133        float16       \n",
      " 177  R_28         float16       \n",
      " 178  D_134        float16       \n",
      " 179  D_135        float16       \n",
      " 180  D_136        float16       \n",
      " 181  D_137        float16       \n",
      " 182  D_138        float16       \n",
      " 183  D_139        float16       \n",
      " 184  D_140        float16       \n",
      " 185  D_141        float16       \n",
      " 186  D_142        float16       \n",
      " 187  D_143        float16       \n",
      " 188  D_144        float16       \n",
      " 189  D_145        float16       \n",
      "dtypes: category(11), datetime64[ns](1), float16(176), int8(1), object(1)\n",
      "memory usage: 4.0+ GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5531451 entries, 0 to 5531450\n",
      "Data columns (total 191 columns):\n",
      " #    Column       Dtype         \n",
      "---   ------       -----         \n",
      " 0    customer_ID  object        \n",
      " 1    S_2          datetime64[ns]\n",
      " 2    P_2          float16       \n",
      " 3    D_39         float16       \n",
      " 4    B_1          float16       \n",
      " 5    B_2          float16       \n",
      " 6    R_1          float16       \n",
      " 7    S_3          float16       \n",
      " 8    D_41         float16       \n",
      " 9    B_3          float16       \n",
      " 10   D_42         float16       \n",
      " 11   D_43         float16       \n",
      " 12   D_44         float16       \n",
      " 13   B_4          float16       \n",
      " 14   D_45         float16       \n",
      " 15   B_5          float16       \n",
      " 16   R_2          float16       \n",
      " 17   D_46         float16       \n",
      " 18   D_47         float16       \n",
      " 19   D_48         float16       \n",
      " 20   D_49         float16       \n",
      " 21   B_6          float16       \n",
      " 22   B_7          float16       \n",
      " 23   B_8          float16       \n",
      " 24   D_50         float16       \n",
      " 25   D_51         float16       \n",
      " 26   B_9          float16       \n",
      " 27   R_3          float16       \n",
      " 28   D_52         float16       \n",
      " 29   P_3          float16       \n",
      " 30   B_10         float16       \n",
      " 31   D_53         float16       \n",
      " 32   S_5          float16       \n",
      " 33   B_11         float16       \n",
      " 34   S_6          float16       \n",
      " 35   D_54         float16       \n",
      " 36   R_4          float16       \n",
      " 37   S_7          float16       \n",
      " 38   B_12         float16       \n",
      " 39   S_8          float16       \n",
      " 40   D_55         float16       \n",
      " 41   D_56         float16       \n",
      " 42   B_13         float16       \n",
      " 43   R_5          float16       \n",
      " 44   D_58         float16       \n",
      " 45   S_9          float16       \n",
      " 46   B_14         float16       \n",
      " 47   D_59         float16       \n",
      " 48   D_60         float16       \n",
      " 49   D_61         float16       \n",
      " 50   B_15         float16       \n",
      " 51   S_11         float16       \n",
      " 52   D_62         float16       \n",
      " 53   D_63         category      \n",
      " 54   D_64         category      \n",
      " 55   D_65         float16       \n",
      " 56   B_16         float16       \n",
      " 57   B_17         float16       \n",
      " 58   B_18         float16       \n",
      " 59   B_19         float16       \n",
      " 60   D_66         category      \n",
      " 61   B_20         float16       \n",
      " 62   D_68         category      \n",
      " 63   S_12         float16       \n",
      " 64   R_6          float16       \n",
      " 65   S_13         float16       \n",
      " 66   B_21         float16       \n",
      " 67   D_69         float16       \n",
      " 68   B_22         float16       \n",
      " 69   D_70         float16       \n",
      " 70   D_71         float16       \n",
      " 71   D_72         float16       \n",
      " 72   S_15         float16       \n",
      " 73   B_23         float16       \n",
      " 74   D_73         float16       \n",
      " 75   P_4          float16       \n",
      " 76   D_74         float16       \n",
      " 77   D_75         float16       \n",
      " 78   D_76         float16       \n",
      " 79   B_24         float16       \n",
      " 80   R_7          float16       \n",
      " 81   D_77         float16       \n",
      " 82   B_25         float16       \n",
      " 83   B_26         float16       \n",
      " 84   D_78         float16       \n",
      " 85   D_79         float16       \n",
      " 86   R_8          float16       \n",
      " 87   R_9          float16       \n",
      " 88   S_16         float16       \n",
      " 89   D_80         float16       \n",
      " 90   R_10         float16       \n",
      " 91   R_11         float16       \n",
      " 92   B_27         float16       \n",
      " 93   D_81         float16       \n",
      " 94   D_82         float16       \n",
      " 95   S_17         float16       \n",
      " 96   R_12         float16       \n",
      " 97   B_28         float16       \n",
      " 98   R_13         float16       \n",
      " 99   D_83         float16       \n",
      " 100  R_14         float16       \n",
      " 101  R_15         float16       \n",
      " 102  D_84         float16       \n",
      " 103  R_16         float16       \n",
      " 104  B_29         float16       \n",
      " 105  B_30         category      \n",
      " 106  S_18         float16       \n",
      " 107  D_86         float16       \n",
      " 108  D_87         float16       \n",
      " 109  R_17         float16       \n",
      " 110  R_18         float16       \n",
      " 111  D_88         float16       \n",
      " 112  B_31         int8          \n",
      " 113  S_19         float16       \n",
      " 114  R_19         float16       \n",
      " 115  B_32         float16       \n",
      " 116  S_20         float16       \n",
      " 117  R_20         float16       \n",
      " 118  R_21         float16       \n",
      " 119  B_33         float16       \n",
      " 120  D_89         float16       \n",
      " 121  R_22         float16       \n",
      " 122  R_23         float16       \n",
      " 123  D_91         float16       \n",
      " 124  D_92         float16       \n",
      " 125  D_93         float16       \n",
      " 126  D_94         float16       \n",
      " 127  R_24         float16       \n",
      " 128  R_25         float16       \n",
      " 129  D_96         float16       \n",
      " 130  S_22         float16       \n",
      " 131  S_23         float16       \n",
      " 132  S_24         float16       \n",
      " 133  S_25         float16       \n",
      " 134  S_26         float16       \n",
      " 135  D_102        float16       \n",
      " 136  D_103        float16       \n",
      " 137  D_104        float16       \n",
      " 138  D_105        float16       \n",
      " 139  D_106        float16       \n",
      " 140  D_107        float16       \n",
      " 141  B_36         float16       \n",
      " 142  B_37         float16       \n",
      " 143  R_26         float16       \n",
      " 144  R_27         float16       \n",
      " 145  B_38         category      \n",
      " 146  D_108        float16       \n",
      " 147  D_109        float16       \n",
      " 148  D_110        float16       \n",
      " 149  D_111        float16       \n",
      " 150  B_39         float16       \n",
      " 151  D_112        float16       \n",
      " 152  B_40         float16       \n",
      " 153  S_27         float16       \n",
      " 154  D_113        float16       \n",
      " 155  D_114        category      \n",
      " 156  D_115        float16       \n",
      " 157  D_116        category      \n",
      " 158  D_117        category      \n",
      " 159  D_118        float16       \n",
      " 160  D_119        float16       \n",
      " 161  D_120        category      \n",
      " 162  D_121        float16       \n",
      " 163  D_122        float16       \n",
      " 164  D_123        float16       \n",
      " 165  D_124        float16       \n",
      " 166  D_125        float16       \n",
      " 167  D_126        category      \n",
      " 168  D_127        float16       \n",
      " 169  D_128        float16       \n",
      " 170  D_129        float16       \n",
      " 171  B_41         float16       \n",
      " 172  B_42         float16       \n",
      " 173  D_130        float16       \n",
      " 174  D_131        float16       \n",
      " 175  D_132        float16       \n",
      " 176  D_133        float16       \n",
      " 177  R_28         float16       \n",
      " 178  D_134        float16       \n",
      " 179  D_135        float16       \n",
      " 180  D_136        float16       \n",
      " 181  D_137        float16       \n",
      " 182  D_138        float16       \n",
      " 183  D_139        float16       \n",
      " 184  D_140        float16       \n",
      " 185  D_141        float16       \n",
      " 186  D_142        float16       \n",
      " 187  D_143        float16       \n",
      " 188  D_144        float16       \n",
      " 189  D_145        float16       \n",
      " 190  target       category      \n",
      "dtypes: category(12), datetime64[ns](1), float16(176), int8(1), object(1)\n",
      "memory usage: 2.0+ GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(test_data.info(verbose=True))\n",
    "display(train_data.info(verbose=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict test data, last_staement_target as outcome:\n",
    "Here will will only flag the last statement as default for each customer that did default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5531451 entries, 0 to 5531450\n",
      "Columns: 182 entries, customer_id to last_statement_target\n",
      "dtypes: category(2), datetime64[ns](1), float16(175), int32(2), int8(1), object(1)\n",
      "memory usage: 2.0+ GB\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joebu\\programming_directory\\DSBA_6156_SERJ\\venv\\venv\\lib\\site-packages\\numpy\\core\\_methods.py:48: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5531451, 12)\n"
     ]
    }
   ],
   "source": [
    "# Prep the data with last_statement_target as outcome\n",
    "print(df.info())\n",
    "X_processed, y_processed, cols_list = prep_df(df, target='last_statement_target', target_to_drop='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with new outcome\n",
    "# Init classifier\n",
    "xgb_cla = xgb.XGBClassifier()\n",
    "\n",
    "# Fit\n",
    "xgb_cla.fit(X_processed, y_processed)\n",
    "\n",
    "import pickle\n",
    "file_name = \"xgb_full.pkl\"\n",
    "\n",
    "# save\n",
    "pickle.dump(xgb_cla, open(file_name, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A given column is not a column of the dataframe",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\joebu\\programming_directory\\DSBA_6156_SERJ\\venv\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3804\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\joebu\\programming_directory\\DSBA_6156_SERJ\\venv\\venv\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\joebu\\programming_directory\\DSBA_6156_SERJ\\venv\\venv\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'd_42'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\joebu\\programming_directory\\DSBA_6156_SERJ\\venv\\venv\\lib\\site-packages\\sklearn\\utils\\__init__.py:416\u001b[0m, in \u001b[0;36m_get_column_indices\u001b[1;34m(X, key)\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m columns:\n\u001b[1;32m--> 416\u001b[0m     col_idx \u001b[39m=\u001b[39m all_columns\u001b[39m.\u001b[39;49mget_loc(col)\n\u001b[0;32m    417\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(col_idx, numbers\u001b[39m.\u001b[39mIntegral):\n",
      "File \u001b[1;32mc:\\Users\\joebu\\programming_directory\\DSBA_6156_SERJ\\venv\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3806\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3807\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'd_42'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m file_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxgb_full.pkl\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      7\u001b[0m xgb_cla \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(\u001b[39mopen\u001b[39m(file_name, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m----> 9\u001b[0m results_df \u001b[39m=\u001b[39m score_feather_file(file\u001b[39m=\u001b[39;49mpath, model\u001b[39m=\u001b[39;49mxgb_cla, keep_cols\u001b[39m=\u001b[39;49mcols_list)\n\u001b[0;32m     10\u001b[0m results_df\u001b[39m.\u001b[39mto_csv(\u001b[39m'\u001b[39m\u001b[39m./ignore/XGB_target.csv\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[8], line 11\u001b[0m, in \u001b[0;36mscore_feather_file\u001b[1;34m(file, model, keep_cols, split_num_lines)\u001b[0m\n\u001b[0;32m      9\u001b[0m df_s\u001b[39m.\u001b[39mcolumns \u001b[39m=\u001b[39m df_s\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39mlower()\n\u001b[0;32m     10\u001b[0m \u001b[39m# Function to prep the test_data\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m X_processed_test \u001b[39m=\u001b[39m prep_test_df(df_s, keep_cols\u001b[39m=\u001b[39;49mkeep_cols)\n\u001b[0;32m     12\u001b[0m \u001b[39m# Predicting outcomes from test_data\u001b[39;00m\n\u001b[0;32m     13\u001b[0m preds \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_processed_test)\n",
      "Cell \u001b[1;32mIn[7], line 25\u001b[0m, in \u001b[0;36mprep_test_df\u001b[1;34m(df, keep_cols)\u001b[0m\n\u001b[0;32m     23\u001b[0m X \u001b[39m=\u001b[39m X[keep_cols]\n\u001b[0;32m     24\u001b[0m \u001b[39m# Apply preprocessing\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m X_processed_test \u001b[39m=\u001b[39m full_processor\u001b[39m.\u001b[39;49mfit_transform(X)\n\u001b[0;32m     26\u001b[0m \u001b[39mreturn\u001b[39;00m X_processed_test\n",
      "File \u001b[1;32mc:\\Users\\joebu\\programming_directory\\DSBA_6156_SERJ\\venv\\venv\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:687\u001b[0m, in \u001b[0;36mColumnTransformer.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    685\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_n_features(X, reset\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    686\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_transformers()\n\u001b[1;32m--> 687\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_column_callables(X)\n\u001b[0;32m    688\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_remainder(X)\n\u001b[0;32m    690\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_transform(X, y, _fit_transform_one)\n",
      "File \u001b[1;32mc:\\Users\\joebu\\programming_directory\\DSBA_6156_SERJ\\venv\\venv\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:374\u001b[0m, in \u001b[0;36mColumnTransformer._validate_column_callables\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    372\u001b[0m         columns \u001b[39m=\u001b[39m columns(X)\n\u001b[0;32m    373\u001b[0m     all_columns\u001b[39m.\u001b[39mappend(columns)\n\u001b[1;32m--> 374\u001b[0m     transformer_to_input_indices[name] \u001b[39m=\u001b[39m _get_column_indices(X, columns)\n\u001b[0;32m    376\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_columns \u001b[39m=\u001b[39m all_columns\n\u001b[0;32m    377\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transformer_to_input_indices \u001b[39m=\u001b[39m transformer_to_input_indices\n",
      "File \u001b[1;32mc:\\Users\\joebu\\programming_directory\\DSBA_6156_SERJ\\venv\\venv\\lib\\site-packages\\sklearn\\utils\\__init__.py:424\u001b[0m, in \u001b[0;36m_get_column_indices\u001b[1;34m(X, key)\u001b[0m\n\u001b[0;32m    421\u001b[0m             column_indices\u001b[39m.\u001b[39mappend(col_idx)\n\u001b[0;32m    423\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m--> 424\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mA given column is not a column of the dataframe\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m    426\u001b[0m     \u001b[39mreturn\u001b[39;00m column_indices\n\u001b[0;32m    427\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: A given column is not a column of the dataframe"
     ]
    }
   ],
   "source": [
    "path = r'C:\\Users\\joebu\\programming_directory\\DSBA_6156_SERJ\\ignore\\test_data.feather'\n",
    "# test_data_col_names = pd.read_csv(r'C:\\Users\\joebu\\programming_directory\\large_data_files\\amex-default-prediction\\test_data.csv', nrows=0, index_col=False).columns.str.lower()\n",
    "\n",
    "# Read the model in from the .pkl file\n",
    "import pickle\n",
    "file_name = \"xgb_full.pkl\"\n",
    "xgb_cla = pickle.load(open(file_name, \"rb\"))\n",
    "\n",
    "results_df = score_feather_file(file=path, model=xgb_cla, keep_cols=cols_list)\n",
    "results_df.to_csv('./ignore/XGB_target.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Only training on last statements:\n",
    "Here we will only consider the last statements when training the model, and drop all the other statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter on only the lastest statement per customer\n",
    "ls_df = df[df['last_statement_flag'] == 1]\n",
    "ls_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 156)\n"
     ]
    }
   ],
   "source": [
    "# Prep the data with last_statement_target as outcome\n",
    "X_processed, y_processed, cols_list = prep_df(ls_df, target='last_statement_target', target_to_drop='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Init classifier\n",
    "xgb_cla = xgb.XGBClassifier()\n",
    "\n",
    "# Fit the model\n",
    "xgb_cla.fit(X_processed, y_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = score_split_files(path=path, model=xgb_cla, keep_cols=cols_list)\n",
    "results_df.to_csv('./ignore/XGB_only_last_statements.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5dcb6b7e2f26f70306738e96e7445a78b658183e0554cf15e38890769044d88c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
